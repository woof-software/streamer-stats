# Ponder Documentation (v0.15)

Source: https://ponder.sh/ | https://github.com/ponder-sh/ponder/tree/main/docs
Generated: 2026-02-10

---

## Get Started

# Get started [An introduction to Ponder]

## What is Ponder?

Ponder is an open-source framework for custom Ethereum indexing.

You write TypeScript code to transform onchain data into your application's schema. Then, Ponder fetches data from the chain, runs your indexing logic, and writes the result to Postgres.

Once indexed, you can query the data through GraphQL, SQL over HTTP, or directly in Postgres.

## Quickstart

### Run `create-ponder`

The quickest way to create a new Ponder project is `create-ponder`, which sets up everything automatically for you.

```bash [pnpm]
pnpm create ponder
```

```bash [yarn]
yarn create ponder
```

```bash [npm]
npm init ponder@latest
```

```bash [bun]
bun --bun create ponder
```

On installation, you'll see a few prompts.

```ansi [Default]
✔ What's the name of your project? › new-project
✔ Which template would you like to use? › Default

✔ Installed packages with pnpm.
✔ Initialized git repository.
```

```ansi [ERC-20 example]
✔ What's the name of your project? › new-project
✔ Which template would you like to use? › Reference - ERC20 token

✔ Installed packages with pnpm.
✔ Initialized git repository.
```

This guide follows the ERC-20 example, which indexes a token contract on Ethereum mainnet.

### Start the dev server

After installation, start the local development server.

```bash [pnpm]
pnpm dev
```

```bash [yarn]
yarn dev
```

```bash [npm]
npm run dev
```

```bash [bun]
bun dev
```

Ponder will connect to the database, start the HTTP server, and begin indexing.

```ansi [Logs]
12:16:42.845 INFO  Connected to database type=postgres database=localhost:5432/demo (35ms)
12:16:42.934 INFO  Connected to JSON-RPC chain=mainnet hostnames=["eth-mainnet.g.alchemy.com"] (85ms)
12:16:43.199 INFO  Created database tables count=4 tables=["account","transfer_event","allowance","approval_event"] (17ms)
12:16:43.324 INFO  Created HTTP server port=42069 (5ms)
12:16:43.325 INFO  Started returning 200 responses endpoint=/health
12:16:43.553 INFO  Started backfill indexing chain=mainnet block_range=[13142655,13150000]
12:16:43.555 INFO  Started fetching backfill JSON-RPC data chain=mainnet cached_block=13145448 cache_rate=38.0%
12:16:43.796 INFO  Indexed block range chain=mainnet event_count=4259 block_range=[13142655,13145448] (164ms)
12:16:43.840 INFO  Indexed block range chain=mainnet event_count=33 block_range=[13145449,13145474] (4ms)
```

```ansi [Terminal UI]
Chains

│ Chain   │ Status   │ Block    │ RPC (req/s) │
├─────────┼──────────┼──────────┼─────────────┤
│ mainnet │ backfill │ 13145260 │        27.5 │

Indexing (backfill)

│ Event          │ Count │ Duration (ms) │
├────────────────┼───────┼───────────────┤
│ ERC20:Transfer │  3345 │         0.015 │
│ ERC20:Approval │   384 │         0.011 │

████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░ 35.1% (1m 22s eta)

API endpoints
Live at http://localhost:42069
```

### Query the database

Visit [localhost:42069/graphql](http://localhost:42069/graphql) in your browser to explore the auto-generated GraphQL API. Here's a query for the top accounts by balance, along with the total number of accounts.

```graphql [Query]
query {
  accounts(orderBy: "balance", orderDirection: "desc", limit: 2) {
    items {
      address
      balance
    }
    totalCount
  }
}
```

```json [Result]
{
  "accounts": {
    "items": [
      {
        "address": "0x1234567890123456789012345678901234567890",
        "balance": "1000000000000000000"
      },
      {
        "address": "0x1234567890123456789012345678901234567891",
        "balance": "900000000000000000"
      }
    ],
    "totalCount": 1726
  }
}
```

Note: You can also query Ponder tables directly in Postgres, or write custom API endpoints. [Read more](#query-direct-sql).

### Customize the schema

Let's add a new column to a table in `ponder.schema.ts`. We want to track which accounts are an owner of the token contract.

```ts [ponder.schema.ts]
import { index, onchainTable, primaryKey, relations } from "ponder";

export const account = onchainTable("account", (t) => ({
  address: t.hex().primaryKey(),
  balance: t.bigint().notNull(),
  isOwner: t.boolean().notNull(), // [!code ++]
}));

// ...
```

Immediately, there's a type error in `src/index.ts` and a runtime error in the terminal. We added a required column, but our indexing logic doesn't include it.

```ansi [Terminal]
12:16:16 PM ERROR indexing   Error while processing 'ERC20:Transfer' event
NotNullConstraintError: Column 'account.isOwner' violates not-null constraint.
    at /workspace/new-project/src/index.ts:10:3
   8 |
   9 | ponder.on("ERC20:Transfer", async ({ event, context }) => {
> 10 |   await context.db
     |   ^
  11 |     .insert(account)
  12 |     .values({ address: event.args.from, balance: 0n })
  13 |     .onConflictDoUpdate((row) => ({
```

### Update indexing logic

Update the indexing logic to include `isOwner` when inserting new rows into the `account` table.

```ts [src/index.ts]
import { ponder } from "ponder:registry";
import { account } from "ponder:schema";

const OWNER_ADDRESS = "0x3bf93770f2d4a794c3d9ebefbaebae2a8f09a5e5"; // [!code ++]

ponder.on("ERC20:Transfer", async ({ event, context }) => {
  await context.db
    .insert(account)
    .values({
      address: event.args.from,
      balance: 0n,
      isOwner: event.args.from === OWNER_ADDRESS, // [!code ++]
    })
    .onConflictDoUpdate((row) => ({
    // ...
})
```

As soon as we save the file, the dev server hot reloads and finishes indexing successfully.

```ansi [Logs]
12:19:31.629 INFO  Hot reload "src/index.ts"
12:19:31.889 WARN  Dropped existing database tables count=4 tables=["account","transfer_event","allowance","approval_event"] (3ms)
12:19:31.901 INFO  Created database tables count=4 tables=["account","transfer_event","allowance","approval_event"] (12ms)
12:19:32.168 INFO  Started backfill indexing chain=mainnet block_range=[13142655,13150000]
12:19:32.169 INFO  Started fetching backfill JSON-RPC data chain=mainnet cached_block=13147325 cache_rate=63.6%
12:19:32.447 INFO  Indexed block range chain=mainnet event_count=6004 block_range=[13142655,13146396] (199ms)
12:19:32.551 INFO  Indexed block range chain=mainnet event_count=3607 block_range=[13146397,13147325] (104ms)
```

```ansi [Terminal UI]
Chains

│ Chain   │ Status   │ Block    │ RPC (req/s) │
├─────────┼──────────┼──────────┼─────────────┤
│ mainnet │ backfill │ 13146425 │        25.2 │

Indexing (backfill)

│ Event          │ Count │ Duration (ms) │
├────────────────┼───────┼───────────────┤
│ ERC20:Transfer │  5155 │         0.014 │
│ ERC20:Approval │   938 │         0.010 │

████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░ 51.5% (1m 07s eta)

API endpoints
Live at http://localhost:42069
```

## Next steps

This quickstart only scratches the surface of what Ponder can do. Take a look at the [examples directory](https://github.com/ponder-sh/ponder/tree/main/examples) for more complex projects, or the [GitHub dependents](https://github.com/ponder-sh/ponder/network/dependents?package_id=UGFja2FnZS0xMzA2OTEyMw%3D%3D) for a list of real-world repositories using Ponder.

Or, continue reading the guides and API reference here on the documentation site.

- [Contract configuration](#config-contracts)
- [Query the database directly](#query-direct-sql)
- [Schema design](#schema-tables)

## Requirements

# Requirements [Get Ponder running on your machine]

The `create-ponder` CLI is the easiest way to [get started](#get-started) with Ponder. If it runs without error, your system likely meets the requirements.

## System requirements

- macOS, Linux, or Windows (including WSL).
- [Node.js](https://nodejs.org/en) 18.18 or later.
- [PostgreSQL](https://www.postgresql.org/download/) version 14, 15, 16 or 17.

## TypeScript

Ponder uses advanced TypeScript features to offer end-to-end type safety without code generation. We **strongly** recommend taking the time to set up a working TypeScript development environment – it will pay dividends in the long run.

### Requirements

- TypeScript `>=5.0.4`, viem `>=2`, and hono `>=4.5`
- ABIs must be asserted `as const` following [ABIType guidelines](https://abitype.dev/guide/getting-started#usage)
- The `ponder-env.d.ts` file must be present and up to date

### `ponder-env.d.ts`

This file powers Ponder's zero-codegen type system. It contains a declaration for the `ponder:registry` virtual module which exports types derived from `ponder.config.ts` and `ponder.schema.ts`.

After upgrading to a new version of `ponder`, the dev server might make changes to `ponder-env.d.ts`. When this happens, please accept and commit the changes.

### VSCode

By default, VSCode's TypeScript language features use an internal version of TypeScript. Sometimes, this version does not meet Ponder's requirement of `>=5.0.4`.

To change VSCode's TypeScript version, run `TypeScript: Select TypeScript version..."` from the command palette and select `Use Workspace Version` or [update VSCode's version](https://stackoverflow.com/questions/39668731/what-typescript-version-is-visual-studio-code-using-how-to-update-it).

## Database

# Database [Set up the database]

Ponder supports two database options, [**PGlite**](https://pglite.dev/) and Postgres.

- **PGlite**: An embedded Postgres database. PGlite runs in the same Node.js process as Ponder, and stores data in the `.ponder` directory. **Only suitable for local development**.
- **PostgreSQL**: A traditional Postgres database server. Required for production, can be used for local development.

## Choose a database

Ponder uses PGlite by default. To use Postgres, set the `DATABASE_URL` environment variable to a Postgres connection string, or use explicit configuration in `ponder.config.ts`.

```ts
import { createConfig } from "ponder";

export default createConfig({
  database: {
    // [!code focus]
    kind: "postgres", // [!code focus]
    connectionString: "postgresql://user:password@localhost:5432/dbname", // [!code focus]
  }, // [!code focus]
  // ...
});
```

[Read more](#api-reference-ponder-config#database) about database configuration in the `ponder.config.ts` API reference.

## Database schema

Ponder uses **database schemas** to organize data. Each instance must use a different schema.

Use the `DATABASE_SCHEMA` environment variable or `--schema` CLI option to configure the database schema for an instance. This is where the app will create the tables defined in `ponder.schema.ts`.

```bash [.env.local]
DATABASE_SCHEMA=my_schema
```

```bash [CLI]
ponder start --schema my_schema
```

[Read more](#production-self-hosting#database-schema) about database schema selection in the self-hosting guide.

### Guidelines

Here are a few things to keep in mind when choosing a database schema.

- No two Ponder instances/deployments can use the same database schema at the same time.
- Tables created by `ponder start` are treated as valuable and will never be dropped automatically.
- The default schema for `ponder dev` is `public`. There is no default for `ponder start`, you must explicitly set the database schema.
- Use `ponder dev` for local development; `ponder start` is intended for production.

## Migration Guide

# Migration guide [Upgrade to a new version of Ponder]

## 0.15

### Breaking changes

None.

### New features

#### `ordering: "experimental_isolated"`

A new ordering mode, `experimental_isolated`, is available. This mode isolates each chain, requiring each table in the schema to include a `chain_id` column in the primary key. It also takes advantage of mulitple CPU cores for better performance.

Visit the [documentation](https://ponder.sh/docs/api-reference/ponder/config#ordering) for details.

#### Improved SQL over HTTP scalability

SQL over HTTP queries are cached and selectively invalidated only when a table referenced by the query is updated.

Live queries are now guaranteed to be updated _only when the query result changes_.

## 0.14

### Breaking changes

#### Metrics updates

- Removed the `ponder_historical_duration`, `ponder_indexing_has_error`, and `ponder_http_server_port` metrics.
- Added a `chain` label to `ponder_historical_start_timestamp_seconds` and `ponder_historical_end_timestamp_seconds`.
- Updated histogram bucket limits.

### New features

#### Log output improvements

Ponder now emits a more useful set of logs. These changes improve signal-to-noise and aim to eliminate scenarios where Ponder appears to hang without printing any logs.

Highlights:

- Pretty logs (the default) now use millisecond precision for timestamps, no longer include a "service" column, and use [logfmt](https://brandur.org/logfmt) formatting for extra properties.
- JSON-formatted logs (`--log-format json` CLI option) now include a wider range of properties, e.g. `duration`, `block_range`, `chain_id`, and so on. The standard `service` property was removed.

![New log output screenshot](/logs-014.png)

#### GraphQL offset pagination

The GraphQL now supports `offset` pagination for each plural query field and `many()` relationship field.

[Read more](#query-graphql#pagination) in the GraphQL pagination docs.

#### Custom database views

Ponder now supports custom database views in `ponder.schema.ts` that reference other tables or views in your schema. Custom views are defined using the Drizzle query builder API.

We expect this feature to be particularly useful for users who want custom query-time transformation logic but still prefer GraphQL (vs. SQL-over-HTTP or direct SQL).

[Read more](#schema-views) in the custom view guide.

## 0.13

### Breaking changes

None.

### New features

#### Performance

Ponder now queries less data from the database when reindexing against a full RPC cache. This can eliminate a significant amount of unnecessary work for apps with a large number of events where the indexing logic only accesses a few properties on the `event` object.

## 0.12

### Breaking changes

#### Lowercase addresses

Address values on the `event` object are now always **lowercase**. Before, these values were always checksum encoded.

This includes decoded event and trace arguments (e.g. `event.args.sender`) and these standard properties of the `event` object:

- `event.block.miner`
- `event.log.address`
- `event.transaction.to`
- `event.transaction.from`
- `event.transactionReceipt.from`
- `event.transactionReceipt.to`
- `event.transactionReceipt.contractAddress`
- `event.trace.from`
- `event.trace.to`

### New features

#### Exit code 75

Ponder now exits with code 75 when the instance encounters a retryable error. This includes most RPC errors and database connection issues.

Exit code 1 now indicates a fatal error that is unlikely to resolve after a restart. This includes logical indexing errors (e.g. unique constraint violations).

## 0.11

### Breaking changes

#### Renamed `networks` → `chains`

The `networks` field in `ponder.config.ts` was renamed and redesigned.

- `networks` → `chains`
- `chainId` → `id`
- `transport` → `rpc`

The new `rpc` field accepts one or more RPC endpoints directly, or a Viem Transport for backwards compatibility. When multiple RPC URLS are provided, Ponder load balances across them.

```ts [ponder.config.ts]
import { createConfig } from "ponder";
import { http } from "viem";

export default createConfig({
  networks: {
    // [!code --]
    mainnet: {
      // [!code --]
      chainId: 1, // [!code --]
      transport: http("https://eth-mainnet.g.alchemy.com/v2/your-api-key"), // [!code --]
    }, // [!code --]
  }, // [!code --]
  chains: {
    // [!code ++]
    mainnet: {
      // [!code ++]
      id: 1, // [!code ++]
      rpc: "https://eth-mainnet.g.alchemy.com/v2/your-api-key", // [!code ++]
    }, // [!code ++]
  }, // [!code ++]
  contracts: {
    Erc20: {
      network: "mainnet", // [!code --]
      chain: "mainnet", // [!code ++]
      // ...
    },
  },
});
```

#### Renamed `context.network` → `context.chain`

The indexing function context object `context.network` was renamed to `context.chain`.

#### Renamed API functions → API endpoints

**API functions** were renamed to **API endpoints** throughout the documentation.

#### `publicClients` now keyed by chain name

The [`publicClients`](#query-api-endpoints#rpc-requests) object (available in API endpoints) is now keyed by chain name, not chain ID.

#### `/status` response type

The response type for the `/status` endpoint and related functions from `@ponder/client` and `@ponder/react` has changed.

```ts
type Status = {
  [chainName: string]: {
    ready: boolean; // [!code --]
    id: number; // [!code ++]
    block: { number: number; timestamp: number };
  };
};
```

#### Default `multichain` ordering

The default event ordering strategy was changed from `omnichain` to `multichain`. [Read more](#api-reference-ponder-config#ordering) about event ordering.

### New features

#### Database views pattern

This release introduces a new pattern for querying Ponder tables directly in Postgres. [Read more](#production-self-hosting#views-pattern) about the views pattern.

:::steps

##### Update start command

To enable the views pattern on platforms like Railway, update the start command to include the new `--views-schema` flag.

```bash [Start command]
pnpm start --schema $RAILWAY_DEPLOYMENT_ID # [!code --]
pnpm start --schema $RAILWAY_DEPLOYMENT_ID --views-schema my_project # [!code ++]
```

Whenever a deployment becomes _ready_ (historical indexing finishes), it will create views in the specified schema that "point" to its tables.

##### Query views schema

With this configuration, downstream applications can query the views schema directly. The views will always point at the latest deployment's tables.

```sql
SELECT * FROM my_project.accounts;
```

## 0.10

### Breaking changes

#### `ponder_sync` database migration

**WARNING**: This release includes an irreversible database migration to the RPC request cache located in the `ponder_sync` schema. Here are some details to consider when upgrading your production environment.

1. When an `0.10` instance starts up, it will attempt to run the migration against the connected database.
2. Any `<=0.9` instances currently connected to the database will crash, or the migration will fail.
3. Once the migration is complete, it's not possible to run `<=0.9` instances against the upgraded database.

#### Removed `event.log.id`

The `event.log.id` and `event.trace.id` properties were removed. Replace each occurrence with the new `event.id` property (described below), or update the table definition to use a compound primary key that better represents the business logic / domain.

```ts [src/index.ts]
import { ponder } from "ponder:registry";
import { transferEvent } from "ponder:registry";

ponder.on("ERC20:Transfer", ({ event, context }) => {
  await context.db
    .insert(transferEvent)
    .values({ id: event.log.id }); // [!code --]
    .values({ id: event.id }); // [!code ++]
});
```

#### Removed `event.name`

The undocumented `event.name` property was also removed.

### New features

#### `event.id`

The new `event.id` property is a globally unique identifier for a log, block, transaction, or trace event that works across any number of chains. Each `event.id` value is a 75-digit positive integer represented as a string.

#### Factory performance

This release fixes a long-standing performance issue affecting large factory contracts (10k+ addresses). Before, a SQL query was used to dynamically generate the list of addresses for each batch of events. This did not scale well. Now, the list of addresses is materialized directly and all address filtering occurs in-memory.

#### RPC request cache fixes

This release fixes two performance issues related to the ad-hoc RPC request cache.

1. **Reorg reconciliation** — Before, the query that evicted non-canonical results from the cache did not have an appropriate index. This occasionally caused timeouts leading to a crash.
2. **Large multicalls** — Before, multicall requests were treated naively as a single large `eth_call`. Now, the caching logic intelligently splits large multicall requests into smaller chunks.

## 0.9

### Breaking changes

#### API endpoints file is required

The Hono / API endpoints file `src/api/index.ts` is now required. The GraphQL API is no longer served by default.

To achieve the same functionality as `<=0.8`, copy the following code into `src/api/index.ts`.

```ts [src/api/index.ts]
import { db } from "ponder:api";
import schema from "ponder:schema";
import { Hono } from "hono";
import { graphql } from "ponder";

const app = new Hono();

app.use("/", graphql({ db, schema }));
app.use("/graphql", graphql({ db, schema }));

export default app;
```

#### Removed `ponder.get()`, `post()`, `use()`

This release makes custom API endpoints less opinionated. Just default export a normal Hono `App` object from the `src/api/index.ts` file, and Ponder will serve it.

The `ponder.get()`, `post()`, `use()` methods were removed. Now, use Hono's built-in routing system.

```ts [src/api/index.ts (0.8 and below)]
import { ponder } from "ponder:registry";

ponder.get("/hello", (c) => {
  return c.text("Hello, world!");
});
```

```ts [src/api/index.ts (0.9)]
import { Hono } from "hono";

const app = new Hono();

app.get("/hello", (c) => {
  return c.text("Hello, world!");
});

export default app;
```

#### Removed `c.db`

The `c.db` object was removed from the Hono context. Now, use the `"ponder:api"` virtual module to access the readonly Drizzle database object.

```ts [src/api/index.ts]
import { db } from "ponder:api"; // [!code focus]
import schema from "ponder:schema";
import { Hono } from "hono";

const app = new Hono();

app.get("/account/:address", async (c) => {
  const address = c.req.param("address");

  const account = await db // [!code focus]
    .select() // [!code focus]
    .from(schema.accounts) // [!code focus]
    .where(eq(schema.accounts.address, address)) // [!code focus]
    .limit(1); // [!code focus]

  return c.json(account);
});

export default app;
```

### New features

#### SQL over HTTP

The `@ponder/client` package provides a new experience for querying a Ponder app over HTTP. It's an SQL-based alternative to the GraphQL API. [Read more](#query-sql-over-http).

#### `@ponder/react`

The `@ponder/react` package uses `@ponder/client` and Tanstack Query to provide reactive live queries. [Read more](#query-sql-over-http#guide-react).

#### `publicClients`

Custom API endpoint files now have access to a new `"ponder:api"` virtual module. This module contains the `db` object and a new `publicClients` object, which contains a Viem [Public Client](https://viem.sh/docs/clients/public) for each network. These clients use the transports defined in `ponder.config.ts`.

```ts [src/api/index.ts] {1,11}
import { publicClients, db } from "ponder:api"; // [!code focus]
import schema from "ponder:schema";
import { Hono } from "hono";

const app = new Hono();

app.get("/account/:chainId/:address", async (c) => {
  const chainId = c.req.param("chainId");
  const address = c.req.param("address");

  const balance = await publicClients[chainId].getBalance({ address }); // [!code focus]

  const account = await db.query.accounts.findFirst({
    where: eq(schema.accounts.address, address),
  });

  return c.json({ balance, account });
});

export default app;
```

#### Custom log filters

The `contracts.filter` property now supports multiple log filters, and requires argument values. [Read more](#config-contracts#filter).

## 0.8

### Breaking changes

Warning: This release includes an irreversible migration to the `ponder_sync` schema (RPC request cache). Once you run a `0.8` app against a database, you can no longer run `<=0.7` apps against the same database.

#### Database management

Ponder now requires the database schema to be explicitly specified with an environment variable or CLI flag. **`onchainSchema()` is removed.**

```bash [.env.local]
DATABASE_SCHEMA=my_schema
```

```bash [shell]
ponder start --schema my_schema
```

Note: Each deployment/instance of a Ponder app must have it's own schema, with some exceptions for `ponder dev` and crash recovery. [Read more](#database#database-schema).

#### Railway

Railway users should [update the start command](#production-railway#create-a-ponder-app-service) to include a database schema.

:```bash [pnpm]
pnpm start --schema $RAILWAY_DEPLOYMENT_ID

````

```bash [yarn]
yarn start --schema $RAILWAY_DEPLOYMENT_ID
````

```bash [npm]
npm run start -- --schema $RAILWAY_DEPLOYMENT_ID
```

```bash [bun]
bun start -- --schema $RAILWAY_DEPLOYMENT_ID
```

#### `@ponder/core` → `ponder`

New versions will be published to `ponder` and not `@ponder/core`.

```bash [pnpm]
pnpm remove @ponder/core
pnpm add ponder
```

```bash [yarn]
yarn remove @ponder/core
yarn add ponder
```

```bash [npm]
npm remove @ponder/core
npm add ponder
```

```bash [bun]
bun remove @ponder/core
bun add ponder
```

#### `@/generated` → `ponder:registry`

The virtual module `@/generated` was replaced with `ponder:registry`.

```diff [src/index.ts]
- import { ponder } from "@/generated";
+ import { ponder } from "ponder:registry";
```

#### `factory()` function

The `factory()` function replaces the `factory` property in the contract config. The result should be passed to the `address` property.

```ts [ponder.config.ts (0.7 and below)]
import { createConfig } from "@ponder/core";

export default createConfig({
  contracts: {
    uniswap: {
      factory: {
        // [!code focus]
        address: "0x1F98431c8aD98523631AE4a59f267346ea31F984", // [!code focus]
        event: getAbiItem({ abi: UniswapV3FactoryAbi, name: "PoolCreated" }), // [!code focus]
        parameter: "pool", // [!code focus]
      }, // [!code focus]
    },
  },
});
```

```ts [ponder.config.ts (0.8)]
import { createConfig, factory } from "ponder"; // [!code focus]

export default createConfig({
  contracts: {
    uniswap: {
      address: factory({
        // [!code focus]
        address: "0x1F98431c8aD98523631AE4a59f267346ea31F984", // [!code focus]
        event: getAbiItem({ abi: UniswapV3FactoryAbi, name: "PoolCreated" }), // [!code focus]
        parameter: "pool", // [!code focus]
      }), // [!code focus]
    },
  },
});
```

#### `ponder-env.d.ts`

This release updates the `ponder-env.d.ts` file. The new file uses [triple slash directives](https://www.typescriptlang.org/docs/handbook/triple-slash-directives.html#-reference-types-) for less frequent updates.

```bash [pnpm]
pnpm codegen
```

```bash [yarn]
yarn codegen
```

```bash [npm]
npm run codegen
```

```bash [bun]
bun codegen
```

#### Removed `transactionReceipt.logs`

The `transactionReceipt.logs` property was removed from the `event` object.

#### Removed redundant properties from `event`

The following properties were removed from the `event` object.

```diff
- event.log.blockNumber;
- event.log.blockHash;
- event.log.transactionHash;
- event.log.transactionIndex;
- event.transaction.blockNumber;
- event.transaction.blockHash;
- event.transactionReceipt.transactionHash;
- event.transactionReceipt.transactionIndex;
```

All of the data is still available on other properties of the `event` object, such as `event.transaction.hash` or `event.block.number`.

### New features

#### Account indexing

A new event source `accounts` is available. Accounts can be used to index transactions and native transfers to and from an address. [Read more](#config-accounts).

#### `ponder:schema` alias

The `ponder:schema` virtual module was added. It is an alias for `ponder.schema.ts`.

```diff [src/index.ts]
- import { accounts } from "../ponder.schema";
+ import { accounts } from "ponder:schema";
```

It also contains a default export of all the exported table objects from `ponder.schema.ts`.

```ts [src/index.ts] {1,3}
import schema from "ponder:schema";

const row = await db.insert(schema.accounts).values({
  address: "0x7Df1",
  balance: 0n,
});
```

#### `ponder db list`

A new command was added for more visibility into which database schemas are being used.

```bash [shell]
$ ponder db list

│ Schema        │ Active   │ Last active    │ Table count │
├───────────────┼──────────┼────────────────┼─────────────┤
│ indexer_prod  │      yes │            --- │          10 │
│ test          │       no │    26m 58s ago │          10 │
│ demo          │       no │      1 day ago │           5 │
```

## 0.7

### Breaking changes

This release includes several breaking changes.

#### Install & run codegen

```bash [pnpm]
pnpm add @ponder/core@0.7
```

```bash [yarn]
yarn add @ponder/core@0.7
```

```bash [npm]
npm add @ponder/core@0.7
```

```bash [bun]
bun add @ponder/core@0.7
```

To ensure strong type safety during the migration, regenerate `ponder-env.d.ts`.

```bash [pnpm]
pnpm codegen
```

```bash [yarn]
yarn codegen
```

```bash [npm]
npm run codegen
```

```bash [bun]
bun codegen
```

#### Migrate `ponder.schema.ts`

Here's a table defined with the new schema definition API, which uses [Drizzle](https://orm.drizzle.team/docs/overview) under the hood.

```ts [ponder.schema.ts (after)]
import { onchainTable } from "@ponder/core";

export const accounts = onchainTable("account", (t) => ({
  address: t.hex().primaryKey(),
  daiBalance: t.bigint().notNull(),
  isAdmin: t.boolean().notNull(),
  graffiti: t.text(),
}));
```

Key changes:

1. Declare tables with the `onchainTable` function exported from `@ponder/core`
2. Export all table objects from `ponder.schema.ts`
3. Use `.primaryKey()` to mark the primary key column
4. Columns are nullable by default, use `.notNull()` to add the constraint
5. The `hex` column type now uses `TEXT` instead of `BYTEA`
6. `p.float()` (`DOUBLE PRECISION`) was removed, use `t.doublePrecision()` or `t.real()` instead

The new `onchainTable` function adds several new capabilities.

- Custom primary key column name (other than `id`)
- Composite primary keys
- Default column values

Here's a more advanced example with indexes and a composite primary key.

```ts [ponder.schema.ts]
import { onchainTable, index, primaryKey } from "@ponder/core";

export const transferEvents = onchainTable(
  "transfer_event",
  (t) => ({
    id: t.text().primaryKey(),
    amount: t.bigint().notNull(),
    timestamp: t.integer().notNull(),
    from: t.hex().notNull(),
    to: t.hex().notNull(),
  }),
  (table) => ({
    fromIdx: index().on(table.from),
  })
);

export const allowance = onchainTable(
  "allowance",
  (t) => ({
    owner: t.hex().notNull(),
    spender: t.hex().notNull(),
    amount: t.bigint().notNull(),
  }),
  (table) => ({
    pk: primaryKey({ columns: [table.owner, table.spender] }),
  })
);

export const approvalEvent = onchainTable("approval_event", (t) => ({
  id: t.text().primaryKey(),
  amount: t.bigint().notNull(),
  timestamp: t.integer().notNull(),
  owner: t.hex().notNull(),
  spender: t.hex().notNull(),
}));
```

#### Migrate indexing functions

This release updates the indexing function database API to offer a unified SQL experience based on Drizzle.

Here's an indexing function defined with the new API, which uses the table objects exported from `ponder.schema.ts`.

```ts [src/index.ts]
import { ponder } from "@/generated";
import { account } from "../ponder.schema";

ponder.on("ERC20:Transfer", async ({ event, context }) => {
  await context.db
    .insert(account)
    .values({
      address: event.args.from,
      balance: 0n,
      isOwner: false,
    })
    .onConflictDoUpdate((row) => ({
      balance: row.balance - event.args.amount,
    }));
});
```

Key changes:

1. Transition from ORM pattern `db.Account.create({ ... }){:ts}` to query builder pattern `db.insert(accounts, { ... }){:ts}`
2. Import table objects from `ponder.schema.ts`
3. Replace `findMany` with `db.sql.select(...)` or `db.sql.query(...)`

Here is a simple migration example to familiarize yourself with the API.

```ts [src/index.ts (0.6 and below)]
// Create a single allowance
await context.db.Allowance.create({
  id: event.log.id,
  data: {
    owner: event.args.owner,
    spender: event.args.spender,
    amount: event.args.amount,
  },
});
```

```ts [src/index.ts (0.7)]
import { allowance } from "../ponder.schema";

// Create a single allowance
await context.db.insert(allowance).values({
  id: event.log.id,
  owner: event.args.owner,
  spender: event.args.spender,
  amount: event.args.amount,
});
```

Here is a reference for how to migrate each method.

```ts [src/index.ts]
// create -> insert
await context.db.Account.create({
  id: event.args.from,
  data: { balance: 0n },
});
await context.db.insert(account).values({ id: event.args.from, balance: 0n });

// createMany -> insert
await context.db.Account.createMany({
  data: [
    { id: event.args.from, balance: 0n },
    { id: event.args.to, balance: 0n },
  ],
});
await context.db.insert(account).values([
  { id: event.args.from, balance: 0n },
  { id: event.args.to, balance: 0n },
]);

// findUnique -> find
await context.db.Account.findUnique({ id: event.args.from });
await context.db.find(account, { address: event.args.from });

// update
await context.db.Account.update({
  id: event.args.from,
  data: ({ current }) => ({ balance: current.balance + 100n }),
});
await context.db
  .update(account, { address: event.args.from })
  .set((row) => ({ balance: row.balance + 100n }));

// upsert
await context.db.Account.upsert({
  id: event.args.from,
  create: { balance: 0n },
  update: ({ current }) => ({ balance: current.balance + 100n }),
});
await context.db
  .insert(account)
  .values({ address: event.args.from, balance: 0n })
  .onConflictDoUpdate((row) => ({ balance: row.balance + 100n }));

// delete
await context.db.Account.delete({ id: event.args.from });
await context.db.delete(account, { address: event.args.from });

// findMany -> raw SQL select, see below
await context.db.Account.findMany({ where: { balance: { gt: 100n } } });
await context.db.sql.select().from(account).where(eq(account.balance, 100n));

// updateMany -> raw SQL update, see below
await context.db.Player.updateMany({
  where: { id: { startsWith: "J" } },
  data: { age: 50 },
});
await context.db.sql
  .update(player)
  .set({ age: 50 })
  .where(like(player.id, "J%"));
```

Finally, another migration example for an ERC20 Transfer indexing function using `upsert`.

```ts [src/index.ts (0.6 and below)]
import { ponder } from "@/generated";

ponder.on("ERC20:Transfer", async ({ event, context }) => {
  const { Account, TransferEvent } = context.db;

  await Account.upsert({
    id: event.args.from,
    create: {
      balance: BigInt(0),
      isOwner: false,
    },
    update: ({ current }) => ({
      balance: current.balance - event.args.amount,
    }),
  });
});
```

```ts [src/index.ts (0.7)]
import { ponder } from "@/generated";
import { account } from "../ponder.schema";

ponder.on("ERC20:Transfer", async ({ event, context }) => {
  await context.db
    .insert(account)
    .values({
      address: event.args.from,
      balance: 0n,
      isOwner: false,
    })
    .onConflictDoUpdate((row) => ({
      balance: row.balance - event.args.amount,
    }));
});
```

#### Migrate API functions

- Removed `c.tables` in favor of importing table objects from `ponder.schema.ts`

### New features

#### Arbitrary SQL within indexing functions

The new `context.db.sql` interface replaces the rigid `findMany` method and supports any valid SQL `select` query.

```ts [src/index.ts]
import { desc } from "@ponder/core";
import { account } from "../ponder.schema";

ponder.on("...", ({ event, context }) => {
  const result = await context.db.sql
    .select()
    .from(account)
    .orderBy(desc(account.balance))
    .limit(1);
});
```

## 0.6.0

### Breaking changes

#### Updated `viem` to `>=2`

This release updates the `viem` peer dependency requirement to `>=2`. The `context.client` action `getBytecode` was renamed to `getCode`.

```bash [pnpm]
pnpm add viem@latest
```

```bash [yarn]
yarn add viem@latest
```

```bash [npm]
npm install viem@latest
```

```bash [bun]
bun add viem@latest
```

#### Simplified Postgres schema pattern

Starting with this release, the indexed tables, reorg tables, and metadata table for a Ponder app are contained in one Postgres schema, specified by the user in `ponder.config.ts` (defaults to `public`). This means the shared `ponder` schema is no longer used. (Note: The `ponder_sync` schema is still in use).

This release also removes the view publishing pattern and the `publishSchema` option from `ponder.config.ts`, which may disrupt production setups using horizontal scaling or direct SQL. If you relied on the publish pattern, please [get in touch on Telegram](https://t.me/kevinkoste) and we'll work to get you unblocked.

### New features

#### Added `/ready`, updated `/health`

The new `/ready` endpoint returns an HTTP `200` response once the app **is ready to serve requests**. This means that historical indexing is complete and the app is indexing events in realtime.

The existing `/health` endpoint now returns an HTTP `200` response as soon as the process starts. (This release removes the `maxHealthcheckDuration` option, which previously governed the behavior of `/health`.)

For Railway users, we now recommend using `/ready` as the health check endpoint to enable zero downtime deployments. If your app takes a while to sync, be sure to set the healthcheck timeout accordingly. Read the [Railway deployment guide](#production-railway#create-a-ponder-app-service) for more details.

## 0.5.0

### Breaking changes

#### `hono` peer dependency

This release adds [Hono](https://hono.dev) as a peer dependency. After upgrading, install `hono` in your project.

```bash [pnpm]
pnpm add hono@latest
```

```bash [yarn]
yarn add hono@latest
```

```bash [npm]
npm install hono@latest
```

```bash [bun]
bun add hono@latest
```

### New features

#### Introduced custom API endpoints

This release added support for API functions. [Read more](#query-api-endpoints).

## 0.4.0

### Breaking changes

This release changes the location of database tables when using both SQLite and Postgres. It **does not** require any changes to your application code, and does not bust the sync cache for SQLite or Postgres.

#### New database layout

Please read the new docs on [direct SQL](#query-direct-sql) for a detailed overview.

**SQLite**

Ponder now uses the `.ponder/sqlite/public.db` file for indexed tables. Before, the tables were present as views in the `.ponder/sqlite/ponder.db`. Now, the`.ponder/sqlite/ponder.db` file is only used internally by Ponder.

**Postgres**

Ponder now creates a table in the `public` schema for each table in `ponder.schema.ts`. Before, Ponder created them as views in the `ponder` schema.

Isolation while running multiple Ponder instances against the same database also works differently. Before, Ponder used a schema with a pseudorandom name if the desired schema was in use. Now, Ponder will fail on startup with an error if it cannot acquire a lock on the desired schema.

This also changes the zero-downtime behavior on platforms like Railway. For more information on how this works in `0.4`, please reference:

- [Direct SQL](#query-direct-sql)
- [Zero-downtime deployments](#production-self-hosting#database-schema)

**Postgres table cleanup**

After upgrading to `0.4`, you can run the following Postgres SQL script to clean up stale tables and views created by `0.3` Ponder apps.

**Note:** This script could obviously be destructive, so please read it carefully before executing.

```sql [cleanup.sql]
DO $$
DECLARE
    view_name TEXT;
    schema_name_var TEXT;
BEGIN
    -- Drop all views from the 'ponder' schema
    FOR view_name IN SELECT table_name FROM information_schema.views WHERE table_schema = 'ponder'
    LOOP
        EXECUTE format('DROP VIEW IF EXISTS ponder.%I CASCADE', view_name);
        RAISE NOTICE 'Dropped view "ponder"."%"', view_name;
    END LOOP;

    -- Drop the 'ponder_cache' schema
    EXECUTE 'DROP SCHEMA IF EXISTS ponder_cache CASCADE';
    RAISE NOTICE 'Dropped schema "ponder_cache"';

    -- Find and drop any 'ponder_instance_*' schemas
    FOR schema_name_var IN SELECT schema_name AS schema_name_alias FROM information_schema.schemata WHERE schema_name LIKE 'ponder_instance_%'
    LOOP
        EXECUTE format('DROP SCHEMA IF EXISTS %I CASCADE', schema_name_var);
        RAISE NOTICE 'Dropped schema "%"', schema_name_var;
    END LOOP;
END $$;
```

## 0.3.0

### Breaking changes

#### Moved SQLite directory

**Note:** This release busted the SQLite sync cache.

The SQLite database was moved from the `.ponder/store` directory to `.ponder/sqlite`. The old `.ponder/store` directory will still be used by older versions.

#### Moved Postgres sync tables

Similar to SQLite, the sync tables for Postgres were moved from the `public` schema to `ponder_sync`. Now, Ponder does not use the `public` schema whatsoever.

This change did NOT bust the sync cache; the tables were actually moved. This process emits some `WARN`-level logs that you should see after upgrading.

## 0.2.0

### Breaking changes

#### Replaced `p.bytes()` with `p.hex()`

Removed `p.bytes()` in favor of a new `p.hex()` primitive column type. `p.hex()` is suitable for Ethereum addresses and other hex-encoded data, including EVM `bytes` types. `p.hex()` values are stored as `bytea` (Postgres) or `blob` (SQLite). To migrate, replace each occurrence of `p.bytes()` in `ponder.schema.ts` with `p.hex()`, and ensure that any values you pass into hex columns are valid hexadecimal strings. The GraphQL API returns `p.hex()` values as hexadecimal strings, and allows sorting/filtering on `p.hex()` columns using the numeric comparison operators (`gt`, `gte`, `le`, `lte`).

### New features

#### Cursor pagination

Updated the GraphQL API to use cursor pagination instead of offset pagination. Note that this change also affects the `findMany` database method. See the [GraphQL pagination docs](#query-graphql#pagination) for more details.

## 0.1

### Breaking changes

#### Config

- In general, `ponder.config.ts` now has much more static validation using TypeScript. This includes network names in `contracts`, ABI event names for the contract `event` and `factory` options, and more.
- The `networks` and `contracts` fields were changed from an array to an object. The network or contract name is now specified using an object property name. The `name` field for both networks and contracts was removed.
- The `filter` field has been removed. To index all events matching a specific signature across all contract addresses, add a contract that specifies the `event` field without specifying an `address`.
- The `abi` field now requires an ABI object that has been asserted as const (cannot use a file path). See the ABIType documentation for more details.

#### Schema

- The schema definition API was rebuilt from scratch to use a TypeScript file `ponder.schema.ts` instead of `schema.graphql`. The `ponder.schema.ts` file has static validation using TypeScript.
- Note that it is possible to convert a `schema.graphql` file into a `ponder.schema.ts` file without introducing any breaking changes to the autogenerated GraphQL API schema.
- Please see the `design your schema` guide for an overview of the new API.

#### Indexing functions

- `event.params` was renamed to `event.args` to better match Ethereum terminology norms.
- If a contract uses the `event` option, only the specified events will be available for registration. Before, all events in the ABI were available.
- `context.models` was renamed to `context.db`
- Now, a read-only Viem client is available at `context.client`. This client uses the same transport you specify in `ponder.config.ts`, except all method are cached to speed up subsequent indexing.
- The `context.contracts` object now contains the contract addresses and ABIs specified in`ponder.config.ts`, typed as strictly as possible. (You should not need to copy addresses and ABIs around anymore, just use `context.contracts`).
- A new `context.network` object was added which contains the network name and chain ID that the current event is from.

#### Multi-chain indexing

- The contract `network` field `ponder.config.ts` was upgraded to support an object of network-specific overrides. This is a much better DX for indexing the same contract on multiple chains.
- The options that you can specify per-network are `address`, `event`, `startBlock`, `endBlock`, and `factory`.
- When you add a contract on multiple networks, Ponder will sync the contract on each network you specify. Any indexing functions you register for the contract will now process events across all networks.
- The `context.network` object is typed according to the networks that the current contract runs on, so you can write network-specific logic like `if (context.network.name === "optimism") { …`

#### Vite

- Ponder now uses Vite to transform and load your code. This means you can import files from outside the project root directory.
- Vite's module graph makes it possible to invalidate project files granularly, only reloading the specific parts of your app that need to be updated when a specific file changes. For example, if you save a change to one of your ABI files, `ponder.config.ts` will reload because it imports that file, but your schema will not reload.
- This update also unblocks a path towards concurrent indexing and granular caching of indexing function results.

## Config > Chains

# Chains [Configure chain IDs and RPC endpoints]

Use the `chains` field in `ponder.config.ts` to configure chain IDs and names, RPC endpoints, and connection options.

This guide describes each configuration option and suggests patterns for common use cases. Visit the config [API reference](#api-reference-ponder-config) for more information.

## Example

This config sets up two chains: Ethereum mainnet and Optimism.

```ts [ponder.config.ts]
import { createConfig } from "ponder";

export default createConfig({
  chains: {
    mainnet: {
      id: 1,
      rpc: process.env.PONDER_RPC_URL_1,
    },
    optimism: {
      id: 10,
      rpc: [process.env.PONDER_RPC_URL_10, "https://optimism.llamarpc.com"],
    },
  },
  contracts: {
    /* ... */
  },
});
```

## Name

Each chain must have a unique name, provided as a key to the `chains` object. The contract, account, and block interval `chain` options reference the chain name.

Within indexing functions, the `context.chain.name` property contains the chain name of the current event.

```ts [ponder.config.ts]
import { createConfig } from "ponder";

export default createConfig({
  chains: {
    mainnet: {
      // [!code focus]
      id: 1,
      rpc: process.env.PONDER_RPC_URL_1,
    },
  },
  contracts: {
    Blitmap: {
      abi: BlitmapAbi,
      chain: "mainnet", // [!code focus]
      address: "0x8d04a8c79cEB0889Bdd12acdF3Fa9D207eD3Ff63",
    },
  },
});
```

## Chain ID

Use the `id` field to specify a unique [Chain ID](https://chainlist.org) for each chain. Within indexing functions, the `context.chain.id` property contains the chain ID of the current event.

The indexing engine uses `id` in the cache key for RPC responses. To avoid cache issues, make sure `id` always matches the chain ID of the configured RPC endpoint.

```ts [ponder.config.ts]
import { createConfig } from "ponder";

export default createConfig({
  chains: {
    mainnet: {
      id: 1, // [!code focus]
      rpc: "https://eth.llamarpc.com",
    },
  },
  contracts: {
    /* ... */
  },
});
```

Note: Ponder does not support chain IDs greater than JavaScript's `Number.MAX_SAFE_INTEGER` (9007199254740991).

## RPC endpoints

Warning: Most Ponder apps require a paid RPC provider plan to avoid rate-limiting.
Use the `rpc` field to provide one or more RPC endpoints for each chain.

Ponder dynamically adapts to provider rate limits to avoid 429 errors and maximize performance. Providing multiple endpoints enables intelligent load balancing and fallback logic to improve reliability.

```ts [ponder.config.ts]
import { createConfig } from "ponder";

export default createConfig({
  chains: {
    mainnet: {
      id: 1,
      rpc: "https://eth-mainnet.g.alchemy.com/v2/...", // [!code focus]
    },
  },
  contracts: {
    /* ... */
  },
});
```

### Custom transport

The `rpc` field also accepts a [Viem Transport](https://viem.sh/docs/clients/intro#transports), which can be useful if you need more granular control over how RPC requests are made.

```ts [ponder.config.ts]
import { createConfig } from "ponder";
import { http, fallback } from "viem"; // [!code focus]

export default createConfig({
  chains: {
    mainnet: {
      id: 1,
      rpc: fallback([
        // [!code focus]
        http("https://eth-mainnet.g.alchemy.com/v2/..."), // [!code focus]
        http("https://quaint-large-card.quiknode.pro/..."), // [!code focus]
      ]), // [!code focus]
    },
  },
});
```

Here are a few common transport options.

- [`http`](https://viem.sh/docs/clients/transports/http)
- [`webSocket`](https://viem.sh/docs/clients/transports/websocket)
- [`fallback`](https://viem.sh/docs/clients/transports/fallback)
- [`loadBalance`](#api-reference-ponder-utils#loadbalance)
- [`rateLimit`](#api-reference-ponder-utils#ratelimit)

## WebSocket

Use the optional `ws` field to specify a WebSocket RPC endpoint for each chain.

When provided, Ponder will use WebSocket connections for realtime block subscriptions instead of polling. Websocket connections typically offer lower latency and reduced RPC usage.

Note: If the WebSocket connection becomes unstable or fails, Ponder automatically falls back to the default polling mechanism to ensure continuous indexing.

```ts [ponder.config.ts]
import { createConfig } from "ponder";

export default createConfig({
  chains: {
    mainnet: {
      id: 1,
      rpc: "https://eth-mainnet.g.alchemy.com/v2/...",
      ws: "wss://eth-mainnet.g.alchemy.com/v2/...", // [!code focus]
    },
  },
  contracts: {
    /* ... */
  },
});
```

## Polling interval

The `pollingInterval` option controls how frequently (in milliseconds) the indexing engine checks for a new block in realtime. The default is `1000` (1 second).

If you set `pollingInterval` greater than the chain's block time, it **does not reduce RPC usage**. The indexing engine still fetches every block to check for reorgs. The default is suitable for most chains.

```ts [ponder.config.ts]
import { createConfig } from "ponder";

export default createConfig({
  chains: {
    mainnet: {
      id: 1,
      rpc: process.env.PONDER_RPC_URL_1,
      pollingInterval: 2_000, // 2 seconds [!code focus]
    },
  },
});
```

## Disable caching

Use the `disableCache` option to disable caching for RPC responses. The default is `false`.

Set this option to `true` when indexing a development node like Anvil, where the chain state / history may change. [Read more](#guides-foundry) about indexing Anvil.

```ts [ponder.config.ts]
import { createConfig } from "ponder";

export default createConfig({
  chains: {
    anvil: {
      id: 31337,
      rpc: "http://127.0.0.1:8545",
      disableCache: true, // [!code focus]
    },
  },
});
```

## `eth_getLogs` block range

Ponder does its best to automatically determine the maximum block range for JSON-RPC requests with the `eth_getLogs` method. When this comes up short, you can set a manual limit with `ethGetLogsBlockRange` option.

```ts [ponder.config.ts]
import { createConfig } from "ponder";

export default createConfig({
  chains: {
    mainnet: {
      id: 1,
      rpc: "https://eth-mainnet.g.alchemy.com/v2/...",
      ethGetLogsBlockRange: 1000, // [!code focus]
    },
  },
});
```

## Config > Contracts

# Contracts [Index events emitted by a contract]

To index **event logs** or **call traces** produced by a contract, use the `contracts` field in `ponder.config.ts`.

This guide describes each configuration option and suggests patterns for common use cases. Visit the config [API reference](#api-reference-ponder-config) for more information.

## Example

This config instructs the indexing engine to fetch event logs emitted by the [Blitmap](https://blitmap.xyz/) NFT contract.

```ts [ponder.config.ts]
import { createConfig } from "ponder";
import { BlitmapAbi } from "./abis/Blitmap";

export default createConfig({
  chains: {
    mainnet: { id: 1, rpc: process.env.PONDER_RPC_URL_1 },
  },
  contracts: {
    Blitmap: {
      abi: BlitmapAbi,
      chain: "mainnet",
      address: "0x8d04a8c79cEB0889Bdd12acdF3Fa9D207eD3Ff63",
      startBlock: 12439123,
    },
  },
});
```

Now, we can register an indexing function for the `MetadataChanged` event that will be called for each event log. In this case, the indexing function inserts or updates a row in the `tokens` table.

```ts [src/index.ts]
import { ponder } from "ponder:registry";
import { tokens } from "ponder:schema";

ponder.on("Blitmap:MetadataChanged", async ({ event, context }) => {
  await context.db
    .insert(tokens)
    .values({
      id: event.args.tokenId,
      metadata: event.args.newMetadata,
    })
    .onConflictDoUpdate({
      metadata: event.args.newMetadata,
    });
});
```

[Read more](#indexing-overview) about writing indexing functions.

## Name

Each contract must have a unique name, provided as a key to the `contracts` object. Names must be unique across contracts, accounts, and block intervals.

```ts [ponder.config.ts]
import { createConfig } from "ponder";
import { BlitmapAbi } from "./abis/Blitmap";

export default createConfig({
  chains: {
    /* ... */
  },
  contracts: {
    Blitmap: {
      // [!code focus]
      abi: BlitmapAbi,
      chain: "mainnet",
      address: "0x8d04a8c79cEB0889Bdd12acdF3Fa9D207eD3Ff63",
    },
  },
});
```

## ABI

Each contract must have an ABI. The indexing engine uses the ABI to validate inputs and encode & decode contract data.

```ts [ponder.config.ts]
import { createConfig } from "ponder";
import { BlitmapAbi } from "./abis/Blitmap";

export default createConfig({
  chains: {
    mainnet: { id: 1, rpc: process.env.PONDER_RPC_URL_1 },
  },
  contracts: {
    Blitmap: {
      abi: BlitmapAbi,
      chain: "mainnet",
      address: "0x8d04a8c79cEB0889Bdd12acdF3Fa9D207eD3Ff63",
      startBlock:
    },
  },
});
```

To enable the type system, save all ABIs in `.ts` files and include an `as const{:ts}` assertion. Read more about these requirements in the [ABIType](https://abitype.dev/guide/getting-started#usage) documentation.

```ts [abis/Blitmap.ts]
export const BlitmapAbi = [
  // [!code focus]
  { inputs: [], stateMutability: "nonpayable", type: "constructor" },
  {
    inputs: [{ internalType: "address", name: "owner", type: "address" }],
    name: "balanceOf",
    outputs: [{ internalType: "uint256", name: "", type: "uint256" }],
    stateMutability: "view",
    type: "function",
  },
  // ...
] as const; // [!code focus]
```

### Multiple ABIs

Use the [`mergeAbis`](#api-reference-ponder-utils#mergeabis) utility function to combine multiple ABIs into one. This function removes duplicate ABI items and maintains strict types.

This pattern is often useful for proxy contracts where the implementation ABI has changed over time.

```ts [ponder.config.ts]
import { createConfig, mergeAbis } from "ponder"; // [!code focus]
import { ERC1967ProxyAbi } from "./abis/ERC1967Proxy";
import { NameRegistryAbi } from "./abis/NameRegistry";
import { NameRegistry2Abi } from "./abis/NameRegistry2";

export default createConfig({
  chains: {
    /* ... */
  },
  contracts: {
    FarcasterNameRegistry: {
      abi: mergeAbis([ERC1967ProxyAbi, NameRegistryAbi, NameRegistry2Abi]), // [!code focus]
      chain: "goerli",
      address: "0xe3Be01D99bAa8dB9905b33a3cA391238234B79D1",
    },
  },
});
```

## Chain

### Single chain

To index a contract on a single chain, pass the chain name as a string to the `chain` field.

```ts [ponder.config.ts]
import { createConfig } from "ponder";
import { BlitmapAbi } from "./abis/Blitmap";

export default createConfig({
  chains: {
    mainnet: { id: 1, rpc: process.env.PONDER_RPC_URL_1 }, // [!code focus]
  },
  contracts: {
    Blitmap: {
      abi: BlitmapAbi,
      chain: "mainnet", // [!code focus]
      address: "0x8d04a8c79cEB0889Bdd12acdF3Fa9D207eD3Ff63",
    },
  },
});
```

### Multiple chains

To index a contract that exists on multiple chains, pass an object to the `chain` field containing chain-specific overrides. Each contract specified this way _must_ have the same ABI.

```ts [ponder.config.ts]
import { createConfig } from "ponder";
import { UniswapV3FactoryAbi } from "./abis/UniswapV3Factory";

export default createConfig({
  chains: {
    mainnet: { id: 1, rpc: process.env.PONDER_RPC_URL_1 }, // [!code focus]
    base: { id: 8453, rpc: process.env.PONDER_RPC_URL_8453 }, // [!code focus]
  },
  contracts: {
    UniswapV3Factory: {
      abi: UniswapV3FactoryAbi,
      chain: {
        // [!code focus]
        mainnet: {
          // [!code focus]
          address: "0x1F98431c8aD98523631AE4a59f267346ea31F984", // [!code focus]
          startBlock: 12369621, // [!code focus]
        }, // [!code focus]
        base: {
          // [!code focus]
          address: "0x33128a8fC17869897dcE68Ed026d694621f6FDfD", // [!code focus]
          startBlock: 1371680, // [!code focus]
        }, // [!code focus]
      }, // [!code focus]
    },
  },
});
```

With this configuration, the indexing functions you register for the `UniswapV3Factory` contract will handle events from both Ethereum and Base.

To determine which chain the current event is from, use the `context.chain` object.

```ts [src/index.ts]
import { ponder } from "ponder:registry";

ponder.on("UniswapV3Factory:Ownership", async ({ event, context }) => {
  context.chain;
  //      ^? { name: "mainnet", id: 1 } | { name: "base", id: 8453 }

  event.log.address;
  //        ^? "0x1F98431c8aD98523631AE4a59f267346ea31F984" | "0x33128a8fC17869897dcE68Ed026d694621f6FDfD"

  if (context.chain.name === "mainnet") {
    // Do mainnet-specific stuff!
  }
});
```

#### Chain override logic

Chain-specific configuration uses an override pattern. Any options defined at the top level are the default, and the chain-specific objects override those defaults.

All contract options other than `abi` can be specified per-chain, including `address`, `startBlock`, and `endBlock`.

**Example: Uniswap V3**

The Uniswap V3 factory contract is deployed to the same address on most chains, but has a different address on Base. This configuration instructs Ponder to use the address defined at the top level (`"0x1F98..."`) for mainnet and Optimism, and the address defined in the `base` object for Base.

```ts [ponder.config.ts]
import { createConfig } from "ponder";
import { UniswapV3FactoryAbi } from "./abis/EntryPoint";

export default createConfig({
  chains: {
    mainnet: { id: 1, rpc: process.env.PONDER_RPC_URL_1 },
    optimism: { id: 10, rpc: process.env.PONDER_RPC_URL_10 },
    base: { id: 8453, rpc: process.env.PONDER_RPC_URL_8453 },
  },
  contracts: {
    UniswapV3Factory: {
      abi: UniswapV3FactoryAbi,
      address: "0x1F98431c8aD98523631AE4a59f267346ea31F984",
      chain: {
        // [!code focus]
        mainnet: { startBlock: 12369621 }, // [!code focus]
        optimism: { startBlock: 0 }, // [!code focus]
        base: {
          // [!code focus]
          address: "0x33128a8fC17869897dcE68Ed026d694621f6FDfD", // [!code focus]
          startBlock: 1371680, // [!code focus]
        }, // [!code focus]
      }, // [!code focus]
    },
  },
});
```

**Example: ERC-4337 EntryPoint**

The ERC-4337 EntryPoint contract is deployed to the same address on all chains. Only the `startBlock` needs to be specified per-chain.

```ts [ponder.config.ts]
import { createConfig } from "ponder";
import { EntryPointAbi } from "./abis/EntryPoint";

export default createConfig({
  chains: {
    mainnet: { id: 1, rpc: process.env.PONDER_RPC_URL_1 },
    optimism: { id: 10, rpc: process.env.PONDER_RPC_URL_10 },
  },
  contracts: {
    EntryPoint: {
      abi: EntryPointAbi,
      address: "0x1F98431c8aD98523631AE4a59f267346ea31F984",
      chain: {
        // [!code focus]
        mainnet: { startBlock: 12369621 }, // [!code focus]
        optimism: { startBlock: 88234528 }, // [!code focus]
      }, // [!code focus]
    },
  },
});
```

## Address

### Single address

The simplest and most common option is to pass a single static address.

```ts [ponder.config.ts]
import { createConfig } from "ponder";
import { BlitmapAbi } from "./abis/Blitmap";

export default createConfig({
  chains: {
    /* ... */
  },
  contracts: {
    Blitmap: {
      abi: BlitmapAbi,
      chain: "mainnet",
      address: "0x8d04a8c79cEB0889Bdd12acdF3Fa9D207eD3Ff63", // [!code focus]
    },
  },
});
```

### Multiple addresses

To index multiple contracts that have the same ABI (or share an interface like `ERC20`), pass a list of addresses to the `address` field.

Note: With this configuration, all addresses share the same `startBlock`. It's
often best to use the earliest deployment block among them.

```ts [ponder.config.ts]
import { createConfig } from "ponder";
import { ERC721Abi } from "./abis/ERC721";

export default createConfig({
  chains: {
    /* ... */
  },
  contracts: {
    NiceJpegs: {
      abi: ERC721Abi,
      chain: "mainnet",
      address: [
        // [!code focus]
        "0x4E1f41613c9084FdB9E34E11fAE9412427480e56", // Terraforms // [!code focus]
        "0xBC4CA0EdA7647A8aB7C2061c2E118A18a936f13D", // BAYC // [!code focus]
        "0x8a90CAb2b38dba80c64b7734e58Ee1dB38B8992e", // Doodles // [!code focus]
        "0x0000000000664ceffed39244a8312bD895470803", // !fundrop // [!code focus]
      ], // [!code focus]
    },
  },
});
```

### Factory pattern

Note: Visit the [factory pattern](#guides-factory) guide for more information.
Use the `factory()` function to specify a dynamic list of addresses collected from a factory contract.

Any indexing functions you register for `SudoswapPool` receive events for all contracts matched by the factory configuration (similar to a multiple chain configuration). The `event.log.address` field contains the address of the specific contract that emitted the current event.

```ts [ponder.config.ts]
import { createConfig, factory } from "ponder"; // [!code focus]
import { parseAbiItem } from "viem";

export default createConfig({
  chains: {
    /* ... */
  },
  contracts: {
    SudoswapPool: {
      abi: SudoswapPoolAbi,
      chain: "mainnet",
      address: factory({
        // [!code focus]
        // Address of the factory contract. // [!code focus]
        address: "0xb16c1342E617A5B6E4b631EB114483FDB289c0A4", // [!code focus]
        // Event from the factory contract ABI which contains the child address. // [!code focus]
        event: parseAbiItem("event NewPair(address poolAddress)"), // [!code focus]
        // Name of the event parameter containing the child address. // [!code focus]
        parameter: "poolAddress", // [!code focus]
      }), // [!code focus]
      startBlock: 14645816,
    },
  },
});
```

```ts [src/index.ts]
import { ponder } from "ponder:registry";

ponder.on("SudoswapPool:Transfer", async ({ event }) => {
  // The address of the child contract that emitted the event.
  event.log.address;
  //        ^? string
});
```

### Proxy & upgradable contracts

To index a proxy/upgradable contract, use the proxy contract address in the `address` field. Then, be sure to include the ABIs of all implementation contracts that the proxy has ever had. The implementation ABIs are required to properly identify and decode all event logs throughout the contract history. To add multiple ABIs safely, use the [`mergeAbis`](#api-reference-ponder-utils#mergeabis) utility function.

Note: On Etherscan, there is a link to the current implementation contract on the **Contract → Read as Proxy** tab. You can copy all the implementation ABIs as text and paste them into `.ts` files.
![Etherscan contract proxy address](/etherscan-proxy-contract.png)

## Block range

Use the `startBlock` and `endBlock` options to specify the block range to index.

```ts [ponder.config.ts]
import { createConfig } from "ponder";
import { BlitmapAbi } from "./abis/Blitmap";

export default createConfig({
  chains: {
    /* ... */
  },
  contracts: {
    Blitmap: {
      abi: BlitmapAbi,
      chain: "mainnet",
      address: "0x8d04a8c79cEB0889Bdd12acdF3Fa9D207eD3Ff63",
      startBlock: 16500000, // [!code focus]
      endBlock: 16501000, // [!code focus]
    },
  },
});
```

### Start block

The `startBlock` option specifies the block number to begin indexing from. The default is `0` – to avoid wasteful RPC requests, set `startBlock` to the contract deployment block number.

If you set `startBlock` to `"latest"`, the indexing engine will fetch the latest block on startup and use that value. This is the best way to skip the backfill and only index live blocks.

### End block

The `endBlock` option specifies the block number to stop indexing at. The default is `undefined`, which means that indexing will continue indefinitely with live blocks.

If you set `endBlock` to `"latest"`, the indexing engine will fetch the latest block on startup and use that value.

Note: To speed up hot reloads during development, you can use `endBlock` to index a small slice of history.

## Filter by indexed parameter value

Warning: You do **not** need to keep `filter` in sync with your indexing function registrations; the build step does this automatically. Most apps should not use `filter`.
Sometimes, it's useful to filter for event logs that match specific [indexed parameter](https://docs.soliditylang.org/en/latest/contracts.html#events) values (topics).

This example filters for all `Transfer` events emitted by the USDC contract where the `from` argument matches the Binance 14 exchange address.

```ts [ponder.config.ts]
import { createConfig } from "ponder";
import { ERC20Abi } from "./abis/ERC20";

export default createConfig({
  chains: {
    /* ... */
  },
  contracts: {
    USDC: {
      abi: ERC20Abi,
      chain: "mainnet",
      address: "0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48", // USDC
      filter: {
        // [!code focus]
        event: "Transfer", // [!code focus]
        args: {
          // [!code focus]
          from: "0x28c6c06298d514db089934071355e5743bf21d60", // Binance 14 // [!code focus]
        }, // [!code focus]
      }, // [!code focus]
    },
  },
});
```

```ts [src/index.ts]
import { ponder } from "ponder:registry";

ponder.on("USDC:Transfer", async ({ event }) => {
  // This will always be "0x28c6c06298d514db089934071355e5743bf21d60"
  event.args.from;
});
```

Note that the `filter` option accepts an array of filter configurations and that each field in the `args` object accepts a single value or a list of values to match.

## Call traces

Note: Visit the [call traces](#guides-call-traces) guide for more information.
Use the `includeCallTraces` option to enable call trace indexing for a contract, which makes it possible to register indexing functions for every _function_ present in the contract ABI.

Call traces are **disabled** by default.

```ts [ponder.config.ts]
import { createConfig } from "ponder";
import { BlitmapAbi } from "./abis/Blitmap";

export default createConfig({
  chains: {
    /* ... */
  },
  contracts: {
    Blitmap: {
      abi: BlitmapAbi,
      chain: "mainnet",
      address: "0x8d04a8c79cEB0889Bdd12acdF3Fa9D207eD3Ff63",
      includeCallTraces: true, // [!code focus]
    },
  },
});
```

```ts [src/index.ts]
import { ponder } from "ponder:registry";

ponder.on("Blitmap.mintOriginal()", async ({ event }) => {
  event.args;
  //    ^? [tokenData: Hex, name: string]
  event.trace.gasUsed;
  //          ^? bigint
});
```

## Transaction receipts

Note: Visit the [transaction receipts](#guides-receipts) guide for more information.
Use the `includeTransactionReceipts` option to fetch the transaction receipt for each event. This will make the `event.transactionReceipt` object available in all indexing functions for the contract.

Transaction receipts are **disabled** by default.

```ts [ponder.config.ts]
import { createConfig } from "ponder";
import { BlitmapAbi } from "./abis/Blitmap";

export default createConfig({
  chains: {
    /* ... */
  },
  contracts: {
    Blitmap: {
      abi: BlitmapAbi,
      chain: "mainnet",
      address: "0x8d04a8c79cEB0889Bdd12acdF3Fa9D207eD3Ff63",
      includeTransactionReceipts: true, // [!code focus]
    },
  },
});
```

```ts [src/index.ts]
import { ponder } from "ponder:registry";

ponder.on("Blitmap.mintOriginal()", async ({ event }) => {
  event.transactionReceipt.cumulativeGasUsed;
  //                       ^? bigint
  event.transactionReceipt.logs;
  //                       ^? Log[]
});
```

## Config > Accounts

# Accounts [Index transactions and native transfers]

To index **transactions** or **native transfers** sent to (or from) an address, use the `accounts` field in `ponder.config.ts`.

This guide describes each configuration option and suggests patterns for common use cases. Visit the config [API reference](#api-reference-ponder-config) for more information.

Warning: The RPC methods that power account indexing (`eth_getBlockByNumber`, `debug_traceBlockByNumber`) do not support filtering the way `eth_getLogs` does. Large backfills may consume an impractical amount of RPC credits.

## Example

This config instructs the indexing engine to fetch transactions or native transfers sent by the [Beaver](https://beaverbuild.org/) block builder account.

```ts [ponder.config.ts]
import { createConfig } from "ponder";

export default createConfig({
  chains: {
    mainnet: { id: 1, rpc: process.env.PONDER_RPC_URL_1 },
  },
  accounts: {
    // [!code focus]
    BeaverBuild: {
      // [!code focus]
      chain: "mainnet", // [!code focus]
      address: "0x95222290DD7278Aa3Ddd389Cc1E1d165CC4BAfe5", // [!code focus]
      startBlock: 20000000, // [!code focus]
    }, // [!code focus]
  }, // [!code focus]
});
```

Now, we can register an indexing function for the `transaction:from` event. The indexing engine will fetch all transactions where `from` matches the specified address, then call the indexing function for each transaction.

```ts [src/index.ts]
import { ponder } from "ponder:registry";
import { deposits } from "ponder:schema";

ponder.on("BeaverBuild:transaction:from", async ({ event, context }) => {
  // [!code focus]
  await context.db.insert(deposits).values({
    from: event.transaction.from,
    to: event.transaction.to,
    value: event.transaction.value,
    input: event.transaction.input,
  });
});
```

You can also register indexing functions for the `transaction:to`, `transfer:from`, and `transfer:to` events. [Read more](#api-reference-ponder-config#accounts) about event types.

Note: The indexing engine only fetches data required for _registered_ indexing functions. In this example, native transfers will **not** be fetched because no indexing functions were registered for `transfer:from` and `transfer:to`.

## Name

Every account must have a unique name, provided as a key to the `accounts` object. Names must be unique across accounts, contracts, and block intervals.

```ts [ponder.config.ts]
import { createConfig } from "ponder";

export default createConfig({
  chains: {
    /* ... */
  },
  accounts: {
    BeaverBuild: {
      // [!code focus]
      chain: "mainnet",
      address: "0x95222290DD7278Aa3Ddd389Cc1E1d165CC4BAfe5",
      startBlock: 12439123,
    },
  },
});
```

## Chain

The `chain` option for accounts works the same way as it does for contracts. You can specify a different `address`, `startBlock`, and `endBlock` for each chain.

[Read more](#config-contracts#chain) in the contracts guide.

## Address

The `address` option for accounts works the same way as it does for contracts. You can provide a single address, a list of addresses, or an address factory. You can also specify chain-specific overrides.

[Read more](#config-contracts#address) in the contracts guide.

## Block range

The `startBlock` and `endBlock` options for accounts work the same way as it does for contracts.

[Read more](#config-contracts#block-range) in the contracts guide.

## Transaction receipts

The `includeTransactionReceipts` option for accounts works the same way as it does for contracts.

[Read more](#config-contracts#transaction-receipts) in the contracts guide.

## Config > Block Intervals

import { Callout } from "vocs/components";

# Block intervals [Run logic on a regular schedule]

To run indexing logic on a **regular schedule**, use the `blocks` field in `ponder.config.ts`. Block intervals are useful for aggregations, time-series logic, and bulk updates using raw SQL.

This guide describes each configuration option and suggests patterns for common use cases. Visit the config [API reference](#api-reference-ponder-config) for more information.

## Example

This config instructs the indexing engine to run an indexing function every 10 blocks starting at the start block – `1000`, `1010`, `1020`, and so on.

```ts [ponder.config.ts]
import { createConfig } from "ponder";

export default createConfig({
  chains: {
    mainnet: { id: 1, rpc: process.env.PONDER_RPC_URL_1 },
  },
  blocks: {
    ChainlinkOracleUpdate: {
      chain: "mainnet",
      interval: 10, // Every 10 blocks
      startBlock: 1000,
    },
  },
});
```

Now, we can register an indexing function for the `ChainlinkOracleUpdate:block` event. This example reads the latest price from the Chainlink oracle contract and inserts a row into the `priceTimeline` table.

```ts [src/index.ts]
import { ponder } from "ponder:registry";
import { priceTimeline } from "ponder:schema";
import { ChainlinkOracleAbi } from "../abis/ChainlinkOracle.ts";

ponder.on("ChainlinkOracleUpdate:block", async ({ event, context }) => {
  // Fetch the price at the current block height (1000, 1010, 1020, etc.)
  const latestPrice = await context.client.readContract({
    abi: ChainlinkOracleAbi,
    address: "0xD10aBbC76679a20055E167BB80A24ac851b37056",
    functionName: "latestAnswer",
  });

  // Insert a row into the price timeline table
  await context.db.insert(priceTimeline).values({
    id: event.id,
    timestamp: event.block.timestamp,
    price: latestPrice,
  });
});
```

## Name

Every block interval must have a name, provided as a key to the `blocks` object. The name must be unique across `blocks`, `contracts`, and `accounts`.

Use a descriptive name to indicate the purpose of the block interval.

```ts [ponder.config.ts]
import { createConfig } from "ponder";

export default createConfig({
  chains: {
    /* ... */
  },
  blocks: {
    ChainlinkOracleUpdate: {
      // [!code focus]
      chain: "mainnet",
      interval: 10,
      startBlock: 19783636,
    },
  },
});
```

## Interval

Use the `interval` option to specify how often the indexing function should run. A block interval with a start block of `100` and an interval of `10` will index blocks `100`, `110`, `120`, `130`, and so on.

### Block time

It's often easier to think about a _time_ interval instead of a _block_ interval. To convert between the two, divide the time interval by the chain's average block time.

For example, if the block time is 3 seconds and you want to run an indexing function once per day:

```ts
// 24 hours per day, 60 minutes per hour, 60 seconds per minute
const secondsInterval = 24 * 60 * 60;
// 3 seconds per block
const blockTime = 3;
// 28800 blocks per day
const blockInterval = secondsInterval / blockTime;
```

To find the block time of a specific chain, check the chain's documentation website or block explorer. Most Etherscan deployments have a [`/chart/blocktime`](https://polygonscan.com/chart/blocktime) page.

## Chain

The `chain` option for block intervals works the same way as it does for contracts. You can specify a different `interval`, `startBlock` and `endBlock` for each chain.

```ts [ponder.config.ts]
import { createConfig } from "ponder";

export default createConfig({
  chains: {
    /* ... */
  },
  blocks: {
    PointsAggregation: {
      chain: {
        mainnet: {
          startBlock: 19783636, // [!code focus]
          interval: (60 * 60) / 12, // Every 60 minutes (12s block time) // [!code focus]
        },
        optimism: {
          startBlock: 119534316, // [!code focus]
          interval: (60 * 60) / 2, // Every 60 minutes (2s block time) // [!code focus]
        },
      },
    },
  },
});
```

[Read more](#config-contracts#chain) in the contracts guide.

## Block range

The `startBlock` and `endBlock` options for block intervals work the same way as they do for contracts.

[Read more](#config-contracts#block-range) in the contracts guide.

## Schema > Tables

# Tables [Define database tables and columns]

Ponder's schema definition API is built on [Drizzle](https://orm.drizzle.team/), a modern TypeScript ORM. To define a table, use the `onchainTable` function and include column definitions.

```ts [ponder.schema.ts]
import { onchainTable } from "ponder";

export const pets = onchainTable("pets", (t) => ({
  name: t.text().primaryKey(),
  age: t.integer().notNull(),
}));
```

Each table _must_ be a named export from the `ponder.schema.ts` file. The build step ignores tables that are not exported.

## Column types

The schema definition API supports most PostgreSQL data types – here's a quick reference for the most common options. Read the [Drizzle documentation](https://orm.drizzle.team/docs/column-types/pg) for a complete list.

| name             | description                        | TypeScript type          | SQL data type     |
| :--------------- | :--------------------------------- | :----------------------- | :---------------- |
| `text{:ts}`      | UTF‐8 character sequence           | `string`                 | `TEXT{:sql}`      |
| `integer{:ts}`   | Signed 4‐byte integer              | `number`                 | `INTEGER{:sql}`   |
| `real{:ts}`      | Signed 4-byte floating‐point value | `number`                 | `REAL{:sql}`      |
| `boolean{:ts}`   | `true` or `false`                  | `boolean`                | `BOOLEAN{:sql}`   |
| `timestamp{:ts}` | Date and time value (no time zone) | `Date`                   | `TIMESTAMP{:sql}` |
| `json{:ts}`      | JSON object                        | `any` or [custom](#json) | `JSON{:sql}`      |

Ponder also includes a few extra column types built specifically for EVM indexing.

| name          | description                                  | TypeScript type | SQL data type         |
| :------------ | :------------------------------------------- | :-------------- | :-------------------- |
| `bigint{:ts}` | Large integer (holds `uint256` and `int256`) | `bigint`        | `NUMERIC(78,0){:sql}` |
| `hex{:ts}`    | UTF‐8 character sequence with `0x` prefix    | `0x${string}`   | `TEXT{:sql}`          |

### `bigint`

Use the `bigint` column type to store EVM `uint256` or `int256` values.

```ts [ponder.schema.ts]
import { onchainTable } from "ponder";

export const accounts = onchainTable("accounts", (t) => ({
  address: t.hex().primaryKey(),
  balance: t.bigint().notNull(), // [!code focus]
}));
```

Note: Ponder's `bigint` type takes precedence over the Drizzle
[`bigint`](https://orm.drizzle.team/docs/column-types/pg#bigint) type, which
is an 8-byte integer (too small for EVM integer values). To
create an 8-byte integer column, use the `int8` alias.

### `hex`

Use the `hex` column type to store EVM `address`, `bytes`, or any other hex-encoded value.

```ts [ponder.schema.ts]
import { onchainTable } from "ponder";

export const accounts = onchainTable("accounts", (t) => ({
  address: t.hex().primaryKey(), // [!code focus]
  balance: t.bigint().notNull(),
}));
```

## Enums

To define an enum, use the `onchainEnum` function. Then, use the value returned by `onchainEnum` as a column type. Under the hood, `onchainEnum` creates a PostgreSQL [enumerated type](https://www.postgresql.org/docs/current/datatype-enum.html).

```ts [ponder.schema.ts]
import { onchainEnum, onchainTable } from "ponder"; // [!code focus]

export const color = onchainEnum("color", ["ORANGE", "BLACK"]); // [!code focus]

export const cats = onchainTable("cats", (t) => ({
  name: t.text().primaryKey(),
  color: color("color"), // [!code focus]
}));
```

## Arrays

To define an array column, use the `.array(){:ts}` modifier. Arrays are a good fit for small one-dimensional collections. Don't use arrays for [relationships](#schema-relations) between records.

```ts [ponder.schema.ts]
import { onchainTable } from "ponder";

export const cats = onchainTable("cats", (t) => ({
  name: t.text().primaryKey(),
  vaccinations: t.text().array(), // ["rabies", "distemper", "parvo"] // [!code focus]
}));
```

## Not null

To mark a column as not null, use the `.notNull(){:ts}` modifier. If you attempt to insert a row that does not include a value for a `NOT NULL{:sql}` column, the database will throw an error.

```ts [ponder.schema.ts]
import { onchainTable } from "ponder";

export const cats = onchainTable("cats", (t) => ({
  name: t.text().primaryKey(),
  age: t.integer().notNull(), // [!code focus]
}));
```

## Default value

To set a default value for a column, use the `.default(){:ts}` modifier and pass a string, number, boolean, or `null`.

```ts [ponder.schema.ts]
import { onchainTable } from "ponder";

export const cats = onchainTable("cats", (t) => ({
  name: t.text().primaryKey(),
  livesRemaining: t.integer().default(9), // [!code focus]
}));
```

Alternatively, use the `.$default(){:ts}` modifier to specify a JavaScript function that returns the default value. With this approach, the database driver calls the function to generate a default value for each row dynamically.

```ts [ponder.schema.ts]
import { onchainTable } from "ponder";
import { generateId } from "../utils"; // [!code focus]

export const cats = onchainTable("cats", (t) => ({
  name: t.text().primaryKey(),
  age: t.integer().$default(() => generateId()), // [!code focus]
}));
```

## Primary key

Every table **must** have a primary key. To define a primary key on a single column, use the `.primaryKey(){:ts}` modifier.

```ts [ponder.schema.ts]
import { onchainTable } from "ponder";

export const tokens = onchainTable("tokens", (t) => ({
  id: t.bigint().primaryKey(), // [!code focus]
}));
```

### Composite primary key

To create a composite primary key, use the `primaryKey()` function exported by `ponder`. Each column that forms the primary key must be not null. [Read more](https://www.postgresql.org/docs/current/ddl-constraints.html#DDL-CONSTRAINTS-PRIMARY-KEYS) about composite primary keys.

```ts [ponder.schema.ts]
import { onchainTable, primaryKey } from "ponder"; // [!code focus]

export const poolStates = onchainTable(
  "pool_states",
  (t) => ({
    poolId: t.bigint().notNull(),
    address: t.hex().notNull(),
    balance: t.bigint().notNull(),
  }),
  (table) => ({
    // [!code focus]
    pk: primaryKey({ columns: [table.poolId, table.address] }), // [!code focus]
  }) // [!code focus]
);
```

## Indexes

To create a database index, use the `index(){:ts}` function. This example defines B-tree indexes on the `persons.name` column to support search queries, and on the `dogs.ownerId` column to support the `persons.dogs` relational query.

```ts [ponder.schema.ts]
import { onchainTable, relations, index } from "ponder";

export const persons = onchainTable(
  "persons",
  (t) => ({
    id: t.text().primaryKey(),
    name: t.text(),
  }),
  (table) => ({
    nameIdx: index().on(table.name),
  })
);

export const personsRelations = relations(persons, ({ many }) => ({
  dogs: many(dogs),
}));

export const dogs = onchainTable(
  "dogs",
  (t) => ({
    id: t.text().primaryKey(),
    ownerId: t.text().notNull(),
  }),
  (table) => ({
    ownerIdx: index().on(table.ownerId),
  })
);

export const dogsRelations = relations(dogs, ({ one }) => ({
  owner: one(persons, { fields: [dogs.ownerId], references: [persons.id] }),
}));
```

The `index(){:ts}` function supports specifying multiple columns, ordering, and custom index types like GIN and GIST. Read more in the [Drizzle](https://orm.drizzle.team/docs/indexes-constraints#indexes) and [PostgreSQL](https://www.postgresql.org/docs/current/indexes.html) documentation.

Note: To improve performance, the indexing engine creates database indexes _after_ the backfill is complete, just before the app becomes healthy.

## Best practices

### Primary keys

Select a primary key that matches the access pattern of your indexing logic. If a table has two or more columns that together form a unique identifier for a row, use a composite primary key – don't use a concatenated string.

```ts [ponder.schema.ts]
import { onchainTable, primaryKey } from "ponder";

// ❌ Don't concatenate strings to form a primary key  [!code focus]
export const allowances = onchainTable("allowances", (t) => ({
  id: t.string().primaryKey(), // `${owner}_${spender}` // [!code focus]
  owner: t.hex(),
  spender: t.hex(),
  amount: t.bigint(),
}));

// ✅ Use a composite primary key  // [!code focus]
export const allowances = onchainTable(
  "allowances",
  (t) => ({
    owner: t.hex(),
    spender: t.hex(),
    amount: t.bigint(),
  }),
  (table) => ({ pk: primaryKey({ columns: [table.owner, table.spender] }) }) // [!code focus]
);
```

### Timestamps

Use the `bigint` column type to store block timestamps using their EVM-native Unix timestamp representation. This maintains consistency with Viem's approach, and avoids error-prone timezone manipulation code.

```ts [ponder.schema.ts]
import { onchainTable } from "ponder";

export const events = onchainTable("events", (t) => ({
  id: t.text().primaryKey(),
  timestamp: t.bigint(), // Unix timestamp in seconds [!code focus]
}));
```

If you strongly prefer working with JavaScript `Date` objects, you can also use the `timestamp` column type, but we recommend doing this conversion in the view layer.

```ts [ponder.schema.ts]
import { onchainTable } from "ponder";

export const events = onchainTable("events", (t) => ({
  id: t.text().primaryKey(),
  timestamp: t.timestamp(), // JavaScript Date object [!code focus]
}));
```

### Custom types

Use the `.$type()` modifier to customize the TypeScript type for a column. Note that the `.$type()` modifier does not validate data at runtime or in the database, it only enforces a TypeScript type.

```ts [ponder.schema.ts]
import { onchainTable } from "ponder";

export const tokens = onchainTable("tokens", (t) => ({
  id: t.bigint().primaryKey(),
  metadata: t
    .json()
    .$type<{ name: string; symbol: string; decimals: number }>(), // [!code focus]
}));
```

### `camelCase` vs `snake_case`

Use `camelCase` for TypeScript names and `snake_case` for SQL names. This guideline applies to all database objects and properties, including tables, columns, relations, and indexes.

```ts [ponder.schema.ts]
import { onchainTable } from "ponder";

export const registrationEvents = onchainTable(
  "registration_events", // Use snake_case for the SQL table name
  (t) => ({
    createdAt: t.bigint(), // Drizzle automatically converts this to `created_at`
    invitedBy: t.text("invited_by"), // Avoid manual case conversion for columns
    // ...
  })
);
```

## Examples

### ERC20

Here's a schema for a simple ERC20 app.

```ts [ponder.schema.ts]
import { index, onchainTable, primaryKey } from "ponder";

export const account = onchainTable("account", (t) => ({
  address: t.hex().primaryKey(),
  balance: t.bigint().notNull(),
  isOwner: t.boolean().notNull(),
}));

export const allowance = onchainTable(
  "allowance",
  (t) => ({
    owner: t.hex(),
    spender: t.hex(),
    amount: t.bigint().notNull(),
  }),
  (table) => ({
    pk: primaryKey({ columns: [table.owner, table.spender] }),
  })
);

export const transferEvent = onchainTable(
  "transfer_event",
  (t) => ({
    id: t.text().primaryKey(),
    amount: t.bigint().notNull(),
    timestamp: t.integer().notNull(),
    from: t.hex().notNull(),
    to: t.hex().notNull(),
  }),
  (table) => ({
    fromIdx: index().on(table.from),
  })
);

export const approvalEvent = onchainTable("approval_event", (t) => ({
  id: t.text().primaryKey(),
  amount: t.bigint().notNull(),
  timestamp: t.integer().notNull(),
  owner: t.hex().notNull(),
  spender: t.hex().notNull(),
}));
```

## Schema > Relations

# Relations [Define relationships between database tables]

Ponder uses [Drizzle Relations](https://orm.drizzle.team/docs/relations) to define relationships between tables. This guide describes each kind of relationship and how to use them.

Note: Relations _only_ enrich the GraphQL API and Drizzle Query API (`findMany` and `findFirst`). They **do not** create foreign key constraints, and won't stop you from inserting rows that violate referential integrity.

## One-to-one

Use the `relations` function exported by `ponder` to define the relationships for a table.

To define a one-to-one relationship, use the `one()` operator and specify which columns relate the two tables. In this example, each user has a profile and each profile belongs to one user.

```ts [ponder.schema.ts]
import { onchainTable, relations } from "ponder"; // [!code focus]

export const users = onchainTable("users", (t) => ({
  id: t.text().primaryKey(),
}));

export const usersRelations = relations(users, ({ one }) => ({
  // [!code focus]
  profile: one(profiles, { fields: [users.id], references: [profiles.userId] }), // [!code focus]
})); // [!code focus]

export const profiles = onchainTable("profiles", (t) => ({
  id: t.text().primaryKey(),
  userId: t.text().notNull(),
  age: t.integer().notNull(),
}));
```

Now that you've defined the relationship, the `profile` field will become available in the Query API (`findMany` and `findFirst`) using the `with` option.

```ts [src/index.ts]
import { users, profiles } from "ponder:schema";

await db.insert(users).values({ id: "hunter42" });
await db.insert(profiles).values({ userId: "hunter42", age: 29 });

const user = await db.sql.query.users.findFirst({
  where: eq(users.id, "hunter42"),
  with: { profile: true },
});

console.log(user.profile.age);
//          ^? { id: string; profile: { id: string; userId: string; age: number } }
```

## One-to-many

To define a one-to-many relationship, use the `one()` and `many()` operators to define both sides of the relationship. In this example, each dog has one owner and each person can own many dogs.

```ts [ponder.schema.ts]
import { onchainTable, relations } from "ponder"; // [!code focus]

export const persons = onchainTable("persons", (t) => ({
  name: t.text().primaryKey(),
}));

export const personsRelations = relations(persons, ({ many }) => ({
  // [!code focus]
  dogs: many(dogs), // [!code focus]
})); // [!code focus]

export const dogs = onchainTable("dogs", (t) => ({
  petId: t.text().primaryKey(),
  ownerName: t.text().notNull(),
}));

export const dogsRelations = relations(dogs, ({ one }) => ({
  // [!code focus]
  owner: one(persons, { fields: [dogs.ownerName], references: [persons.name] }), // [!code focus]
})); // [!code focus]
```

Now, any row inserted into the `dogs` table with `ownerName: "Bob"` will become available in Bob's `dogs` field.

```ts [src/index.ts]
import { persons, dogs } from "ponder:schema";

await db.insert(persons).values({ name: "Bob" });
await db.insert(dogs).values([
  { petId: "Chip", ownerName: "Bob" },
  { petId: "Spike", ownerName: "Bob" },
]);

const bob = await db.sql.query.persons.findFirst({
  where: eq(persons.id, "Bob"),
  with: { dogs: true },
});

console.log(bob.dogs);
//          ^? { name: string; dogs: { petId: string; age: number }[] }
```

Note: Note that in a one-to-many relationship, you cannot directly set the value of
the `many` field. Instead, you must insert or update the related rows
individually.

## Many-to-many

To define a many-to-many relationship, create a "join table" that relates the two tables you want to connect using two one-to-many relationships.

```ts [ponder.schema.ts]
import { onchainTable, relations, primaryKey } from "ponder";

export const users = onchainTable("users", (t) => ({
  id: t.text().primaryKey(),
}));

export const usersRelations = relations(users, ({ many }) => ({
  userTeams: many(userTeams),
}));

export const teams = onchainTable("teams", (t) => ({
  id: t.text().primaryKey(),
  mascot: t.text().notNull(),
}));

export const teamsRelations = relations(teams, ({ many }) => ({
  userTeams: many(userTeams),
}));

export const userTeams = onchainTable(
  "user_teams",
  (t) => ({
    userId: t.text().notNull(),
    teamId: t.text().notNull(),
  }),
  // A composite primary key is often a good choice for a join table.
  (table) => ({ pk: primaryKey({ columns: [table.userId, table.teamId] }) })
);

export const userTeamsRelations = relations(userTeams, ({ one }) => ({
  user: one(users, { fields: [userTeams.userId], references: [users.id] }),
  team: one(teams, { fields: [userTeams.teamId], references: [teams.id] }),
}));
```

Each row in the `userTeams` table represents a relationship between a `user` and `team` row. You can query for the relationship by nesting the `with` option in the Query API.

```ts [src/index.ts]
import { users, teams, userTeams } from "ponder:schema";

await db
  .insert(users)
  .values([{ id: "ron" }, { id: "harry" }, { id: "hermione" }]);
await db.insert(teams).values([
  { id: "muggle", mascot: "dudley" },
  { id: "wizard", mascot: "hagrid" },
]);
await db.insert(userTeams).values([
  { userId: "ron", teamId: "wizard" },
  { userId: "harry", teamId: "wizard" },
  { userId: "hermione", teamId: "muggle" },
  { userId: "hermione", teamId: "wizard" },
]);

const hermione = await db.sql.query.users.findFirst({
  where: eq(users.id, "hermione"),
  with: { userTeams: { with: { team: true } } },
});

console.log(hermione.userTeams);
//          ^? {
//            id: string;
//            userTeams: {
//              userId: string;
//              teamId: string;
//              team: {
//                id: string;
//                mascot: string
//              }
//            }[]
//          }
```

## GraphQL API

Every relationship you define in `ponder.schema.ts` automatically becomes available in the GraphQL API, with `one` relations creating singular fields and `many` relations creating plural/connection fields.

The [one-to-many example](#one-to-many) above corresponds to the following GraphQL query and result.

<div className="code-columns">

```graphql [Query]
query {
  person(id: "Bob") {
    id
    dogs {
      id
    }
  }
}
```

```json [Result]
{
  "person": {
    "id": "Bob",
    "dogs": [{ "id": "Chip" }, { "id": "Spike" }]
  }
}
```

</div>

## Schema > Views

# Custom views [Define custom database views over onchain data]

Ponder supports custom [PostgreSQL views](https://www.postgresql.org/docs/current/tutorial-views.html) defined using Drizzle.

Note: Custom views are not to be confused with the **views schema** pattern, an advanced feature that enables direct SQL queries. [Read more](#production-self-hosting#views-pattern) about the views schema pattern in the self-hosting guide.

## Usage

To define a view, use the `onchainView` function and write a query using Drizzle that references other tables or views in `ponder.schema.ts`.

```ts [ponder.schema.ts]
import { onchainTable, onchainView, count } from "ponder";

export const pets = onchainTable("pets", (t) => ({
  id: t.text().primaryKey(),
  name: t.text().notNull(),
  owner: t.text().notNull(),
}));

export const petLeaderboard = onchainView("pet_leaderboard").as((qb) =>
  qb
    .select({
      ownerName: pets.owner,
      petCount: count().as("pet_count"),
    })
    .from(pets)
    .groupBy(pets.owner)
);
```

Each view _must_ be a named export from the `ponder.schema.ts` file. The build step ignores views that are not exported.

## When to use custom views

Custom views are particularly useful in two common scenarios.

1. **Customize the GraphQL API**. With views, you can add custom fields to the GraphQL API without adding and populating an entire table.
2. **Move data processing from indexing-time to query-time**. By moving transformation logic to the query layer, views can simplify the project as a whole and help speed up lengthy backfills.

## Limitations

Custom views do not have a primary key constraint, which leads to several important limitations.

1. **Store API disabled**. The indexing function store API cannot access custom views. However, you can query custom views within indexing functions using raw SQL.
2. **No GraphQL singular query fields**. The GraphQL API does not include singular query fields for custom views.
3. **No GraphQL cursor pagination**. The GraphQL API includes plural query fields for custom views that support offset pagination, but do not support cursor pagination.

## Performance

Custom views are a useful tool to simplify indexing logic and provide a richer schema, but they are not magic. Each query against a custom view re-executes the stored `SELECT` statement.

To avoid performance issues, be sure to check the query plan for each custom view query and add database indexes on the underlying tables as appropriate.

## Examples

Here's an example of an `hourlyBucket` view from an ERC20 indexer which uses a `GROUP BY` query to aggregate transfer volumes over a time interval.

```ts [ponder.schema.ts]
import { onchainTable, onchainView, index, sql, sum, count } from "ponder";

export const transferEvent = onchainTable("transfer_event", (t) => ({
  id: t.text().primaryKey(),
  amount: t.bigint().notNull(),
  timestamp: t.integer().notNull(),
  from: t.hex().notNull(),
  to: t.hex().notNull(),
}));

export const hourlyBucket = onchainView("hourly_bucket").as((qb) =>
  qb
    .select({
      hour: sql`FLOOR(${transferEvent.timestamp} / 3600) * 3600`.as("hour"),
      totalVolume: sum(transferEvent.amount).as("total_volume"),
      transferCount: count().as("transfer_count"),
    })
    .from(transferEvent)
    .groupBy(sql`FLOOR(${transferEvent.timestamp} / 3600)`)
);
```

## Indexing > Overview

import { Callout } from "vocs/components";

# Indexing [Write indexing functions that populate the database]

An indexing function is a TypeScript function that's triggered by onchain activity (an event log, call trace, transaction, transfer, or block).

The purpose of indexing functions is to transform onchain data and insert it into the tables you've defined in `ponder.schema.ts`.

## Register an indexing function

To register an indexing function, use `ponder.on(...)`. The first argument is the event name, and the second argument is the function / callback that the indexing engine runs to process the event.

```ts [src/index.ts]
import { ponder } from "ponder:registry"; // [!code focus]

ponder.on("Blitmap:MetadataChanged", async ({ event, context }) => {
  // [!code focus]
  await context.db
    .insert(tokens)
    .values({
      id: event.args.tokenId,
      metadata: event.args.newMetadata,
    })
    .onConflictDoUpdate({
      metadata: event.args.newMetadata,
    });
}); // [!code focus]
```

Read more about how to [write to the database](#indexing-write) and [read contract data](#indexing-read-contracts) within indexing functions.

## Frequently asked questions

### Ordering

For each chain, the indexing engine calls indexing functions according to EVM execution order (block number, transaction index, log index). [Read more](#api-reference-ponder-config#ordering) about the ordering guarantee across multiple chains, which is more complex.

### Reorgs

The indexing engine handles reorgs automatically. You do not need to adjust your indexing function logic to handle them. Here's how it works.

- The indexing engine records all changes (insert, update, delete) to each table defined in `ponder.schema.ts` using a trigger-based [transaction log](https://en.wikipedia.org/wiki/Transaction_log).
- When the indexing engine detects a reorg, it follows these steps to reconcile the database state with the new canonical chain.
  1. Evict all non-canonical data from the RPC cache.
  2. Roll back the database to the common ancestor block height using the transaction log.
  3. Fetch the new canonical data from the RPC / remote chain.
  4. Run indexing functions to process the new canonical data.
- The indexing engine periodically drops finalized data from the transaction log to avoid database bloat.

### Crash recovery

If the process crashes and starts back up again using the same exact configuration, the indexing engine attempts a crash recovery. This process is similar to reorg reconciliation, except all unfinalized changes (the entire transaction log) are rolled back. Then, indexing resumes from the finalized block.

### Backfill vs. live indexing

Internally, the indexing engine has two distinct modes – **backfill** and **live** indexing – which use different approaches for fetching data from the RPC.

However, indexing function logic works the same way in both modes. As long as the logic is compatible with the expected onchain activity, indexing will work fine in both modes.

## Indexing > Write

# Write to the database [Insert, update, and delete rows]

There are two ways to write to the database in a Ponder app.

1. **Store API**: The recommended way to write to the database. 100-1000x faster than raw SQL.
2. **Raw SQL**: A useful escape hatch for logic that's too complex for the Store API.

## Store API

The Store API is a SQL-like query builder optimized for common indexing workloads. All operations run **in-memory** and rows are flushed to the database periodically using efficient `COPY` statements.

The examples below use this `ponder.schema.ts` to demonstrate the core concepts.

```ts [ponder.schema.ts]
import { onchainTable, primaryKey } from "ponder";

export const accounts = onchainTable("accounts", (t) => ({
  address: t.hex().primaryKey(),
  balance: t.bigint().notNull(),
  nickname: t.text(),
}));

export const allowances = onchainTable(
  "allowances",
  (t) => ({
    owner: t.hex().notNull(),
    spender: t.hex().notNull(),
    value: t.bigint().notNull(),
  }),
  (table) => ({
    pk: primaryKey({ columns: [table.owner, table.spender] }),
  })
);
```

### Insert

Insert one or many rows into the database. Returns the inserted rows, **including** any default values that were generated.

```ts [src/index.ts]
import { accounts } from "ponder:schema";

// Insert a single row
const row = await db.insert(accounts).values({
  address: "0x7Df1",
  balance: 0n,
});

// Insert multiple rows
const rows = await db.insert(accounts).values([
  { address: "0x7Df2", balance: -50n },
  { address: "0x7Df3", balance: 100n },
]);
```

#### Errors

If you insert a row that's missing a required column value (not null constraint violation), `insert` will reject with an error.

```ts [src/index.ts]
import { accounts } from "ponder:schema";

const row = await db.insert(accounts).values({
  address: "0x7Df1",
});

// Error: Column "balance" is required but not present in the values object.
```

If you insert a duplicate row (unique constraint violation), `insert` will reject with an error.

```ts [src/index.ts]
import { accounts } from "ponder:schema";

const row = await db.insert(accounts).values({
  address: "0x7Df1",
});

// Error: Column "balance" is required but not present in the values object.
```

Use [conflict resolution](#conflict-resolution) to ignore unique constraint violations with `onConflictDoNothing` or achieve upsert behavior with `onConflictDoUpdate`.

### Find

Find a single row by primary key. Returns the row, or `null` if not found.

The second argument is an object that specifies the primary key value to search for.

```ts [src/index.ts]
import { accounts } from "ponder:schema";

const row = await db.find(accounts, { address: "0x7Df1" });
```

If the table has a composite primary key, the object must include a value for each column in the primary key.

```ts [src/index.ts]
import { allowances } from "ponder:schema";

const row = await db.find(allowances, {
  owner: "0x7Df1",
  spender: "0x7Df2",
});
```

### Update

Update a row by primary key. Returns the updated row.

```ts [src/index.ts]
import { accounts } from "ponder:schema";

const row = await db
  .update(accounts, { address: "0x7Df1" })
  .set({ balance: 100n });
```

You can also pass a function to `set`, which receives the existing row and returns the update object.

```ts [src/index.ts]
import { accounts } from "ponder:schema";

const row = await db
  .update(accounts, { address: "0x7Df1" })
  .set((row) => ({ balance: row.balance + 100n })); // [!code focus]
```

#### Errors

If the target row is not found, `update` will reject with an error.

```ts [src/index.ts]
import { tokens } from "ponder:schema";

const row = await db
  .update(accounts, { address: "0xa4F0" })
  .set({ balance: 200n });

// Error: No row found for address "0xa4F0".
```

If the new row violates a not null constraint, `update` will reject with an error.

```ts [src/index.ts]
import { tokens } from "ponder:schema";

const row = await db
  .update(accounts, { address: "0x7Df1" })
  .set({ balance: null });

// Error: Column "balance" is required but not present in the object.
```

### Delete

Delete a row by primary key. Returns `true` if the row was deleted, or `false` if not found.

```ts [src/index.ts]
import { accounts } from "ponder:schema";

const deleted = await db.delete(accounts, { address: "0x7Df1" });
```

### Conflict resolution

The `insert` method supports conflict resolution.

#### `onConflictDoNothing`

Use `onConflictDoNothing` to skip the insert if the specified row already exists. This avoids unique constraint violation errors.

```ts [src/index.ts]
import { accounts } from "ponder:schema";

const row = await db
  .insert(accounts)
  .values({ address: "0x7Df1", balance: 0n })
  .onConflictDoNothing(); // [!code focus]
```

#### `onConflictDoUpdate`

Use `onConflictDoUpdate` to achieve "upsert" behavior.

If the row does not exist, it will be inserted using the specified `values`. Otherwise, the existing row will be updated with the values passed to `onConflictDoUpdate`.

```ts [src/index.ts]
import { accounts } from "ponder:schema";

const row = await db
  .insert(accounts)
  .values({ address: "0x7Df1", balance: 0n })
  .onConflictDoUpdate({ value: 200n }); // [!code focus]
```

Just like with `update`, you can pass a function to `onConflictDoUpdate` that receives the existing row and returns the update object.

```ts [src/index.ts]
import { accounts } from "ponder:schema";

const row = await db
  .insert(accounts)
  .values({ address: "0x7Df1", balance: 0n })
  .onConflictDoUpdate((row) => ({
    // [!code focus]
    balance: row.balance + 50n, // [!code focus]
  })); // [!code focus]
```

## Raw SQL

Warning: Raw SQL queries are **much slower** than the store API. Only use raw SQL when you need complex queries that aren't possible with the store API.

### Query builder

Use `db.sql` to access the raw Drizzle PostgreSQL query builder. This is useful for complex queries that join multiple tables or use advanced SQL features.

```ts [src/index.ts]
import { accounts, tradeEvents } from "ponder:schema";
import { eq, and, gte, inArray, sql } from "drizzle-orm";

// Add 100 points to accounts with recent trades
await db.sql
  .update(accounts)
  .set({ points: sql`${accounts.points} + 100` })
  .where(
    inArray(
      accounts.address,
      db.sql
        .select({ address: tradeEvents.from })
        .from(tradeEvents)
        .where(gte(tradeEvents.timestamp, event.block.timestamp - 24 * 60 * 60))
    )
  );
```

### Relational queries

Use `db.sql.query` to access Drizzle's relational query builder. This provides a type-safe way to write complex `SELECT` queries that join multiple tables.

```ts [src/index.ts]
import { accounts, tradeEvents } from "ponder:schema";

// Find recent large trades with account details
const trades = await db.sql.query.tradeEvents.findMany({
  where: (table, { gt, gte, and }) =>
    and(
      gt(table.amount, 1_000n),
      gte(table.timestamp, Date.now() - 1000 * 60 * 60)
    ),
  limit: 10,
  with: { account: true },
});
```

Visit the [Drizzle documentation](https://orm.drizzle.team/docs/rqb) for more details on writing raw SQL queries.

## Indexing > Read Contracts

# Read contract data [Call read-only functions directly]

Sometimes, indexing function _triggers_ (event logs, traces, etc.) do not contain all of the onchain data you need to build your application. It's often useful to call read-only contract functions, fetch transaction receipts, or simulate contract interactions.

Ponder natively supports this pattern through a custom [Viem Client](https://viem.sh/docs/clients/intro) that includes performance & usability improvements specific to indexing.

## Basic example

To read data from a contract, use `context.client.readContract()` and include the contract address and ABI from `context.contracts`.

```ts [ponder.config.ts]
import { createConfig } from "ponder";
import { BlitmapAbi } from "./abis/Blitmap";

export default createConfig({
  chains: {
    mainnet: { id: 1, rpc: process.env.PONDER_RPC_URL_1 },
  },
  contracts: {
    Blitmap: {
      chain: "mainnet",
      abi: BlitmapAbi,
      address: "0x8d04...D3Ff63",
      startBlock: 12439123,
    },
  },
});
```

```ts [src/index.ts]
import { ponder } from "ponder:registry";
import { tokens } from "ponder:schema";

ponder.on("Blitmap:Mint", async ({ event, context }) => {
  const { client } = context;
  //      ^? ReadonlyClient<"mainnet">
  const { Blitmap } = context.contracts;
  //      ^? {
  //           abi: [...]
  //           address: "0x8d04...D3Ff63",
  //         }

  // Fetch the URI for the newly minted token.
  const tokenUri = await client.readContract({
    abi: Blitmap.abi,
    address: Blitmap.address,
    functionName: "tokenURI",
    args: [event.args.tokenId],
  });

  // Insert a Token record, including the URI.
  await context.db.insert(tokens).values({
    id: event.args.tokenId,
    uri: tokenUri,
  });
});
```

## Client

The `context.client` object is a custom [Viem Client](https://viem.sh/docs/clients/intro) that caches RPC responses.

```ts [src/index.ts]
import { ponder } from "ponder:registry";

ponder.on("Blitmap:Mint", async ({ event, context }) => {
  const tokenUri = await context.client.readContract({
    abi: context.contracts.Blitmap.abi,
    address: context.contracts.Blitmap.address,
    method: "tokenUri",
    args: [event.args.tokenId],
  });
});
```

Warning: **_Do not manually set up a Viem Client._** If `context.client` is not working
for you, please open a GitHub issue or send a message to the chat. We'd like
to understand and accommodate your workflow.

```ts [src/index.ts]
import { ponder } from "ponder:registry";
import { createPublicClient, http } from "viem";

// Don't do this! ❌ ❌ ❌
const publicClient = createPublicClient({
  transport: http("https://eth-mainnet.g.alchemy.com/v2/..."),
});

ponder.on("Blitmap:Mint", async ({ event, context }) => {
  const tokenUri = await publicClient.readContract({
    abi: context.contracts.Blitmap.abi,
    address: context.contracts.Blitmap.address,
    method: "tokenUri",
    args: [event.args.tokenId],
  });
});
```

### Supported actions

The `context.client` object supports most Viem actions.

| name                        | description                                                                                         | Viem docs                                                                                      |
| :-------------------------- | :-------------------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------------------------- |
| readContract                | Returns the result of a read-only function on a contract.                                           | [readContract](https://viem.sh/docs/contract/readContract)                                     |
| multicall                   | Similar to readContract, but batches requests.                                                      | [multicall](https://viem.sh/docs/contract/multicall)                                           |
| simulateContract            | Simulates & validates a contract interaction.                                                       | [simulateContract](https://viem.sh/docs/contract/simulateContract)                             |
| getBalance                  | Returns the balance of an address in wei.                                                           | [getBalance](https://viem.sh/docs/actions/public/getBalance)                                   |
| getBytecode                 | Returns the bytecode at an address.                                                                 | [getBytecode](https://viem.sh/docs/contract/getBytecode.html)                                  |
| getStorageAt                | Returns the value from a storage slot at a given address.                                           | [getStorageAt](https://viem.sh/docs/contract/getStorageAt)                                     |
| getBlock                    | Returns information about a block at a block number, hash or tag.                                   | [getBlock](https://viem.sh/docs/actions/public/getBlock)                                       |
| getTransactionCount         | Returns the number of transactions an account has broadcast / sent.                                 | [getTransactionCount](https://viem.sh/docs/actions/public/getTransactionCount)                 |
| getBlockTransactionCount    | Returns the number of Transactions at a block number, hash or tag.                                  | [getBlockTransactionCount](https://viem.sh/docs/actions/public/getBlockTransactionCount)       |
| getTransaction              | Returns information about a transaction given a hash or block identifier.                           | [getTransaction](https://viem.sh/docs/actions/public/getTransaction)                           |
| getTransactionReceipt       | Returns the transaction receipt given a transaction hash.                                           | [getTransactionReceipt](https://viem.sh/docs/actions/public/getTransactionReceipt)             |
| getTransactionConfirmations | Returns the number of blocks passed (confirmations) since the transaction was processed on a block. | [getTransactionConfirmations](https://viem.sh/docs/actions/public/getTransactionConfirmations) |
| call                        | An Action for executing a new message call.                                                         | [call](https://viem.sh/docs/actions/public/call)                                               |
| estimateGas                 | An Action for estimating gas for a transaction.                                                     | [estimateGas](https://viem.sh/docs/actions/public/estimateGas)                                 |
| getFeeHistory               | Returns a collection of historical gas information.                                                 | [getFeeHistory](https://viem.sh/docs/actions/public/getFeeHistory)                             |
| getProof                    | Returns the account and storage values of the specified account including the Merkle-proof.         | [getProof](https://viem.sh/docs/actions/public/getProof)                                       |
| getEnsAddress               | Gets address for ENS name.                                                                          | [getEnsAddress](https://viem.sh/docs/ens/actions/getEnsAddress)                                |
| getEnsAvatar                | Gets the avatar of an ENS name.                                                                     | [getEnsAvatar](https://viem.sh/docs/ens/actions/getEnsAvatar)                                  |
| getEnsName                  | Gets primary name for specified address.                                                            | [getEnsName](https://viem.sh/docs/ens/actions/getEnsName)                                      |
| getEnsResolver              | Gets resolver for ENS name.                                                                         | [getEnsResolver](https://viem.sh/docs/ens/actions/getEnsResolver)                              |
| getEnsText                  | Gets a text record for specified ENS name.                                                          | [getEnsText](https://viem.sh/docs/ens/actions/getEnsText)                                      |

### Direct RPC requests

Use the `context.client.request` method to make direct RPC requests. This low-level approach can be useful for advanced RPC request patterns that are not supported by the actions above.

```ts [src/index.ts]
import { ponder } from "ponder:registry";

ponder.on("ENS:NewOwner", async ({ event, context }) => {
  const traces = await context.client.request({
    // [!code focus]
    method: "debug_traceTransaction", // [!code focus]
    params: [event.transaction.hash, { tracer: "callTracer" }], // [!code focus]
  }); // [!code focus]

  // ...
});
```

### Block number

By default, the `blockNumber` option is set to the block number of the current event (`event.block.number`).

```ts [src/index.ts]
import { ponder } from "ponder:registry";

ponder.on("Blitmap:Mint", async ({ event, context }) => {
  const totalSupply = await context.client.readContract({
    abi: context.contracts.Blitmap.abi,
    address: context.contracts.Blitmap.address,
    functionName: "totalSupply",
    // This is set automatically, no need to include it yourself.
    // blockNumber: event.block.number,
  });
});
```

You can also specify a `blockNumber` to read data at a specific block height. It will still be cached.

```ts [src/index.ts]
import { ponder } from "ponder:registry";

ponder.on("Blitmap:Mint", async ({ event, context }) => {
  const totalSupply = await context.client.readContract({
    abi: context.contracts.Blitmap.abi,
    address: context.contracts.Blitmap.address,
    functionName: "totalSupply",
    blockNumber: 15439123n, // [!code focus]
  });
});
```

Note: The `blockTag` option is not supported by custom client actions.

### Caching

Most RPC requests made using `context.client` are cached in the database. When an indexing function calls a method with a specific set of arguments for the first time, it will make an RPC request. Any subsequent calls to the same method with the same arguments will be served from the cache.

See the [full list](https://github.com/ponder-sh/ponder/blob/main/packages/core/src/indexing/client.ts#L73-L121) of cache-enabled RPC methods in the source code.

## Contract addresses & ABIs

The `context.contracts` object contains each contract address and ABI you provide in `ponder.config.ts`.

### Multiple chains

If a contract is configured to run on multiple chains, `context.contracts` contains the contract addresses for whichever chain the current event is from.

Warning: It's not currently possible to call a contract that's on a different chain
than the current event. If you need this feature, please open an issue or send
a message to the chat.

```ts [ponder.config.ts]
import { createConfig } from "ponder";
import { UniswapV3FactoryAbi } from "./abis/UniswapV3Factory";

export default createConfig({
  chains: {
    mainnet: { id: 1, rpc: process.env.PONDER_RPC_URL_1 },
    base: { id: 8453, rpc: process.env.PONDER_RPC_URL_8453 },
  },
  contracts: {
    UniswapV3Factory: {
      abi: UniswapV3FactoryAbi,
      chain: {
        // [!code focus]
        mainnet: {
          // [!code focus]
          address: "0x1F98431c8aD98523631AE4a59f267346ea31F984", // [!code focus]
          startBlock: 12369621, // [!code focus]
        }, // [!code focus]
        base: {
          // [!code focus]
          address: "0x33128a8fC17869897dcE68Ed026d694621f6FDfD", // [!code focus]
          startBlock: 1371680, // [!code focus]
        }, // [!code focus]
      }, // [!code focus]
    },
  },
});
```

```ts [src/index.ts]
import { ponder } from "ponder:registry";

ponder.on("UniswapV3Factory:FeeAmountEnabled", async ({ event, context }) => {
  const tickSpacing = await context.client.readContract({
    abi: context.contracts.UniswapV3Factory.abi,
    address: context.contracts.UniswapV3Factory.address,
    functionName: "feeAmountTickSpacing",
    args: [event.args.fee],
  });
});
```

### Factory contracts

The `context.contracts` object does not include an `address` property for contracts that use `factory()`. To read data from the contract that emitted the current event, use `event.log.address`.

```ts [src/index.ts]
import { ponder } from "ponder:registry";

ponder.on("SudoswapPool:Transfer", async ({ event, context }) => {
  const { SudoswapPool } = context.contracts;
  //      ^? { abi: [...] }

  const totalSupply = await context.client.readContract({
    abi: SudoswapPool.abi,
    address: event.log.address,
    functionName: "totalSupply",
  });
});
```

To call a factory contract child from an indexing function for a _different_ contract, use your application logic to determine the correct address. For example, the address might come from `event.args`.

```ts [src/index.ts]
import { ponder } from "ponder:registry";

ponder.on("LendingProtocol:RegisterPool", async ({ event, context }) => {
  const totalSupply = await context.client.readContract({
    abi: context.contracts.SudoswapPool.abi,
    address: event.args.pool,
    functionName: "totalSupply",
  });
});
```

### Read a contract without indexing it

The `context.contracts` object only contains addresses & ABIs for the contracts in `ponder.config.ts`.

To read an external contract, import the ABI object directly and include the address manually. Ad-hoc requests like this are still cached and the block number will be set automatically.

```ts [ponder.config.ts]
import { createConfig } from "ponder";
import { AaveTokenAbi } from "./abis/AaveToken";

export default createConfig({
  contracts: {
    AaveToken: {
      chain: "mainnet",
      abi: AaveTokenAbi,
      address: "0x7Fc66500c84A76Ad7e9c93437bFc5Ac33E2DDaE9",
      startBlock: 10926829,
    },
  },
});
```

```ts [src/index.ts]
import { ponder } from "ponder:registry";
import { ChainlinkPriceFeedAbi } from "../abis/ChainlinkPriceFeed";

ponder.on("AaveToken:Mint", async ({ event, context }) => {
  const priceData = await context.client.readContract({
    abi: ChainlinkPriceFeedAbi,
    address: "0x547a514d5e3769680Ce22B2361c10Ea13619e8a9",
    functionName: "latestRoundData",
  });

  const usdValue = priceData.answer * event.args.amount;
  // ...
});
```

## More examples

### Zorbs gradient data

Suppose we're building an application that stores the gradient metadata of each [Zorb NFT](https://etherscan.io/address/0xca21d4228cdcc68d4e23807e5e370c07577dd152#code). Here's a snippet from the contract.

```solidity [ZorbNft.sol]
contract ZorbNft is ERC721 {

    function mint() public {
        // ...
    }

    function gradientForAddress(address user) public pure returns (bytes[5] memory) { // [!code focus]
        return ColorLib.gradientForAddress(user); // [!code focus]
    } // [!code focus]
}
```

Every Zorb has a gradient, but the contract doesn't emit gradient data in any event logs. To read the gradient data for each new Zorb, we can call the `gradientForAddress` function.

```ts [src/index.ts]
import { ponder } from "ponder:registry";
import { zorbs } from "ponder:schema";

ponder.on("ZorbNft:Transfer", async ({ event, context }) => {
  if (event.args.from === ZERO_ADDRESS) {
    // If this is a mint, read gradient metadata from the contract. // [!code focus]
    const gradientData = await context.client.readContract({
      // [!code focus]
      abi: context.contracts.ZorbNft.abi, // [!code focus]
      address: context.contracts.ZorbNft.address, // [!code focus]
      functionName: "gradientForAddress", // [!code focus]
      args: [event.args.to], // [!code focus]
    }); // [!code focus]

    await context.db.insert(zorbs).values({
      id: event.args.tokenId,
      gradient: gradientData,
      ownerId: event.args.to,
    });
  } else {
    // If not a mint, just update ownership information.
    await context.db
      .update(zorbs, { id: event.args.tokenId })
      .set({ ownerId: event.args.to });
  }
});
```

## Query > Sql Over Http

# SQL over HTTP [Query with custom SQL over HTTP]

Ponder natively supports SQL queries over HTTP using the `@ponder/client` and `@ponder/react` packages.

The SQL over HTTP is a more powerful alternative to [GraphQL](#query-graphql) that offers zero-codegen type inference, live queries, and the flexibility of SQL directly in your client code.

## Setup

### Enable on the server

Use the `client` Hono middleware to enable SQL over HTTP queries.

```ts [src/api/index.ts]
import { db } from "ponder:api";
import schema from "ponder:schema";
import { Hono } from "hono";
import { client } from "ponder"; // [!code focus]

const app = new Hono();

app.use("/sql/*", client({ db, schema })); // [!code focus]

export default app;
```

### Install `@ponder/client`

Install the `@ponder/client` package in your client project.

```bash [pnpm]
pnpm add @ponder/client
```

```bash [yarn]
yarn add @ponder/client
```

```bash [npm]
npm add @ponder/client
```

```bash [bun]
bun add @ponder/client
```

### Create a query client

Use `createClient` to connect to the server at the path where you registered the middleware.

```ts [Client project]
import { createClient } from "@ponder/client";

const client = createClient("http://localhost:42069/sql");
```

### Import `ponder.schema.ts`

Import your schema from `ponder.schema.ts` and pass it to `createClient`. [Read more](#use-schema-from-a-different-repo) about schema portability.

```ts [Client project]
import { createClient } from "@ponder/client";
import * as schema from "../../ponder/ponder.schema"; // [!code focus]

const client = createClient("http://localhost:42069/sql", { schema }); // [!code focus]
```

Now, the client is ready to send SQL over HTTP queries to the server.

```ts [Client project]
import { createClient } from "@ponder/client";
import * as schema from "../../ponder/ponder.schema";

const client = createClient("http://localhost:42069/sql", { schema });

const result = await client.db.select().from(schema.account); // [!code focus]
//   ^? { address: `0x${string}`; balance: bigint; }[] // [!code focus]
```

## Setup React

The `@ponder/react` package provides React hook bindings for the SQL over HTTP client. This package wraps [TanStack Query](https://tanstack.com/query), a popular library for managing async state in React.

### Install dependencies

Install `@ponder/react` and peer dependencies in your client project.

```bash [pnpm]
pnpm add @ponder/react @ponder/client @tanstack/react-query
```

```bash [yarn]
yarn add @ponder/react @ponder/client @tanstack/react-query
```

```bash [npm]
npm add @ponder/react @ponder/client @tanstack/react-query
```

```bash [bun]
bun add @ponder/react @ponder/client @tanstack/react-query
```

### Set up `@ponder/client`

Follow the [steps above](#guide) to set up a SQL over HTTP query client using `@ponder/client`.

```ts [lib/ponder.ts]
import { createClient } from "@ponder/client";
import * as schema from "../../ponder/ponder.schema"; // [!code focus]

const client = createClient("http://localhost:42069/sql", { schema }); // [!code focus]
```

### Set up `PonderProvider`

Wrap your app with `PonderProvider` and include the `client` object you created in the previous step.

```ts [app/layout.tsx]
import { PonderProvider } from "@ponder/react";
import { client } from "../lib/ponder";

function App() {
  return (
    <PonderProvider client={client}>
      {/** ... */}
    </PonderProvider>
  );
}
```

### Set up TanStack Query

Inside the `PonderProvider`, wrap your app with a TanStack Query Provider. If you're already using TanStack Query, you can skip this step. [Read more](https://tanstack.com/query/latest/docs/framework/react/quick-start) about setting up TanStack Query.

```ts [app/layout.tsx]
import { PonderProvider } from "@ponder/react";
import { QueryClient, QueryClientProvider } from "@tanstack/react-query"; // [!code focus]
import { client } from "../lib/ponder";

const queryClient = new QueryClient(); // [!code focus]

function App() {
  return (
    <PonderProvider client={client}>
      <QueryClientProvider client={queryClient}> // [!code focus]
        {/** ... */}
      </QueryClientProvider> // [!code focus]
    </PonderProvider>
  );
}
```

## Querying

The SQL over HTTP client can be used to read indexed data from your Ponder database.

It's different than [direct SQL](#query-direct-sql) in two key areas:

- Schema names are automatically applied on the server using Postgres's [`search_path`](https://www.postgresql.org/docs/current/ddl-schemas.html#DDL-SCHEMAS-PATH). Table names should be unqualified.
- Only a subset of SQL statements are allowed, with limited resources. Read more about [security](#security).

```ts [index.ts Node.js]
import { desc } from "@ponder/client";
import * as schema from "../../ponder/ponder.schema";

const result = await client.db
  .select()
  .from(schema.account)
  .orderBy(desc(schema.account.balance));
```

```ts [index.ts React]
import { desc } from "@ponder/client";
import { usePonderQuery } from "@ponder/react";
import * as schema from "../../ponder/ponder.schema";

const query = usePonderQuery({
  queryFn: (db) =>
    db.select().from(schema.account).orderBy(desc(schema.account.balance)),
});
```

Note: The `@ponder/client` package re-exports all Drizzle utility functions (like `desc` and `eq`). You shouldn't need to install `drizzle-orm` separately.

### Live queries

Live queries are automatically updated when the underlying data changes. Ponder uses Server-Sent Events to stream updates to the **only when the query result changes**.

```ts [index.ts Node.js]
import { desc } from "@ponder/client";
import * as schema from "../../ponder/ponder.schema";

await client.live(
  (db) =>
    db.select().from(schema.account).orderBy(desc(schema.account.balance)),
  (result) => {
    // ... handle result
  },
  (error) => {
    // ... handle error
  }
);
```

```ts [index.ts React]
import { desc } from "@ponder/client";
import { usePonderQuery } from "@ponder/react";
import * as schema from "../../ponder/ponder.schema";

// `usePonderQuery` always uses live queries!
const query = usePonderQuery({
  queryFn: (db) =>
    db.select().from(schema.account).orderBy(desc(schema.account.balance)),
});
```

### Untyped queries

It's also possible to query the Ponder database without relying on importing `ponder.schema.ts` using the [`sql`](https://orm.drizzle.team/docs/sql) operator.

```ts [index.ts Node.js]
import { sql } from "@ponder/client";

const result = await client.db.execute(sql`SELECT * FROM account limit 10;`);
```

```ts [index.ts React]
import { sql } from "@ponder/client";
import { usePonderQuery } from "@ponder/react";

const query = usePonderQuery({
  queryFn: (db) => db.execute(sql`SELECT * FROM account limit 10;`),
});
```

### Pagination

The SQL over HTTP supports both limit/offset and cursor-based pagination patterns to handle large result sets efficiently.

```ts [index.ts Node.js]
import { desc } from "@ponder/client";
import * as schema from "../../ponder/ponder.schema";

const count = await client.db.$count(schema.account);

const result = await client.db
  .select()
  .from(schema.account)
  .orderBy(desc(schema.account.balance))
  .limit(100)
  .offset(500);
```

```ts [index.ts React]
import { desc } from "@ponder/client";
import { usePonderQuery } from "@ponder/react";
import * as schema from "../../ponder/ponder.schema";

const countQuery = usePonderQuery({
  queryFn: (db) => db.$count(schema.account),
});

const query = usePonderQuery({
  queryFn: (db) =>
    db
      .select()
      .from(schema.account)
      .orderBy(desc(schema.account.balance))
      .limit(100)
      .offset(500),
});
```

### Relational query builder

The SQL over HTTP also supports the [Drizzle query builder](https://orm.drizzle.team/docs/rqb) with some additional setup required.

The `createClient` function accepts a `schema` option to enable the Drizzle query builder.

```ts
import { createClient } from "@ponder/client";
import * as schema from "../../ponder/ponder.schema";

const client = createClient("http://localhost:42069/sql", { schema });

const result = await client.db.query.account.findMany({
  orderBy: (account, { desc }) => desc(account.balance),
});
```

#### React

In addition to the step above, you need to "register" your `schema` globally with TypeScript using [declaration merging](https://www.typescriptlang.org/docs/handbook/declaration-merging.html).

```ts
import * as schema from "../../ponder/ponder.schema";

declare module "@ponder/react" {
  // [!code focus]
  interface Register {
    // [!code focus]
    schema: typeof schema; // [!code focus]
  } // [!code focus]
} // [!code focus]
```

`usePonderQuery` is now type-safe without the need to import `schema` in every query.

```ts
import { usePonderQuery } from "@ponder/react";

const query = usePonderQuery({
  queryFn: (db) =>
    db.query.account.findMany({
      orderBy: (account, { desc }) => desc(account.balance),
    }),
});
```

## Examples

- [Basic usage](https://github.com/ponder-sh/ponder/blob/main/examples/with-client/client/src/index.ts) (`@ponder/client` only)
- [Usage with Next.js](https://github.com/ponder-sh/ponder/blob/main/examples/with-nextjs/frontend/src/pages/index.ts#L11-L18) (`@ponder/client` and `@ponder/react`)
- Usage with [`useInfiniteQuery`](https://tanstack.com/query/latest/docs/framework/react/guides/infinite-queries)

For this example, we'll use the following schema.

```ts [ponder.schema.ts]
import { onchainTable } from "ponder";

export const person = onchainTable("person", (t) => ({
  id: t.integer().primaryKey(),
  name: t.text().notNull(),
  age: t.integer(),
}));
```

Get all `person` records with an `age` greater than `32`.

```ts
import { asc, gt } from "@ponder/client";
import { usePonderClient } from "@ponder/react";
import { useInfiniteQuery } from "@tanstack/react-query";

const client = usePonderClient();

const personQuery = useInfiniteQuery({
  queryKey: ["persons"],
  queryFn: ({ pageParam }) =>
    client.db
      .select()
      .from(schema.person)
      .where(gt(schema.person.age, 32))
      .orderBy(asc(schema.person.id))
      .limit(100)
      .offset(pageParam),
  initialPageParam: 0,
  getNextPageParam: (lastPage, pages) =>
    lastPage.length === 100 ? undefined : pages.length * 100,
});
```

- [Uniswap v4](https://github.com/marktoda/v4-ponder)

For this example, we'll use the following schema.

```ts [ponder.schema.ts]
import { index, relations, primaryKey, onchainTable } from "ponder";

export const token = onchainTable(
  "token",
  (t) => ({
    address: t.hex().notNull(),
    chainId: t.integer().notNull(),
    name: t.text().notNull(),
    symbol: t.text().notNull(),
    decimals: t.integer().notNull(),
    creationBlock: t.integer().notNull(),
  }),
  (table) => ({
    pk: primaryKey({ columns: [table.address, table.chainId] }),
    addressIndex: index().on(table.address),
    chainIdIndex: index().on(table.chainId),
  })
);

export const tokenRelations = relations(token, ({ many }) => ({
  pools: many(pool),
}));

export const pool = onchainTable(
  "pool",
  (t) => ({
    poolId: t.hex().notNull(),
    currency0: t.hex().notNull(),
    currency1: t.hex().notNull(),
    fee: t.integer().notNull(),
    tickSpacing: t.integer().notNull(),
    hooks: t.hex().notNull(),
    chainId: t.integer().notNull(),
    creationBlock: t.integer().notNull(),
  }),
  (table) => ({
    pk: primaryKey({ columns: [table.poolId, table.chainId] }),
    poolIdIndex: index().on(table.poolId),
    chainIdIndex: index().on(table.chainId),
  })
);

export const poolRelations = relations(pool, ({ many, one }) => ({
  token0: one(token, {
    fields: [pool.currency0, pool.chainId],
    references: [token.address, token.chainId],
  }),
  token1: one(token, {
    fields: [pool.currency1, pool.chainId],
    references: [token.address, token.chainId],
  }),
}));
```

Get all `pool` records with a `chainId` of `1` and a `fee` of `0` and include the `token0` and `token1` data.

```ts
import { usePonderQuery } from "@ponder/react";

const query = usePonderQuery({
  queryFn: (db) =>
    qb.query.pool.findMany({
      where: (pool, { and, eq }) => and(eq(pool.chainId, 1), eq(pool.fee, 0)),
      orderBy: (pool, { desc }) => desc(pool.creationBlock),
      with: {
        token0: true,
        token1: true,
      },
    }),
});
```

## Frequently asked questions

### Use schema from a different repo

The `@ponder/client` package needs the `onchainTable` objects exported by `ponder.schema.ts` to properly compile the Drizzle queries client-side.

If the client project is in a different repo from the Ponder project, there are a few other options:

- Import the `ponder.schema.ts` locally using a monorepo.
- Publish the `ponder.schema.ts` to npm.
- Copy the `ponder.schema.ts` into the client project and install `ponder` to get access to the `onchainTable` function.
- Forfeit type safety and use [untyped queries](#untyped-queries).

### Security

Here are the measures taken by the `client` middleware to prevent malicious queries & denial-of-service attacks. These measures aim to achieve a similar level of risk as the GraphQL API.

- **Read-only**: Each query statement runs in a `READ ONLY` transaction using autocommit.
- **Query validator**: Each query is parsed using [`libpg_query`](https://github.com/pganalyze/libpg_query) and must pass the following checks.
  - The query AST root must be a `SELECT{:sql}` statement. Queries containing multiple statements are rejected.
  - The query must only contain allowed AST node types and built-in SQL functions. For example, `SELECT{:sql}`, `WHERE{:sql}`, and `max(){:sql}` are allowed, but `DELETE{:sql}`, `SET{:sql}`, and `pg_advisory_lock(){:sql}` are not. [Read more](https://github.com/ponder-sh/ponder/blob/main/packages/core/src/client/validate.ts).
  - The query must not reference objects in schemas other than the current schema. [Read more](#database#database-schema).

- **Resource limits**: The database session uses the following resource limit settings.
  <div className="h-2" />
  ```sql
  SET work_mem = '512MB';
  SET statement_timeout = '500ms';
  SET lock_timeout = '500ms';
  ```

## Query > Graphql

# GraphQL [Query the autogenerated GraphQL API]

Ponder automatically generates a [GraphQL](https://graphql.org/learn/) API based on the tables, views, and relations defined in `ponder.schema.ts`.

## Setup

### Enable on the server

To enable the GraphQL API, register the `graphql` Hono middleware.

```ts [src/api/index.ts]
import { db } from "ponder:api";
import schema from "ponder:schema";
import { Hono } from "hono";
import { graphql } from "ponder"; // [!code focus]

const app = new Hono();

app.use("/graphql", graphql({ db, schema })); // [!code focus]

export default app;
```

The `graphql()` middleware includes a [GraphiQL](https://github.com/graphql/graphiql/tree/main/packages/graphiql#graphiql) interface in response to GET requests (you can visit it in your browser). GraphiQL is a useful tool to explore your schema and test queries.

Note: The `graphql()` middleware function also writes the `generated/schema.graphql` file during the build step. The `ponder codegen` command does not write `schema.graphql`.

## Schema generation

The GraphQL schema includes **singular** and a **plural** query fields based on the tables and views defined in `ponder.schema.ts`.

| Type           | Singular field | Plural field                           |
| :------------- | :------------- | :------------------------------------- |
| `onchainTable` | Yes            | Yes (offset **and** cursor pagination) |
| `onchainView`  | No             | Yes (offset pagination **only**)       |

For example, if your schema contains a `person` table, the GraphQL schema will include a `person` and a `persons` field on the root `Query` type. The singular query field returns a single record (or null) and the plural query field returns a page of records.

```ts [ponder.schema.ts]
import { onchainTable } from "ponder";

export const person = onchainTable("person", (t) => ({
  id: t.integer().primaryKey(),
  name: t.text().notNull(),
  age: t.integer(),
}));
```

```graphql [GraphQL schema]
type person {
  id: Int!
  name: String!
  age: Int
}

type personPage {
  items: [person!]!
  pageInfo: PageInfo!
  totalCount: Int!
}

type Query {
  person(id: Int!): person
  persons(
    where: personFilter
    orderBy: String
    orderDirection: String
    before: String
    after: String
    offset: Int
    limit: Int
  ): personPage!
}
```

## Filtering

Use the `where` argument to filter for records that match certain criteria. The `where` argument type includes filter options for every column defined on a table. Here are the filter options available for each column type.

| Filter option              | Available for column types    | _Include records where \{column\}..._     |
| :------------------------- | :---------------------------- | :---------------------------------------- |
| `{column}`                 | All                           | **equals** the value                      |
| `{column}_not`             | All                           | **does not equal** the value              |
| `{column}_in`              | All primitives and enums      | **is one of** the values                  |
| `{column}_not_in`          | All primitives and enums      | **is not one of** the values              |
| `{column}_gt`              | Numeric primitives            | is **greater than** the value             |
| `{column}_lt`              | Numeric primitives            | is **less than** the value                |
| `{column}_gte`             | Numeric primitives            | is **greater than or equal to** the value |
| `{column}_lte`             | Numeric primitives            | is **less than or equal to** the value    |
| `{column}_contains`        | String primitives             | **contains** the substring                |
| `{column}_not_contains`    | String primitives             | **does not contain** the substring        |
| `{column}_starts_with`     | String primitives             | **starts with** the substring             |
| `{column}_not_starts_with` | String primitives             | **does not start with** the substring     |
| `{column}_ends_with`       | String primitives             | **ends with** the substring               |
| `{column}_not_ends_with`   | String primitives             | **does not end with** the substring       |
| `{column}_has`             | Lists of primitives and enums | **has** the value as an element           |
| `{column}_not_has`         | Lists of primitives and enums | **does not have** the value as an element |

You can compose filters using the `AND` and `OR` operators. These special fields accept an array of filter objects.

### Examples

For the following examples, assume these records exist in your database.

```json [person data]
[
  { "id": 1, "name": "Barry", "age": 57 },
  { "id": 2, "name": "Lucile", "age": 32 },
  { "id": 3, "name": "Sally", "age": 22 },
  { "id": 4, "name": "Pablo", "age": 71 }
]
```

Get all `person` records with an `age` greater than `32`.

```graphql [Query]
query {
  persons(where: { age_gt: 32 }) {
    name
    age
  }
}
```

```json [Result]
{
  "persons": [
    { "name": "Barry", "age": 57 },
    { "name": "Pablo", "age": 71 }
  ]
}
```

Get all `person` records with a `name` that does not end with `"y"` _and_ an age greater than `60`. Note that when you include multiple filter conditions, they are combined with a logical `AND`.

```graphql [Query]
query {
  persons(where: { AND: [{ name_not_ends_with: "y" }, { age_gte: 60 }] }) {
    name
    age
  }
}
```

```json [Result]
{
  "persons": [{ "name": "Pablo", "age": 71 }]
}
```

Get all `person` records with a `name` that contains `"ll"` _or_ an age greater than or equal to `50`. In this case, we use the special `OR` operator to combine multiple filter conditions.

```graphql [Query]
query {
  persons(where: { OR: [{ name_contains: "ll" }, { age_gte: 50 }] }) {
    name
    age
  }
}
```

```json [Result]
{
  "persons": [
    { "name": "Barry", "age": 57 },
    { "name": "Sally", "age": 22 },
    { "name": "Pablo", "age": 71 }
  ]
}
```

## Sorting

Use the `orderBy` and `orderDirection` arguments to sort the result by a column. By default, the result is sorted by the primary key column(s) in ascending order.

| Option           | Default               |
| :--------------- | :-------------------- |
| `orderBy`        | Primary key column(s) |
| `orderDirection` | `"asc"`               |

### Examples

```graphql [Query]
query {
  persons(orderBy: "age", orderDirection: "desc") {
    name
    age
  }
}
```

```json [Result]
{
  "persons": [
    { "name": "Pablo", "age": 71 },
    { "name": "Barry", "age": 57 },
    { "name": "Lucile", "age": 32 },
    { "name": "Sally", "age": 22 }
  ]
}
```

## Pagination

Ponder supports both **cursor** and **offset** pagination through a unified interface on each plural query field and `many()` relationship field.

Here are some trade-offs to consider when choosing between cursor and offset pagination.

|                       | Complexity   | Query performance          | Jump to any page |
| :-------------------- | :----------- | :------------------------- | :--------------- |
| **Cursor pagination** | More complex | Consistently fast          | Not supported    |
| **Offset pagination** | Simple       | Slow for large result sets | Supported        |

### Page

Each plural field and `many()` relationship field returns a `Page` type which includes a list of items, a `PageInfo` object, and the total count of records that match the query.

```ts [ponder.schema.ts]
import { onchainTable } from "ponder";

export const pet = onchainTable("pet", (t) => ({
  id: t.text().primaryKey(),
  name: t.text().notNull(),
}));
```

```graphql [Generated schema] {1-5}
type petPage { # [!code focus]
  items: [pet!]! # [!code focus]
  pageInfo: PageInfo! # [!code focus]
  totalCount: Int! # [!code focus]
} # [!code focus]
type pet {
  id: String!
  name: String!
}

type PageInfo {
  startCursor: String
  endCursor: String
  hasPreviousPage: Boolean!
  hasNextPage: Boolean!
}
```

The `Page` type is the same for both pagination strategies.

### Page info

The `PageInfo` object contains information about the position of the current page within the result set.

| name                | type       |                                                 |
| :------------------ | :--------- | :---------------------------------------------- |
| **startCursor**     | `String`   | Cursor of the first record in `items`           |
| **endCursor**       | `String`   | Cursor of the last record in `items`            |
| **hasPreviousPage** | `Boolean!` | Whether there are more records before this page |
| **hasNextPage**     | `Boolean!` | Whether there are more records after this page  |

The `PageInfo` type is the same for both pagination strategies, but the `startCursor` and `endCursor` values will always be `null` when using offset pagination.

### Total count

The `totalCount` field returns the number of records present in the database that match the specified query. The value is the same regardless of the current pagination position and the `limit` argument. Only the `where` argument, or changes to the underlying dataset, can change the value of `totalCount`.

Warning: The SQL query that backs `totalCount` can be slow. To avoid performance issues, consider including `totalCount` for the first page, then exclude it for subsequent pages.

### Cursor pagination

Cursor pagination works by taking the `startCursor` or `endCursor` value from the previous page's `PageInfo` and passing it as the `before` or `after` argument in the next query.

Note: Note that plural query fields for views (`onchainView`) do not support cursor pagination. [Read more](#schema-views).

#### Cursor values

Each cursor value is an opaque string that encodes the position of a record in the result set.

- Cursor values should not be decoded or manipulated by the client. The only valid use of a cursor value is an argument, e.g. `after: previousPage.endCursor`.
- Cursor pagination works with any filter and sort criteria. However, do not change the filter or sort criteria between paginated requests. This will cause validation errors or incorrect results.

#### Examples

For the following examples, assume that these records exist in your database.

```json [person data]
[
  { "id": 1, "name": "Barry", "age": 57 },
  { "id": 2, "name": "Lucile", "age": 32 },
  { "id": 3, "name": "Sally", "age": 22 },
  { "id": 4, "name": "Pablo", "age": 71 }
]
```

First, make a request without specifying any pagination options. The `items` list will contain the first `n=limit` records that match the filter and sort criteria.

```graphql [Query 1]
query {
  persons(orderBy: "age", orderDirection: "asc", limit: 2) {
    items {
      name
      age
    }
    pageInfo {
      startCursor
      endCursor
      hasPreviousPage
      hasNextPage
    }
    totalCount
  }
}
```

```json [Result 1]
{
  "persons" {
    "items": [
      { "name": "Sally", "age": 22 },
      { "name": "Lucile", "age": 32 },
    ],
    "pageInfo": {
      "startCursor": "MfgBzeDkjs44",
      "endCursor": "Mxhc3NDb3JlLTA=",
      "hasPreviousPage": false,
      "hasNextPage": true,
    },
    "totalCount": 4,
  }
}
```

To paginate forwards, pass `pageInfo.endCursor` from the previous request as the `after` option in the next request.

```graphql [Query 2]
query {
  persons(
    orderBy: "age"
    orderDirection: "asc"
    limit: 2
    after: "Mxhc3NDb3JlLTA=" # [!code focus]
  ) {
    items {
      name
      age
    }
    pageInfo {
      startCursor
      endCursor
      hasPreviousPage
      hasNextPage
    }
    totalCount
  }
}
```

```json [Result 2]
{
  "persons" {
    "items": [
      { "name": "Barry", "age": 57 },
      { "name": "Pablo", "age": 71 },
    ],
    "pageInfo": {
      "startCursor": "MxhcdoP9CVBhY",
      "endCursor": "McSDfVIiLka==",
      "hasPreviousPage": true,
      "hasNextPage": false,
    },
    "totalCount": 4,
  }
}
```

To paginate backwards, pass `pageInfo.startCursor` from the previous request as the `before` option in the next request.

```graphql [Query 3]
query {
  persons(
    orderBy: "age"
    orderDirection: "asc"
    limit: 2
    before: "MxhcdoP9CVBhY" # [!code focus]
  ) {
    items {
      name
      age
    }
    pageInfo {
      startCursor
      endCursor
      hasPreviousPage
      hasNextPage
    }
    totalCount
  }
}
```

```json [Result 3]
{
  "persons" {
    "items": [
      { "name": "Lucile", "age": 32 },
    ],
    "pageInfo": {
      "startCursor": "Mxhc3NDb3JlLTA=",
      "endCursor": "Mxhc3NDb3JlLTA=",
      "hasPreviousPage": true,
      "hasNextPage": true,
    },
    "totalCount": 4,
  }
}
```

### Offset pagination

Offset pagination works by increasing the `offset` argument with each successive query to "skip" rows that have already been fetched.

#### Examples

For the following examples, assume that these records exist in your database.

```json [person data]
[
  { "id": 1, "name": "Barry", "age": 57 },
  { "id": 2, "name": "Lucile", "age": 32 },
  { "id": 3, "name": "Sally", "age": 22 },
  { "id": 4, "name": "Pablo", "age": 71 }
]
```

First, make a request without specifying any pagination options. The `items` list will contain the first `n=limit` records that match the filter and sort criteria.

```graphql [Query 1]
query {
  persons(orderBy: "age", orderDirection: "asc", limit: 2) {
    items {
      name
      age
    }
    pageInfo {
      hasPreviousPage
      hasNextPage
    }
    totalCount
  }
}
```

```json [Result 1]
{
  "persons": {
    "items": [
      { "name": "Sally", "age": 22 },
      { "name": "Lucile", "age": 32 }
    ],
    "pageInfo": {
      "hasPreviousPage": false,
      "hasNextPage": true
    },
    "totalCount": 4
  }
}
```

To paginate forwards, increase the `offset` argument by the `limit` value from the previous request.

```graphql [Query 2]
query {
  persons(
    orderBy: "age"
    orderDirection: "asc"
    limit: 2
    offset: 2 # [!code focus]
  ) {
    items {
      name
      age
    }
    pageInfo {
      hasPreviousPage
      hasNextPage
    }
    totalCount
  }
}
```

```json [Result 2]
{
  "persons": {
    "items": [
      { "name": "Barry", "age": 57 },
      { "name": "Pablo", "age": 71 }
    ],
    "pageInfo": {
      "hasPreviousPage": true,
      "hasNextPage": false
    },
    "totalCount": 4
  }
}
```

To jump to a specific page, calculate the `offset` as `(pageNumber - 1) * limit`. For example, to get page 2 with a limit of 2, use `offset: 2`.

```graphql [Query 3]
query {
  persons(
    orderBy: "age"
    orderDirection: "asc"
    limit: 2
    offset: 2 # Page 2: (2 - 1) * 2 = 2
  ) {
    items {
      name
      age
    }
    pageInfo {
      hasPreviousPage
      hasNextPage
    }
    totalCount
  }
}
```

```json [Result 3]
{
  "persons": {
    "items": [
      { "name": "Barry", "age": 57 },
      { "name": "Pablo", "age": 71 }
    ],
    "pageInfo": {
      "hasPreviousPage": true,
      "hasNextPage": false
    },
    "totalCount": 4
  }
}
```

You can also use offset pagination with filtering. The `offset` and `limit` are applied after the `where` filter.

```graphql [Query 4]
query {
  persons(
    where: { age_gt: 30 }
    orderBy: "age"
    orderDirection: "asc"
    limit: 1
    offset: 1
  ) {
    items {
      name
      age
    }
    pageInfo {
      hasPreviousPage
      hasNextPage
    }
    totalCount
  }
}
```

```json [Result 4]
{
  "persons": {
    "items": [{ "name": "Barry", "age": 57 }],
    "pageInfo": {
      "hasPreviousPage": true,
      "hasNextPage": true
    },
    "totalCount": 3
  }
}
```

## Relationship fields

Note: [Read more](#schema-relations) about how to define relationships in your schema.
The GraphQL schema includes a relationship field for each `one` or `many` relation defined in your schema. One-to-many fields are very similar to the top-level plural query field, except they are automatically filtered by the parent row ID.

```ts [ponder.schema.ts]
import { onchainTable, relations } from "ponder";

export const pet = onchainTable("pet", (t) => ({
  id: t.text().primaryKey(),
  name: t.text().notNull(),
  ownerId: t.integer().notNull(),
}));

export const petRelations = relations(pet, ({ one }) => ({
  owner: one(person, { fields: [pet.ownerId], references: [person.id] }),
}));

export const person = onchainTable("person", (t) => ({
  id: t.integer().primaryKey(),
}));

export const personRelations = relations(person, ({ many }) => ({
  dogs: many(pet),
}));
```

```graphql [Generated schema]
type pet {
  id: String!
  name: String!
  ownerId: Int!
  owner: person! # [!code focus]
}

type person {
  id: Int!
  pets( # [!code focus]
    # Has { ownerId: person.id } applied # [!code focus]
    where: petFilter # [!code focus]
    orderBy: String # [!code focus]
    orderDirection: String # [!code focus]
    before: String # [!code focus]
    after: String # [!code focus]
    limit: Int # [!code focus]
  ): petPage! # [!code focus]
}
```

## Performance tips

Here are a few tips for speeding up slow GraphQL queries.

1. **Limit query depth**: Each layer of depth in a GraphQL query introduces at least one additional sequential database query. Avoid queries that are more than 2 layers deep.
2. **Use pagination**: Use cursor-based pagination to fetch records in smaller, more manageable chunks. This can help reduce the load on the database.
3. **Consider database indexes**: Consider creating database indexes to speed up filters, joins, and sort conditions. Keep in mind that relations **do not** automatically create indexes. [Read more](#schema-tables#indexes).
4. **Enable horizontal scaling**: If the GraphQL API is struggling to keep up with request volume, consider spreading the load across multiple instances. [Read more](#production-self-hosting#scale-the-http-server).

## Query > Api Endpoints

# API endpoints [Customize the HTTP server]

Ponder supports **custom API endpoints** with direct access to the database and other useful resources.

Custom API endpoints offer more flexibility than GraphQL or SQL over HTTP queries, making it possible to serve web requests with complex SQL queries, data from external sources, authentication, and more.

## Guide

### Open `src/api/index.ts`

Ponder's API server uses [Hono](https://hono.dev/), a fast and lightweight HTTP router. The `src/api/index.ts` file **must** default export a Hono instance.

```ts [src/api/index.ts (minimal)]
import { Hono } from "hono";

const app = new Hono();

export default app;
```

### Register a route handler

To customize the server, register routes and middleware on the Hono instance before exporting it.

```ts [src/api/index.ts]
import { Hono } from "hono";

const app = new Hono();

app.get("/hello", (c) => {
  // [!code focus]
  return c.text("Hello, world!"); // [!code focus]
}); // [!code focus]

export default app;
```

### Test the endpoint

To test the endpoint, start the development server and visit the route in your browser.

```text [Response]
Hello, world!
```

Hono supports all HTTP methods, custom middleware, cookies, JSX, and more. Visit the [Hono documentation](https://hono.dev/docs) for more details.

## Resources

The `ponder:api` virtual module includes useful resources for custom API endpoints.

### Database queries

The `db` object exported from `ponder:api` is a ready-to-use Drizzle database instance. This is the same database instance that powers GraphQL and SQL over HTTP queries.

Use the `db` object to run read-only SQL queries within custom API endpoints.

```ts [src/api/index.ts]
import { db } from "ponder:api"; // [!code focus]
import { accounts } from "ponder:schema";
import { Hono } from "hono";
import { eq } from "ponder";

const app = new Hono();

app.get("/account/:address", async (c) => {
  const address = c.req.param("address");

  const account = await db // [!code focus]
    .select() // [!code focus]
    .from(accounts) // [!code focus]
    .where(eq(accounts.address, address)); // [!code focus]

  return c.json(account);
});

export default app;
```

### RPC requests

The `publicClients` object exported from `ponder:api` is a collection of Viem [Public Client](https://viem.sh/docs/clients/public) objects — one for each chain defined in `ponder.config.ts`, using the same transports.

Use these clients to make RPC requests within custom API endpoints.

```ts [src/api/index.ts]
import { publicClients } from "ponder:api"; // [!code focus]
import { Hono } from "hono";

const app = new Hono();

app.get("/balance/:address", async (c) => {
  const address = c.req.param("address");

  const balance = await publicClients["base"].getBalance({ address }); // [!code focus]

  return c.json({ address, balance });
});

export default app;
```

## More examples

- [**Basic usage**](https://github.com/ponder-sh/ponder/tree/main/examples/feature-api-functions/src/api/index.ts) - An app with custom endpoints serving ERC-20 data.
- [**Usage with offchain data**](https://github.com/ponder-sh/ponder/blob/main/examples/with-offchain/ponder/src/api/index.ts) - An app that includes data from offchain sources.

## Query > Direct Sql

# Direct SQL [Query indexed data directly in Postgres]

It's often useful to query Ponder tables directly in Postgres.

Note: Direct SQL is more complex than querying over HTTP with GraphQL or SQL over HTTP. If either of those options are sufficient for your use case, consider using them instead.

## Limitations

As a rule of thumb, the _only_ supported operation is `SELECT` queries against Ponder tables.

- **Direct SQL queries are read-only**. Direct SQL queries should not insert, update, or delete rows from Ponder tables.
- **Direct SQL with zero-downtime deployments requires additional setup**. [Read more](#production-self-hosting) about the views pattern in the production guide.
- **Triggers on Ponder tables are not supported**.

## Database schema

Ponder uses **database schemas** to isolate deployments. [Read more](#production-self-hosting#database-schema) in the self-hosting guide.

Direct SQL queries should target the database schema corresponding to a specific deployment. Or, if your project uses the [views pattern](#production-self-hosting#views-pattern) (**recommended**), queries should target the views schema.

Here are a few strategies to configure the database schema.

### Manual / hard-coded

The easiest way to target a specific database schema is to specify it manually in each SQL query. This works well for projects using the views pattern, because the schema changes less frequently.

```sql [Direct SQL query]
SELECT *
FROM my_ponder_project.accounts -- Database schema specified
ORDER BY created_at ASC
LIMIT 100;
```

### Search path

Note: [Read more](https://www.postgresql.org/docs/current/ddl-schemas.html#DDL-SCHEMAS-PATH) about the schema search path in the Postgres documentation.
Another approach is to write direct SQL queries using unqualified table names (no database schema specified), then update the `search_path` setting to include the target database schema.

```sql [Set search path]
SET search_path TO my_ponder_project, "$user", public;
```

### Drizzle (`setDatabaseSchema`)

If you're writing direct SQL queries using Drizzle (e.g. from a downstream Node.js application), you can use the `setDatabaseSchema` utility function to target a specific database schema.

This function mutates a Drizzle schema such that any queries built using that schema will target the specified database schema. [Read more](https://orm.drizzle.team/docs/schemas) in the Drizzle documentation.

```ts [Drizzle]
import { drizzle, asc } from "drizzle-orm/node-postgres";
import { setDatabaseSchema } from "@ponder/client"; // [!code focus]
import * as schema from "../../ponder/ponder.schema"; // [!code focus]

setDatabaseSchema(schema, "target_schema"); // [!code focus]

const db = drizzle(process.env.DATABASE_URL, {
  schema,
  casing: "snake_case",
});

const oldAccounts = await db
  .select()
  .from(schema.accounts)
  .orderBy(asc(schema.accounts.createdAt))
  .limit(100);

console.log(oldAccounts);
```

```sql [Generated SQL]
SELECT *
FROM target_schema.accounts -- Database schema specified
ORDER BY created_at ASC
LIMIT 100;
```

## Production > Marble

import { Callout } from "vocs/components";

# Deploy on Marble [Run Ponder projects on Marble]

[Marble](https://marble.xyz) is a cloud platform purpose-built for Ponder projects, with automatic support for zero downtime deployments, HTTP autoscaling, observability, and much more.

## Request access

Marble is currently in private beta. [Request access](https://marble.xyz) and we'll get back to you soon.

## Production > Railway

import { Callout } from "vocs/components";

# Deploy on Railway [Host a Ponder app on Railway]

[Railway](https://railway.app)'s general-purpose cloud platform is a great starting point for most Ponder apps.

## Guide

### Log in to Railway

Connect your GitHub account, and make sure that your Ponder app has been pushed to remote.

### Create a Ponder app service

From the Railway console:

1. Click **New Project** → **Deploy from GitHub repo** and select your repo from the list.
2. Click **Add variables**, then add RPC URLs (e.g. `PONDER_RPC_URL_1`) and other environment variables.
3. Create a public domain. In **Settings** → **Networking**, click **Generate Domain**.
4. Update the start command. In **Settings** → **Deploy**, set the **Custom Start Command** to include the `--schema` option. This is required to enable zero-downtime deployments. [Read more](#database#database-schema).

```bash [pnpm]
pnpm start --schema $RAILWAY_DEPLOYMENT_ID
```

```bash [yarn]
yarn start --schema $RAILWAY_DEPLOYMENT_ID
```

```bash [npm]
npm run start -- --schema $RAILWAY_DEPLOYMENT_ID
```

```bash [bun]
bun start --schema $RAILWAY_DEPLOYMENT_ID
```

5. Set the healthcheck path and timeout. In **Settings** → **Deploy**, set the **Healthcheck Path** to `/ready` and the **Healthcheck Timeout** to `3600` seconds (1 hour, the maximum allowed).

Note: _Monorepo users:_ Use the **Root Directory** and **Start Command** options
to run `ponder start` at the Ponder project root. For example, set the root directory
to `packages/ponder` or set the start command to `cd packages/ponder && pnpm start`.

### Create a Postgres database

From the new project dashboard:

1. Click **Create** → **Database** → **Add PostgreSQL**
2. Open the **Variables** tab for the Ponder app service, click **New Variable** → **Add Reference** → select `DATABASE_URL` and click **Add**

After a moment, the service running `ponder start` should redeploy successfully. Check the **Build Logs** and **Deploy Logs** tabs to debug any issues.

## Production > Self Hosting

# Self-hosting [Host a Ponder app on your own infrastructure]

In general, hosting a Ponder app is similar to hosting an ordinary Node.js web server. This section describes the key Ponder-specific quirks to consider when self-hosting in production.

## Database connection

Ponder works best with a Postgres database running in the same private network. Set the `DATABASE_URL` environment variable to the connection string of your Postgres database, or manually override the `database.connectionString` option in `ponder.config.ts`.

```ts [ponder.config.ts]
import { createConfig } from "ponder";

export default createConfig({
  database: {
    // [!code focus]
    kind: "postgres", // [!code focus]
    connectionString: "postgres://user:password@mycloud.internal:5432/database", // [!code focus]
  }, // [!code focus]
  // ...
});
```

Note: Your app will likely have performance issues if the roundtrip database latency
is greater than **50ms**. This is common when using a database in a different region or network.

## Database schema

Ponder uses **database schemas** to isolate deployments. Each deployment must use a different schema.

Use the `DATABASE_SCHEMA` environment variable or the `--schema` CLI argument to specify which database schema a deployment should use. [Read more](#database#database-schema) about database schema selection rules.

It typically makes sense to automate the database schema for each deployment. Here are a few common options.

- Kubernetes pod name
- Git branch name or commit hash
- Railway deployment ID

### Views pattern

The **views pattern** makes the _latest_ deployment's data available in a _static_ database schema using [database views](https://www.postgresql.org/docs/current/tutorial-views.html). This makes it possible to write direct SQL queries that always target the latest deployment's tables — without requiring a configuration change after each deployment.

Ponder natively supports this pattern in two ways.

- **Standalone CLI command**: The `ponder db create-views` CLI command creates (or updates) views in the target schema to point at the specified deployment's tables.
  <div className="h-3" />
  ```bash
  pnpm db create-views --schema=deployment-123 --views-schema=project-name
  ```
  <div className="h-3" />
- **Automated**: The `ponder start` command also accepts the `--views-schema` CLI flag. When specified, the deployment will run the `ponder db create-views` command automatically as soon as it becomes ready (when the backfill is complete).
  <div className="h-3" />
  ```bash
  pnpm start --schema=deployment-123 --views-schema=project-name
  ```
  <div className="h-3" />

:Note: :::details[****Additional explanation of the views pattern****]

<div className="h-[1px]" />
**Problem: Database schema changes on each deployment**

If you query Ponder tables directly, you'll soon run into a problem. On each new deployment, the schema containing the _latest_ deployment's tables (the ones you want to query) will change.

To avoid querying the wrong tables, downstream systems will need to be updated on _every_ new deployment. What a pain!

**Solution: Use database views as a "proxy"**

When you query a Ponder project over HTTP, this problem is typically solved at the orchestration layer through healthchecks, blue/green deployments, and an HTTP proxy.

To simulate the same behavior at the SQL level, Ponder supports using **database views** that always "proxy" queries to the latest deployment's tables.

## Health checks & probes

Use the `/health` and `/ready` endpoints to configure health checks or [probes](https://kubernetes.io/docs/concepts/configuration/liveness-readiness-startup-probes/).

- **`/health`**: Returns status code `200` immediately after the process starts.
- **`/ready`**: Returns status code `200` once indexing progress has reached realtime across all chains. During the backfill, this endpoint returns status code `503`.

## Crash recovery

If a Ponder app running `ponder start` crashes and restarts using the same database schema, it will attempt to resume indexing where it left off. [Read more](#api-reference-ponder-database) about the instance lifecycle and crash recovery mechanism.

## Advanced

### Resource Usage

Ponder dynamically adjusts it's memory usage based on availability. To adjust the memory limit, set the `--max-old-space-size` flag for Node.js. [Read more](https://nodejs.org/api/cli.html#--max-old-space-sizesize-in-mib).

When using `ordering: "experimental_isolated"`, Ponder will use up to 4 CPU cores to index blocks in parallel.

### Scale the HTTP server

If a `ponder start` instance receives a large volume of HTTP traffic (e.g. GraphQL requests), the HTTP server will contend with the indexing engine for CPU and memory resources. This can lead to degraded indexing performance and might ultimately crash the instance.

To solve this problem, you can use `ponder serve` to run standalone instances of the HTTP server without the indexing engine. Here are a few things to keep in mind.

- The `ponder serve` instance should use the same [database schema](#database-schema) as the `ponder start` instance that you'd like to scale.
- If one `ponder serve` instance is not enough, it's safe to run multiple replicas behind a proxy.

### Database maintenance

The `ponder db` CLI entrypoint offers a set of commands useful for observing and maintaining your database. [Read more](#api-reference-ponder-cli).

## Guides > Factory

import { Callout } from "vocs/components";

# Factory pattern [Collect a dynamic list of addresses]

The factory pattern makes it possible to index a dynamic list of contracts. You can think of the `factory()` function as returning a list of addresses that updates whenever a log is found that matches the configuration.

## Basic usage

To configure a factory, use the `factory()` function as the `address` value in a contract or account.

```ts [ponder.config.ts]
import { createConfig, factory } from "ponder"; // [!code focus]
import { parseAbiItem } from "viem";
import { SudoswapPoolAbi } from "./abis/SudoswapPool";

export default createConfig({
  chains: {
    /* ... */
  },
  contracts: {
    SudoswapPool: {
      abi: SudoswapPoolAbi,
      chain: "mainnet",
      address: factory({
        // [!code focus]
        // Address of the factory contract. // [!code focus]
        address: "0xb16c1342E617A5B6E4b631EB114483FDB289c0A4", // [!code focus]
        // Event from the factory contract ABI which contains the child address. // [!code focus]
        event: parseAbiItem("event NewPair(address poolAddress)"), // [!code focus]
        // Name of the event parameter containing the child address. // [!code focus]
        parameter: "poolAddress", // [!code focus]
      }), // [!code focus]
      startBlock: 14645816,
    },
  },
});
```

The indexing functions you register for a contract (or account) that uses `factory()` will process events for _all_ contracts (or accounts) found by the factory configuration.

Visit the [contracts](#config-contracts) and [accounts](#config-accounts) guides to learn more.

## Index the factory contract itself

It's often useful to register an indexing function for the factory event itself, e.g. to run setup logic for each child contract.

To index the factory contract itself, add a new entry to `contracts`. This entry should be a normal contract with a single address.

```ts [ponder.config.ts]
import { createConfig, factory } from "ponder";
import { parseAbiItem } from "viem";
import { SudoswapPoolAbi } from "./abis/SudoswapPool";
import { SudoswapFactoryAbi } from "./abis/SudoswapFactory";

export default createConfig({
  chains: {
    /* ... */
  },
  contracts: {
    SudoswapFactory: {
      // [!code focus]
      abi: SudoswapFactoryAbi, // [!code focus]
      chain: "mainnet", // [!code focus]
      address: "0xb16c1342E617A5B6E4b631EB114483FDB289c0A4", // [!code focus]
      startBlock: 14645816, // [!code focus]
    }, // [!code focus]
    SudoswapPool: {
      abi: SudoswapPoolAbi,
      chain: "mainnet",
      address: factory({
        address: "0xb16c1342E617A5B6E4b631EB114483FDB289c0A4",
        event: parseAbiItem("event NewPair(address poolAddress)"),
        parameter: "poolAddress",
      }),
      startBlock: 14645816,
    },
  },
});
```

```ts [src/index.ts]
import { ponder } from "ponder:registry";

// This function will run whenever a new child contract is created. // [!code focus]
ponder.on("SudoswapFactory:NewPair", async ({ event }) => {
  // [!code focus]
  // Address of the child contract that was created. // [!code focus]
  event.args.poolAddress; // [!code focus]
  //        ^? string // [!code focus]
}); // [!code focus]

ponder.on("SudoswapPool:Transfer", async ({ event }) => {
  // Address of the child contract that emitted the event.
  event.log.address;
  //        ^? string
});
```

## Multiple factories, same child

Sometimes, multiple factory contracts 1) have the same factory event signature and 2) create the same kind of child contract.

In these cases, you can pass a list of factory contract addresses to the `factory()` function, and the list of child addresses across all factories will be merged into a single list.

```ts [ponder.config.ts]
import { createConfig } from "ponder";
import { parseAbiItem } from "viem";
import { SudoswapPoolAbi } from "./abis/SudoswapPool";

export default createConfig({
  chains: {
    /* ... */
  },
  contracts: {
    SudoswapPool: {
      abi: SudoswapPoolAbi,
      chain: "mainnet",
      address: factory({
        // A list of factory contract addresses that all create SudoswapPool contracts. // [!code focus]
        address: [
          // [!code focus]
          "0xb16c1342E617A5B6E4b631EB114483FDB289c0A4", // [!code focus]
          "0xb16c1342E617A5B6E4b631EB114483FDB289c0A4", // [!code focus]
        ], // [!code focus]
        event: parseAbiItem("event NewPair(address poolAddress)"),
        parameter: "poolAddress",
      }),
    },
  },
});
```

## Usage with non-factory contracts

The factory pattern is simply a primitive that extracts a list of addresses from event logs. The contract does not have to be a "factory" in the EVM/Solidity sense (it doesn't need to create other contracts).

For example, the `ENSRegistry` contract emits the `NewResolver` event whenever a name's resolver gets set or changed. We can use this event with the factory pattern to index all resolvers that have ever been used.

```ts [ponder.config.ts]
import { createConfig, factory } from "ponder";
import { parseAbiItem } from "viem";
import { ENSResolverAbi } from "./abis/ENSResolver";

export default createConfig({
  chains: {
    /* ... */
  },
  contracts: {
    ENSResolver: {
      abi: ENSResolverAbi,
      chain: "mainnet",
      address: factory({
        // ENS Registry address
        address: "0x00000000000C2E074eC69A0dFb2997BA6C7d2e1e",
        event: parseAbiItem(
          "event NewResolver(bytes32 indexed node, address resolver)"
        ),
        parameter: "resolver",
      }),
    },
  },
});
```

## Factory block range

In some cases, the indexer needs to collect child addresses from the factory before indexing it.

In these cases, to save indexing time you can specify `startBlock` and `endBlock` of the factory separately. The `startBlock` option specifies the block number to begin collecting factory children from. The `endBlock` option specifies the block number to stop collecting factory children at. Both options default to contract's `startBlock` and `endBlock` respectively.

This separation allows you to, for example, scan the entire factory history (from its deployment) to collect all existing child contracts, while then indexing those contracts starting from a more recent block.

```ts [ponder.config.ts]
import { createConfig, factory } from "ponder"; // [!code focus]
import { parseAbiItem } from "viem";
import { SudoswapPoolAbi } from "./abis/SudoswapPool";

export default createConfig({
  chains: {
    /* ... */
  },
  contracts: {
    SudoswapPool: {
      abi: SudoswapPoolAbi,
      chain: "mainnet",
      address: factory({
        // [!code focus]
        address: "0xb16c1342E617A5B6E4b631EB114483FDB289c0A4",
        event: parseAbiItem("event NewPair(address poolAddress)"),
        parameter: "poolAddress",
        startBlock: 14645816, // [!code focus]
      }), // [!code focus]
      startBlock: "latest", // [!code focus]
    },
  },
});
```

## How it works

1. Fetch logs emitted by the factory contract that match the configuration using `eth_getLogs` in bulk.
2. Decode each log using the provided `event` ABI item and extract the child address from it using the `parameter` name.
3. Fetch the requested data for each child contract – usually, more logs using `eth_getLogs` in bulk.

## Performance

As of version `0.10`, the factory pattern introduces negligible overhead to the indexing process.

## Limitations

### Event signature requirements

The factory contract must emit an event log announcing the creation of each new child contract that contains the new child contract address as a named parameter (with type `"address"`). The parameter can be either indexed or non-indexed. Here are a few factory event signatures with their eligibility explained:

```solidity
// ✅ Eligible. The parameter "child" has type "address" and is non-indexed.
event ChildContractCreated(address child);

// ✅ Eligible. The parameter "pool" has type "address" and is indexed.
event PoolCreated(address indexed deployer, address indexed pool, uint256 fee);

// ❌ Not eligible. The parameter "contracts" is an array type, which is not supported.
// Always emit a separate event for each child contract, even if they are created in a batch.
event ContractsCreated(address[] contracts);

// ❌ Not eligible. The parameter "child" is a struct/tuple, which is not supported.
struct ChildContract {
  address addr;
}
event ChildCreated(ChildContract child);
```

### Nested factory patterns

Ponder does not support factory patterns that are nested beyond a single layer.

## Guides > Isolated Indexing

# Isolated indexing [Index each chain independently]

The **isolated** ordering mode runs each chain independently across several worker threads.

Warning: Isolated indexing is currently marked as _experimental_.

## When to use

Isolated indexing is a good choice for projects with the following characteristics.

- The project was already using `"multichain"` ordering.
- The indexing logic on each chain is **completely independent**. This means that indexing on each chain can logically proceed regardless of indexing progress on other chains.
- Backfill duration is a priority, and other performance optimizations are already in place (minimize raw SQL, minimize contract calls).

## Guide

### Enable isolated mode

To enable isolated mode, use the `ordering` option in `ponder.config.ts`.

```ts [ponder.config.ts]
import { createConfig } from "ponder";

export default createConfig({
  ordering: "experimental_isolated", // [!code focus]
  // ...
});
```

### Update primary keys

When using isolated mode, each table must have a **composite primary key** that includes a column named `chainId`. If any tables don't, the build step will fail.

In this example, the `balance` column value would represent the balance on a specific chain.

```ts [ponder.schema.ts]
import { onchainTable } from "ponder";

export const account = onchainTable(
  "account",
  (t) => ({
    chainId: t.integer().notNull(),
    address: t.hex().notNull(),
    balance: t.bigint().notNull(),
  }),
  (table) => ({ pk: primaryKey({ columns: [table.chainId, table.address] }) }) // [!code focus]
);
```

Note: Under the hood, the composite primary key design enables Ponder to use partitioned tables with one partition per chain. This design avoids any contention between concurrent writers across chains, and also speeds up queries that only access one chain.
It also generally makes sense to include the `chainId` column in index definitions.

```ts [ponder.schema.ts]
export const transferEvent = onchainTable(
  "transfer_event",
  (t) => ({
    chainId: t.integer().notNull(),
    id: t.text().notNull(),
    from: t.hex().notNull(),
    to: t.hex().notNull(),
    amount: t.bigint().notNull(),
  }),
  (table) => ({
    pk: primaryKey({ columns: [table.chainId, table.id] }), // [!code focus]
    fromIdx: index().on(table.chainId, table.from), // [!code focus]
  })
);
```

### Update indexing logic

Next, update your indexing logic to include `chainId` when inserting data using the `context.chain.id` value.

```ts [src/index.ts]
import { ponder } from "ponder:registry";

ponder.on("ERC20:Transfer", async ({ event, context }) => {
  await context.db
    .insert(account)
    .values({
      chainId: context.chain.id, // [!code focus]
      address: event.args.to,
      balance: 0,
    })
    .onConflictDoUpdate((row) => ({ balance: row.balance + event.args.value }));

  // ...
});
```

## Frequently asked questions

#### How many threads does it use?

At the moment, Ponder uses a maximum of 4 threads. If there are more than 4 chains, the chains will be distributed evenly across the 4 threads. The maximum thread count will likely be made configurable as the feature matures.

## Guides > Call Traces

# Call traces [Index call traces for a contract]

Ponder supports indexing **call traces**, which represent a _function call_ instead of an event log.

Warning: Call traces are slower, more expensive, and less widely supported than logs. You might struggle to find an RPC provider that supports `debug_traceBlockByNumber` and `debug_traceBlockByHash` for new chains.

## Guide

:::steps

### Enable call traces

To enable call traces, use the `includeCallTraces` option on the contract configuration.

```ts [ponder.config.ts]
import { createConfig } from "ponder";
import { BlitmapAbi } from "./abis/Blitmap";

export default createConfig({
  contracts: {
    Blitmap: {
      abi: BlitmapAbi,
      chain: "mainnet",
      address: "0x8d04a8c79cEB0889Bdd12acdF3Fa9D207eD3Ff63",
      startBlock: 12439123,
      includeCallTraces: true, // [!code focus]
    },
  },
  // ...
});
```

### Register an indexing function

Now, each function in the contract ABI will become available as an indexing function event name using the `"ContractName.functionName()"{:ts}` scheme.

```ts [src/index.ts]
import { ponder } from "ponder:registry";

ponder.on("Blitmap.mintOriginal()", async ({ event }) => {
  event.args;
  //    ^? [tokenData: Hex, name: string]
  event.trace.gasUsed;
  //          ^? bigint
});
```

## What is a call trace?

Let's define call traces from three different perspectives.

- **Ponder**: A call trace is similar to a log, but it represents a function call instead of an event log. You can register an indexing function that will run whenever a specific function on one of your contracts gets called.
- **Solidity**: A call trace records a function call. For example, whenever someone calls the `transfer(address to, uint256 amount){:solidity}` function of an ERC20 token contract, it produces a call trace.
- **EVM**: A call trace records the execution of the [`CALL`, `STATICCALL`, `DELEGATECALL`, or `CALLCODE`](https://www.evm.codes/#f1) opcode within a transaction.

### Top-level vs. internal calls

A call trace can be a **top-level call** or an **internal call**. A top-level call is from an externally-owned account, and an internal call is from another contract.

To check if a call trace is a top-level call, use `event.trace.traceAddress.length === 0{:ts}`.

```ts [src/index.ts]
ponder.on("ERC20.transfer()", async ({ event }) => {
  const isTopLevelCall = event.trace.traceAddress.length === 0; // [!code focus]
  // ...
});
```

Note: Top-level calls also always have `event.trace.to === event.transaction.to{:ts}`, but this can also be true for internal calls.

### `eth_call` and `view` functions

The `eth_call` RPC method **does not** produce a call trace. These calls do not occur during the execution of a transaction, so they are not recorded as call traces.

However, calls made to `view` or `pure` functions **do** produce call traces if they are made during the execution of a transaction. These call traces are rarely useful for indexing, but they do happen.

## Guides > Receipts

# Transaction receipts [Fetch transaction receipts]

A **transaction receipt** is an object containing the _post-execution_ results of a transaction, including the price and amount of gas consumed, the revert status, the logs emitted, and more.

Note: In contrast, the **transaction input** only includes _pre-execution_ data like the from and to addresses, input, and native transfer amount. Ponder includes transaction inputs automatically at `event.transaction`.

## Guide

Ponder supports transaction receipts with the `includeTransactionReceipts` option, **or** dynamic RPC requests through `context.client`.

### Include receipts for every event

Warning: Transaction receipts fetched using `includeTransactionReceipts` do not include the `logs` array.
To fetch the transaction receipt associated with every event produced by a contract, use the `includeTransactionReceipts` option.

```ts [ponder.config.ts]
import { createConfig } from "ponder";
import { BlitmapAbi } from "./abis/Blitmap";

export default createConfig({
  contracts: {
    Blitmap: {
      abi: BlitmapAbi,
      chain: "mainnet",
      address: "0x8d04a8c79cEB0889Bdd12acdF3Fa9D207eD3Ff63",
      includeTransactionReceipts: true, // [!code focus]
      startBlock: 12439123,
    },
  },
  // ...
});
```

Once enabled, the `event.transactionReceipt` object will become available in your indexing functions.

```ts [src/index.ts]
import { ponder } from "ponder:registry";

ponder.on("Blitmap:Mint", async ({ event }) => {
  console.log(event.transactionReceipt);

  // ...
});
```

### Fetch receipts ad-hoc

If you only need the transaction receipt in special cases, or you need the `logs` array, use the `context.client.getTransactionReceipt` method within your indexing function logic.

```ts [src/index.ts]
import { ponder } from "ponder:registry";

ponder.on("Blitmap:Mint", async ({ event }) => {
  const receipt = await context.client.getTransactionReceipt({
    hash: event.transaction.hash,
  });
  console.log(receipt);

  // ...
});
```

## Guides > Time Series

# Time-series data [Techniques for working with time-series data]

This guide describes techniques for working with time-series data in your app.

## Candlestick charts (bucketing)

To power a [candlestick](https://en.wikipedia.org/wiki/Candlestick_chart) or open-high-low-close chart, create a table that stores OHLC data for a specific time interval.

```ts [ponder.schema.ts]
import { onchainTable } from "ponder";

export const hourBuckets = onchainTable("hour_buckets", (t) => ({
  id: t.integer().primaryKey(),
  open: t.real().notNull(),
  close: t.real().notNull(),
  low: t.real().notNull(),
  high: t.real().notNull(),
  average: t.real().notNull(),
  count: t.integer().notNull(),
}));
```

Then, in your indexing function, create or update the bucket record that the current event falls into.

```ts [src/index.ts]
import { ponder, type Schema } from "ponder:registry";

const secondsInHour = 60 * 60;

ponder.on("Token:Swap", async ({ event, context }) => {
  const { timestamp } = event.block;
  const { price } = event.args;

  const hourId = Math.floor(timestamp / secondsInHour) * secondsInHour;

  await context.db
    .insert(hourBuckets)
    .values({
      id: hourId,
      open: price,
      close: price,
      low: price,
      high: price,
      average: price,
      count: 1,
    })
    .onConflictDoUpdate((row) => ({
      close: price,
      low: Math.min(row.low, price),
      high: Math.max(row.high, price),
      average: (row.average * row.count + price) / (row.count + 1),
      count: row.count + 1,
    }));
});
```

Here are GraphQL and SQL queries that return the last 48 hours of OHLC data. These queries could be used to power a chart on your frontend.

```graphql [GraphQL query]
{
  hourBuckets(orderBy: { id: "desc" }, limit: 48) {
    items {
      id
      open
      close
      low
      high
      average
      count
    }
  }
}
```

```sql [SQL query]
SELECT *
  FROM "HourBucket"
  ORDER BY id DESC
  LIMIT 48;
```

## Include `block.timestamp`

The simplest way to add a time dimension to your data is to include the block number or block timestamp (or both!) as a column.

```ts [ponder.schema.ts]
import { onchainTable } from "ponder";

export const swapEvents = onchainTable("swap_events", (t) => ({
  id: t.text().primaryKey(),
  from: t.hex().notNull(),
  to: t.hex().notNull(),
  amount: t.bigint().notNull(),
  timestamp: t.bigint().notNull(),
}));
```

```ts [src/index.ts]
import { ponder } from "ponder:registry";
import { swapEvents } from "ponder:schema";

ponder.on("Token:Swap", async ({ event, context }) => {
  await context.db.insert(swapEvents).values({
    id: event.id,
    from: event.args.from,
    to: event.args.to,
    amount: event.args.amount,
    timestamp: event.block.timestamp, // [!code focus]
  });
});
```

Now, you can use the `timestamp` column to filter and sort data over different time intervals.

```graphql [GraphQL query]
{
  swapEvents(
    orderBy: { timestamp: "desc" }
    where: { timestamp_gt: 1712500000, timestamp_lt: 1713000000 }
  ) {
    items {
      id
      from
      to
      amount
      timestamp
    }
  }
}
```

## Guides > Offchain Data

# Offchain data [Combine onchain and offchain data]

Ponder supports querying onchain data (Ponder-managed tables) alongside offchain data (other tables in the same PostgreSQL database) using Drizzle.

Note: Ponder does not support reading or writing offchain data within indexing functions. This guide only applies to read-only SQL queries from custom API endpoints or standalone Node.js code.

## Setup

### Define the Ponder schema

Create a `ponder.schema.ts` file in your Ponder project. No special configuration is required.

```ts [ponder.schema.ts]
import { onchainTable } from "ponder";

export const account = onchainTable("account", (t) => ({
  address: t.hex().primaryKey(),
}));

export const token = onchainTable("token", (t) => ({
  id: t.bigint().primaryKey(),
  owner: t.hex().notNull(),
}));

export const transferEvent = onchainTable("transfer_event", (t) => ({
  id: t.text().primaryKey(),
  timestamp: t.integer().notNull(),
  from: t.hex().notNull(),
  to: t.hex().notNull(),
  token: t.bigint().notNull(),
}));
```

### Define the offchain schema

Next, create a schema definition file for the offchain data using Drizzle ([docs](https://orm.drizzle.team/docs/sql-schema-declaration#example)).

```ts [offchain.ts]
import { json, numeric, pgSchema } from "drizzle-orm/pg-core";

export const offchainSchema = pgSchema("offchain");

export const metadataTable = offchainSchema.table("metadata", {
  tokenId: numeric({ precision: 78, scale: 0 }).primaryKey(),
  metadata: json(),
});
```

Note: Be sure to use the same `drizzle-orm` version that your installed version of `ponder` uses. At time of writing, this is `drizzle-orm@0.41.0`.

### Combine the schemas

In a separate file, combine the onchain and offchain schemas. You can also define Drizzle relations that connect tables across the two schemas.

```ts [schema.ts]
import { setDatabaseSchema } from "@ponder/client";
import { relations } from "drizzle-orm";
import * as ponderSchema from "./ponder.schema";
import * as offchainSchema from "./offchain";

setDatabaseSchema(ponderSchema, "prod");

export const metadataRelations = relations(
  offchainSchema.metadataTable,
  ({ one }) => ({
    token: one(ponderSchema.token, {
      fields: [offchainSchema.metadataTable.tokenId],
      references: [ponderSchema.token.id],
    }),
  })
);

export const schema = {
  ...offchainSchema,
  ...ponderSchema,
  metadataRelations,
};
```

Note: Set the _database schema_ for Ponder tables and enums explicitly using `setDatabaseSchema`. To avoid having to update the schema name for each deployment, use the [views pattern](#production-self-hosting#views-pattern).

## Query

### From Node.js

Once you've defined the combined schema, you can start writing queries from any Node.js code.

```ts [index.ts]
import { drizzle } from "drizzle-orm/node-postgres";
import { schema } from "./schema";

export const db = drizzle(process.env.DATABASE_URL!, { schema });

const result = await db.query.metadataTable.findMany({
  with: {
    token: true,
  },
});

console.log(result);
```

### From Ponder API endpoints

It's also possible to query offchain (or combined) data directly from custom API endpoints.

```ts [api/index.ts]
import { Hono } from "hono";
import { db } from "ponder:api";
import * as offchainSchema from "../../offchain";

const app = new Hono();

app.post("/new-metadata", async (c) => {
  const { tokenId, metadata } = await c.req.json();
  await db.insert(offchainSchema.metadataTable).values({
    tokenId,
    metadata,
  });
});

export default app;
```

## Guides > Foundry

# Foundry [Use Ponder with Foundry]

Ponder works with Anvil, the local development chain included with Foundry.

Foundry projects follow various development workflows (test-driven, deploy to a fresh chain, deploy to a fork, etc). This guide offers patterns that you can adapt to your specific requirements.

## Configure the `anvil` chain

### Disable caching

Ponder's RPC request cache works well for live chains where the chain is generally immutable, but causes issues when indexing a local chain that "resets".

Use the `disableCache` option to **disable RPC request caching** for the Anvil chain. With this option set to true, Ponder will clear the cache on start up and between hot reloads.

```ts [ponder.config.ts]
import { createConfig } from "ponder";

export default createConfig({
  chains: {
    anvil: {
      id: 31337,
      rpc: "http://127.0.0.1:8545",
      disableCache: true, // [!code hl]
    },
  },
  // ...
});
```

### Chain ID

We recommend using `31337` (the default Anvil chain ID) even when forking a live chain. This avoids common footguns when working with multiple chains.

### Mining mode

We recommend using [interval mining](https://book.getfoundry.sh/reference/anvil/#mining-modes) with a block time of ~2 seconds. This better simulates a live chain.

Warning: Known issue: When indexing Anvil with auto mining enabled in an app with
multiple chains, indexing progress will get "stuck" at the timestamp of the
latest Anvil block.

## Generate ABI files

To enable end-to-end type safety, the contract ABIs generated by Foundry must be copied into TypeScript (`.ts`) source files.

### Wagmi CLI

The Wagmi CLI [Foundry plugin](https://wagmi.sh/cli/api/plugins/foundry) is an excellent tool to automate tedious ABI file management. For more information, visit the [Wagmi CLI documentation](https://wagmi.sh/cli/getting-started).

Here is the Wagmi CLI config file used by the Foundry [example project](https://github.com/ponder-sh/ponder/tree/main/examples/with-foundry).

```ts [wagmi.config.ts]
import { defineConfig } from "@wagmi/cli";
import { foundry } from "@wagmi/cli/plugins";

export default defineConfig({
  out: "abis/CounterAbi.ts",
  plugins: [
    foundry({
      project: "foundry",
      include: ["Counter.sol/**"],
    }),
  ],
});
```

## Import broadcast files

Foundry scripts write transaction inputs and receipts to JSON files in the `broadcast` directory. You can import these files directly into `ponder.config.ts` to automate address management and enable hot reloading.

Note: Remember to enable
[broadcast](https://book.getfoundry.sh/guides/scripting-with-solidity#deploying-to-a-local-anvil-instance)
so that `forge script` submits transactions to Anvil.

### Automate address management

To read the contract address and deployment block number from a broadcast file, import the file directly into `ponder.config.ts` and access properties from the JSON object.

The `ponder.config.ts` file from the Foundry [example project](https://github.com/ponder-sh/ponder/tree/main/examples/with-foundry) demonstrates this pattern. Here, the first transaction in the broadcast file deployed the `Counter.sol` contract. The location of the contract address and start block within the broadcast file depends on the order and number of transactions in your deployment script.

```ts [ponder.config.ts]
import { createConfig } from "ponder";
import { http, getAddress, hexToNumber } from "viem";
import { counterABI } from "../abis/CounterAbi";
import CounterDeploy from "../foundry/broadcast/Deploy.s.sol/31337/run-latest.json"; // [!code focus]

const address = getAddress(CounterDeploy.transactions[0]!.contractAddress); // [!code focus]
const startBlock = hexToNumber(CounterDeploy.receipts[0]!.blockNumber); // [!code focus]

export default createConfig({
  chains: {
    anvil: {
      id: 31337,
      rpc: "http://127.0.0.1:8545",
      disableCache: true,
    },
  },
  contracts: {
    Counter: {
      chain: "anvil",
      abi: counterABI,
      address, // [!code focus]
      startBlock, // [!code focus]
    },
  },
});
```

### Enable hot reloading

If you import a JSON broadcast file in `ponder.config.ts`, the dev server will reload each time that file changes. This is a simple way to ensure that Ponder reloads every time you run a Foundry deployment script.

```ts [ponder.config.ts]
import { createConfig } from "ponder";
import CounterDeploy from "../foundry/broadcast/Deploy.s.sol/31337/run-latest.json"; // [!code focus]
// [!code focus] // ^ The development server detects changes to this file and triggers a hot reload.

export default createConfig({
  // ...
});
```

## Api Reference > Create Ponder

# `create-ponder` [API reference]

The `create-ponder` CLI tool is the easiest way to get started with Ponder.

It asks a few questions, then creates a new Ponder project in the specified directory including all required files (`package.json`, `ponder.config.ts`, ABIs, etc).

```bash [pnpm]
pnpm create ponder {...options}
```

```bash [yarn]
yarn create ponder {...options}
```

```bash [npm]
npm init ponder@latest {...options}
```

```bash [bun]
bun --bun create ponder {...options}
```

## Options

```sh
Usage:
  $ create-ponder <directory> [options]

Options:
  -t, --template [id]             Use a template
  --npm                           Use npm as your package manager
  --pnpm                          Use pnpm as your package manager
  --yarn                          Use yarn as your package manager
  --skip-git                      Skip initializing a git repository
  --skip-install                  Skip installing packages
  -h, --help                      Display this message
  -v, --version                   Display version number
```

## Templates

Templates help get you started faster by copying contract addresses, ABIs, and deployment blocks from an existing source.

### Example projects

The `-t, --template [id]` option creates a new project from one of the [example projects](https://github.com/ponder-sh/ponder/tree/main/examples).
For example, this command creates a project using the `feature-factory` example project.

```bash [pnpm]
pnpm create ponder --template feature-factory
```

```bash [yarn]
yarn create ponder --template feature-factory
```

```bash [npm]
npm init ponder@latest --template feature-factory
```

```bash [bun]
bun --bun create ponder --template feature-factory
```

Here are the available projects:

| Name                   | Template ID              | Link                                                                                      |
| :--------------------- | :----------------------- | :---------------------------------------------------------------------------------------- |
| Factory contract       | feature-factory          | [GitHub](https://github.com/ponder-sh/ponder/tree/main/examples/feature-factory)          |
| Custom event filter    | feature-filter           | [GitHub](https://github.com/ponder-sh/ponder/tree/main/examples/feature-filter)           |
| Multiple chains        | feature-multichain       | [GitHub](https://github.com/ponder-sh/ponder/tree/main/examples/feature-multichain)       |
| Proxy contract         | feature-proxy            | [GitHub](https://github.com/ponder-sh/ponder/tree/main/examples/feature-proxy)            |
| Contract calls         | feature-read-contract    | [GitHub](https://github.com/ponder-sh/ponder/tree/main/examples/feature-read-contract)    |
| Friendtech project     | project-friendtech       | [GitHub](https://github.com/ponder-sh/ponder/tree/main/examples/project-friendtech)       |
| Uniswap V3 flash loans | project-uniswap-v3-flash | [GitHub](https://github.com/ponder-sh/ponder/tree/main/examples/project-uniswap-v3-flash) |
| Basic ERC20 token      | reference-erc20          | [GitHub](https://github.com/ponder-sh/ponder/tree/main/examples/reference-erc20)          |
| Basic ERC721 token     | reference-erc721         | [GitHub](https://github.com/ponder-sh/ponder/tree/main/examples/reference-erc721)         |

## Api Reference > Ponder > Cli

# `ponder` CLI [API reference]

The CLI (provided by the `ponder` package) is the entrypoint for your project.

```bash
Usage: ponder <command> [OPTIONS]

Options:
  --root <PATH>          Path to the project root directory (default: working directory)
  --config <PATH>        Path to the project config file (default: "ponder.config.ts")
  -v, --debug            Enable debug logs, e.g. realtime blocks, internal events
  -vv, --trace           Enable trace logs, e.g. db queries, indexing checkpoints
  --log-level <LEVEL>    Minimum log level ("error", "warn", "info", "debug", or "trace", default: "info")
  --log-format <FORMAT>  The log format ("pretty" or "json") (default: "pretty")
  -V, --version          Show the version number
  -h, --help             Show this help message

Commands:
  dev [options]          Start the development server with hot reloading
  start [options]        Start the production server
  serve [options]        Start the production HTTP server without the indexer
  db                     Database management commands
  codegen                Generate the ponder-env.d.ts file, then exit
```

## dev

Start the app in development mode.

- The app automatically restarts when changes are detected in any project file.
- An auto-updating terminal UI displays useful information.

```bash
Usage: ponder dev [options]

Start the development server with hot reloading

Options:
  --schema <SCHEMA>          Database schema (max: 45 characters)
  --disable-ui               Disable the terminal UI
  -p, --port <PORT>          Port for the web server (default: 42069)
  -H, --hostname <HOSTNAME>  Hostname for the web server (default: "0.0.0.0" or "::")
  -h, --help                 display help for command
```

## start

Start the app in production mode.

- Project files are built once on startup, and file changes are ignored.
- The terminal UI is disabled.

```bash
Usage: ponder start [options]

Start the production server

Options:
  --schema <SCHEMA>          Database schema (max: 45 characters)
  --views-schema <SCHEMA>    Views database schema (max: 45 characters)
  -p, --port <PORT>          Port for the web server (default: 42069)
  -H, --hostname <HOSTNAME>  Hostname for the web server (default: "0.0.0.0" or "::")
  -h, --help                 display help for command
```

## serve

Start the app in server-only mode. This option can be used to horizontally scale the HTTP server in production.

- Only works with Postgres.
- Project files are built once on startup, and file changes are ignored.
- Indexing is disabled.
- The HTTP server runs as normal, serving data from the connected database.

```bash
Usage: ponder serve [options]

Start the production HTTP server without the indexer

Options:
  --schema <SCHEMA>          Database schema (max: 45 characters)
  -p, --port <PORT>          Port for the web server (default: 42069)
  -H, --hostname <HOSTNAME>  Hostname for the web server (default: "0.0.0.0" or "::")
  -h, --help                 display help for command
```

## codegen

Write or update the `ponder-env.d.ts` file.

```bash
Usage: ponder codegen [options]

Generate the ponder-env.d.ts file, then exit

Options:
  -h, --help  display help for command
```

## db

Database management commands.

### create-views

Creates views for the views pattern. [Read more](#production-self-hosting#views-pattern).

```bash
Usage: ponder create-views [options]

Create database views for the views pattern

Options:
  --schema <SCHEMA>          Database schema (max: 45 characters)
  --views-schema <SCHEMA>    Views database schema (max: 45 characters)
  -h, --help                 display help for command
```

### list

List all `ponder start` instances that have ever ran in the connected database.

```bash
Usage: ponder db list [options]

List all Ponder deployments

Options:
  -h, --help  display help for command
```

```bash [Result]
│ Schema        │ Active   │ Last active    │ Table count │
├───────────────┼──────────┼────────────────┼─────────────┤
│ indexer_prod  │      yes │            --- │          10 │
│ test          │       no │    26m 58s ago │          10 │
│ demo          │       no │      1 day ago │           5 │
```

### prune

Drop all database tables, functions, and schemas created by Ponder deployments that are not currently active.

```bash
Usage: ponder db prune [options]

Drop all database tables, functions, and schemas created by Ponder deployments that are not active

Options:
  -h, --help  display help for command
```

## Api Reference > Ponder > Config

# `ponder.config.ts` [API reference]

Note: This is a low-level reference. For an introduction, visit the
different config sections: [Chains](#config-chains), [Contracts](#config-contracts), [Accounts](#config-accounts), [Block intervals](#config-block-intervals).
The `ponder.config.ts` file defines chain IDs, RPC URLs, contract addresses & ABIs, and database configuration.

## File requirements

The `ponder.config.ts` file must **default export** the object returned by `createConfig`.

{/_ prettier-ignore _/}

```ts [ponder.config.ts] {1,4}
import { createConfig } from "ponder";

export default createConfig({
  chains: {
    /* ... */
  },
  contracts: {
    /* ... */
  },
});
```

By default, `ponder dev` and `start` look for `ponder.config.ts` in the current working directory. Use the `--config-file` CLI option to specify a different path.

## `createConfig`

### `database`

Here is the logic Ponder uses to determine which database to use:

- If the `database.kind` option is specified, use the specified database.
- If the `DATABASE_URL` environment variable is defined, use Postgres with that connection string.
- If `DATABASE_URL` is not defined, use PGlite.

| field    |           type           |                                          |
| :------- | :----------------------: | :--------------------------------------- |
| **kind** | `"pglite" \| "postgres"` | **Default: See above.** Database to use. |

#### PGlite

| field         |    type    |                                                                                 |
| :------------ | :--------: | :------------------------------------------------------------------------------ |
| **kind**      | `"pglite"` |                                                                                 |
| **directory** |  `string`  | **Default: `.ponder/pglite`**. Directory path to use for PGlite database files. |

```ts [ponder.config.ts] {4-7}
import { createConfig } from "ponder";

export default createConfig({
  database: {
    kind: "pglite",
    directory: "./.ponder/pglite",
  },
  // ...
});
```

#### Postgres

| field                |                        type                         |                                                                           |
| :------------------- | :-------------------------------------------------: | :------------------------------------------------------------------------ |
| **kind**             |                    `"postgres"`                     |                                                                           |
| **connectionString** |                      `string`                       | **Default: `DATABASE_URL` env var**. Postgres database connection string. |
| **poolConfig**       | [`PoolConfig`](https://node-postgres.com/apis/pool) | **Default: `{ max: 30 }`**. Pool configuration passed to `node-postgres`. |

```ts [ponder.config.ts] {4-10}
import { createConfig } from "ponder";

export default createConfig({
  database: {
    kind: "postgres",
    connectionString: "postgresql://user:password@localhost:5432/dbname",
    poolConfig: {
      max: 100,
      ssl: true,
    },
  },
  // ...
});
```

### `ordering`

Specifies how events across multiple chains should be ordered. For single-chain apps, `ordering` has no effect.

#### Usage

```ts [ponder.config.ts] {4}
import { createConfig } from "ponder";

export default createConfig({
  ordering: "multichain",
  chains: {
    /* ... */
  },
  // ... more config
});
```

#### Parameters

| field        |                           type                           |                             |
| :----------- | :------------------------------------------------------: | :-------------------------- |
| **ordering** | `"omnichain" \| "multichain" \| "experimental_isolated"` | **Default:** `"multichain"` |

#### Guarantees

The ordering strategies offer different guarantees. Omnichain ordering combines all chains into a single, unified stream of events. Multichain and isolated ordering treat each chain independently, with isolated enforcing additional constraints but taking advantage of multiple CPU cores for better performance.

Note: Isolated ordering (experimental): When using ordering: "experimental_isolated", all tables in your schema must include a chainId column that is part of the primary key. This ensures complete isolation between chains and prevents any cross-chain data access.
| | Omnichain | Multichain (default) | Isolated |
| :----------------------------------- | :-------------------------------------------------------------------------- | :--------------------------------------------------------- | :--------------------------------------------------------- |
| Event order for any individual chain | Deterministic, by EVM execution | Deterministic, by EVM execution | Deterministic, by EVM execution |
| Event order across chains | Deterministic, by (block timestamp, chain ID, block number) | Non-deterministic, no ordering guarantee | Non-deterministic, no ordering guarantee |
| Live indexing latency | Medium-high, must wait for the slowest chain to maintain ordering guarantee | Low, each chain indexes blocks as soon as they arrive | Low, each chain is processed independently |
| Indexing logic constraints | None | Must avoid cross-chain writes **or** use commutative logic | Cross-chain reads and write are no possible |
| Use cases | Bridges, cross-chain contract calls, global constraints | Same protocol deployed to multiple chains | Same protocol deployed to multiple chains |

### `chains`

An object mapping chain names to chain configuration.

Warning: Most Ponder apps require a paid RPC provider plan to avoid rate limits.

#### Usage

```ts [ponder.config.ts]
import { createConfig } from "ponder";
import { BlitmapAbi } from "./abis/Blitmap";

export default createConfig({
  chains: {
    // [!code focus]
    mainnet: {
      // [!code focus]
      id: 1, // [!code focus]
      rpc: process.env.PONDER_RPC_URL_1, // [!code focus]
      ws: process.env.PONDER_WS_URL_1, // [!code focus]
    }, // [!code focus]
  }, // [!code focus]
  // ...
});
```

#### Parameters

| field                    |               type                |                                                                                                                                                                                 |
| :----------------------- | :-------------------------------: | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **name**                 |             `string`              | **Required**. A unique name for the chain. Must be unique across all chains. _Provided as the object property name._                                                            |
| **id**                   |             `number`              | **Required**. The [chain ID](https://chainlist.org) for the chain.                                                                                                              |
| **rpc**                  | `string \| string[] \| Transport` | **Required**. One or more RPC endpoints or a Viem [Transport](https://viem.sh/docs/clients/transports/http) e.g. `http` or `fallback`.                                          |
| **ws**                   |             `string`              | **Default: `undefined`**. A webSocket endpoint for realtime indexing on this chain.                                                                                             |
| **pollingInterval**      |             `number`              | **Default: `1_000`**. Frequency (in ms) used when polling for new events on this chain.                                                                                         |
| **disableCache**         |             `boolean`             | **Default: `false`**. Disables the RPC request cache. Use when indexing a [local node](#guides-foundry) like Anvil.                                                             |
| **ethGetLogsBlockRange** |             `number`              | **Default: `undefined`**. Maximum block range for `eth_getLogs` requests. If undefined, Ponder will attempt to determine the block range automatically based on error messages. |

### `contracts`

An object mapping contract names to contract configuration. Ponder will fetch RPC data and run indexing functions according to the options you provide.

#### Usage

```ts [ponder.config.ts]
import { createConfig } from "ponder";
import { BlitmapAbi } from "./abis/Blitmap";

export default createConfig({
  contracts: {
    // [!code focus]
    Blitmap: {
      // [!code focus]
      abi: BlitmapAbi, // [!code focus]
      chain: "mainnet", // [!code focus]
      address: "0x8d04a8c79cEB0889Bdd12acdF3Fa9D207eD3Ff63", // [!code focus]
      startBlock: 12439123, // [!code focus]
    }, // [!code focus]
  }, // [!code focus]
  // ...
});
```

#### Parameters

| field                          |                  type                   |                                                                                                                                                                                                                                        |
| :----------------------------- | :-------------------------------------: | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **name**                       |                `string`                 | **Required**. A unique name for the smart contract. Must be unique across all contracts. _Provided as the object property name._                                                                                                       |
| **abi**                        |              `abitype.Abi`              | **Required**. The contract [ABI](https://docs.soliditylang.org/en/v0.8.17/abi-spec.html) as an array as const. Must be asserted as constant, see [ABIType documentation](https://abitype.dev/guide/getting-started#usage) for details. |
| **chain**                      |         `string \| ChainConfig`         | **Required**. The name of the chain this contract is deployed to. References the `chains` field. Also supports [multiple chains](#config-contracts#multiple-chains).                                                                   |
| **address**                    | `0x{string} \| 0x{string}[] \| Factory` | **Default: `undefined`**. One or more contract addresses or factory configuration.                                                                                                                                                     |
| **startBlock**                 |          `number \| "latest"`           | **Default: `0`**. Block number or tag to start indexing. Usually set to the contract deployment block number.                                                                                                                          |
| **endBlock**                   |          `number \| "latest"`           | **Default: `undefined`**. Block number or tag to stop indexing. If this field is specified, the contract will not be indexed in realtime. This field can be used alongside `startBlock` to index a specific block range.               |
| **filter**                     |           [`Filter`](#filter)           | **Default: `undefined`**. Event filter criteria. [Read more](#config-contracts#filter-by-indexed-parameter-value).                                                                                                                     |
| **includeTransactionReceipts** |                `boolean`                | **Default: `false`**. If this field is `true`, `transactionReceipt` will be included in `event`.                                                                                                                                       |
| **includeCallTraces**          |                `boolean`                | **Default: `false`**. If this field is `true`, each function in the abi will be available as an indexing function event name. [Read more](#guides-call-traces).                                                                        |

#### `filter`

Note: The `filter` option is typically only necessary if you have not specified an
`address`. By default, Ponder only fetches and indexes events for which you
have registered an indexing function.
The `filter` option is used to filter event logs by argument value. [Read more](#config-contracts#filter-by-indexed-parameter-value) about log filters.

| field     |         type         |                                                                                                                                       |
| :-------- | :------------------: | :------------------------------------------------------------------------------------------------------------------------------------ |
| **event** | `string \| string[]` | **Required**. One or more event names present in the provided ABI.                                                                    |
| **args**  |       `object`       | **Required**. An object containing indexed argument values to filter for. Only allowed if **one** event name was provided in `event`. |

### `accounts`

An object mapping account names to account configuration. Accounts are used to index transactions or native transfers.

#### Usage

```ts [ponder.config.ts]
import { createConfig } from "ponder";

export default createConfig({
  accounts: {
    // [!code focus]
    coinbasePrime: {
      // [!code focus]
      chain: "mainnet", // [!code focus]
      address: "0xCD531Ae9EFCCE479654c4926dec5F6209531Ca7b", // [!code focus]
      startBlock: 12111233, // [!code focus]
    }, // [!code focus]
  }, // [!code focus]
  // ...
});
```

#### Parameters

| field                          |                  type                   |                                                                                                                                                                                                                         |
| :----------------------------- | :-------------------------------------: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **name**                       |                `string`                 | **Required**. A unique name for the smart contract. Must be unique across all contracts. _Provided as the object property name._                                                                                        |
| **chain**                      |                `string`                 | **Required**. The name of the chain this contract is deployed to. References the `chains` field. Also supports [multiple chains](#config-contracts#chain).                                                              |
| **address**                    | `0x{string} \| 0x{string}[] \| Factory` | **Default: `undefined`**. One or more contract addresses or factory configuration.                                                                                                                                      |
| **startBlock**                 |                `number`                 | **Default: `0`**. Block number to start syncing events.                                                                                                                                                                 |
| **endBlock**                   |                `number`                 | **Default: `undefined`**. Block number to stop syncing events. If this field is specified, the contract will not be indexed in realtime. This field can be used alongside `startBlock` to index a specific block range. |
| **includeTransactionReceipts** |                `boolean`                | **Default: `false`**. If this field is `true`, `transactionReceipt` will be included in `event`.                                                                                                                        |

### `blocks`

An object mapping block interval names to block interval configuration.

#### Usage

```ts [ponder.config.ts]
import { createConfig } from "ponder";

export default createConfig({
  blocks: {
    // [!code focus]
    ChainlinkPriceOracle: {
      // [!code focus]
      chain: "mainnet", // [!code focus]
      startBlock: 19_750_000, // [!code focus]
      interval: 5, // [!code focus] every minute
    }, // [!code focus]
  }, // [!code focus]
  // ...
});
```

#### Parameters

| field          |   type   |                                                                                                                                                                                                                         |
| :------------- | :------: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **name**       | `string` | **Required**. A unique name for the block interval. Must be unique across all block intervals. _Provided as the object property name._                                                                                  |
| **chain**      | `string` | **Required**. The name of the chain this block interval is deployed to. References the `chains` field. Also supports [multiple chains](#config-contracts#chain).                                                        |
| **startBlock** | `number` | **Default: `0`**. Block number to start syncing events.                                                                                                                                                                 |
| **endBlock**   | `number` | **Default: `undefined`**. Block number to stop syncing events. If this field is specified, the contract will not be indexed in realtime. This field can be used alongside `startBlock` to index a specific block range. |
| **interval**   | `number` | **Default: `0`**. The interval between blocks to index.                                                                                                                                                                 |

## `factory`

Specifies a list of addresses collected from decoded event logs. Both [`contracts`](#contracts) and [`accounts`](#accounts) support `factory()` in their `address` field. [Read more](#guides-factory) in the factory pattern guide.

| field         |                         type                         |                                                                                            |
| :------------ | :--------------------------------------------------: | :----------------------------------------------------------------------------------------- |
| **address**   |      `0x{string} \| 0x{string}[] \| undefined`       | **Optional**. Address of the factory contract that creates instances of this contract.     |
| **event**     | [`AbiEvent`](https://abitype.dev/api/types#abievent) | **Required**. ABI item of the event that announces the creation of a new child contract.   |
| **parameter** |                       `string`                       | **Required**. Name of the parameter within `event` that contains child contract addresses. |

```ts [ponder.config.ts] {8-14}
import { createConfig, factory } from "ponder"; // [!code focus]

export default createConfig({
  contracts: {
    uniswapV2: {
      // ...
      address: factory({
        // [!code focus]
        address: "0x5C69bEe701ef814a2B6a3EDD4B1652CB9cc5aA6f", // [!code focus]
        event: parseAbiItem(
          // [!code focus]
          "event PairCreated(address indexed token0, address indexed token1, address pair, uint256)" // [!code focus]
        ), // [!code focus]
        parameter: "pair", // [!code focus]
      }), // [!code focus]
    },
  },
  // ...
});
```

## Types

The `ponder` package exports several utility types. Use these types to maintain type safety when generating config options dynamically.

### DatabaseConfig

```ts [ponder.config.ts] {1,6}
import { createConfig, type DatabaseConfig } from "ponder"; // [!code focus]

const database = {
  // [!code focus]
  kind: "postgres", // [!code focus]
  connectionString: process.env.DATABASE_URL, // [!code focus]
} as const satisfies DatabaseConfig; // [!code focus]

export default createConfig({
  database,
  // ...
});
```

### ChainConfig

```ts [ponder.config.ts]
import { createConfig, type ChainConfig } from "ponder"; // [!code focus]

const mainnet = {
  // [!code focus]
  id: 1, // [!code focus]
  rpc: process.env.PONDER_RPC_URL_1, // [!code focus]
  ws: process.env.PONDER_WS_URL_1, // [!code focus]
} as const satisfies ChainConfig; // [!code focus]

export default createConfig({
  chains: {
    mainnet,
  },
  // ...
});
```

### ContractConfig

```ts [ponder.config.ts] {1}
import { createConfig, type ContractConfig } from "ponder"; // [!code focus]
import { Erc20Abi } from "./abis/Erc20Abi.ts";

const Erc20 = { // [!code focus]
  chain: "mainnet" // [!code focus]
  abi: Erc20Abi, // [!code focus]
  address: "0xC02aaA39b223FE8D0A0e5C4F27eAD9083C756Cc2", // [!code focus]
} as const satisfies ContractConfig; // [!code focus]

export default createConfig({
  contracts: {
    Erc20,
  },
  // ...
});
```

### BlockConfig

```ts [ponder.config.ts]
import { createConfig, type BlockConfig } from "ponder"; // [!code focus]

const ChainlinkPriceOracle = {
  // [!code focus]
  chain: "mainnet", // [!code focus]
  startBlock: 19_750_000, // [!code focus]
  interval: 5, // [!code focus]
} as const satisfies BlockConfig; // [!code focus]

export default createConfig({
  blocks: {
    ChainlinkPriceOracle,
  },
  // ...
});
```

## Api Reference > Ponder > Schema

# `ponder.schema.ts` [API reference]

Note: This is a low-level reference. For an introduction and guides, visit the
[Schema](#schema-tables) section.
The `ponder.schema.ts` file defines your database tables and their relationships. Each table you include in `ponder.schema.ts` will be created as an SQL table, populated during indexing, and exposed via the GraphQL API.

## File requirements

The `ponder.schema.ts` must use **named exports** for tables, enums, and relations. These objects must be created using the correct functions exported from `"ponder"{:ts}`.

```ts [ponder.schema.ts] {1,3}
import { onchainTable } from "ponder";

export const pets = onchainTable("pets", (t) => ({
  name: t.text().primaryKey(),
  age: t.integer().notNull(),
}));
```

## `onchainTable`

The `onchainTable` function accepts three positional arguments.

| field           |                      type                      | description                                                                               |
| :-------------- | :--------------------------------------------: | :---------------------------------------------------------------------------------------- |
| **name**        |                    `string`                    | The SQL table name. Use `snake_case`. Maximum of 45 characters.                           |
| **columns**     | `(t: TableBuilder) => Record<string, Column>`  | A function that returns column definitions.                                               |
| **constraints** | `(table: Table) => Record<string, Constraint>` | Optional function that returns table constraints like composite primary keys and indexes. |

{/_ prettier-ignore _/}

```ts [ponder.schema.ts]
import { onchainTable } from "ponder";

export const transferEvents = onchainTable(
  "transfer_event", // SQL table name
  (t) => ({
    // Column definitions
    id: t.text().primaryKey(),
    from: t.hex().notNull(),
    to: t.hex().notNull(),
    value: t.bigint().notNull(),
  }),
  (table) => ({
    // Constraints & indexes
    fromIdx: index().on(table.from),
  })
);
```

### Column types

The schema definition API supports most PostgreSQL data types. Here's a quick reference for the most commonly used data types. For a complete list, visit the [Drizzle documentation](https://orm.drizzle.team/docs/column-types/pg).

| name             | description                                  | TypeScript type          | SQL data type         |
| :--------------- | :------------------------------------------- | :----------------------- | :-------------------- |
| `text{:ts}`      | UTF‐8 character sequence                     | `string`                 | `TEXT{:sql}`          |
| `integer{:ts}`   | Signed 4‐byte integer                        | `number`                 | `INTEGER{:sql}`       |
| `real{:ts}`      | Signed 4-byte floating‐point value           | `number`                 | `REAL{:sql}`          |
| `boolean{:ts}`   | `true` or `false`                            | `boolean`                | `BOOLEAN{:sql}`       |
| `timestamp{:ts}` | Date and time value (no time zone)           | `Date`                   | `TIMESTAMP{:sql}`     |
| `json{:ts}`      | JSON object                                  | `any` or [custom](#json) | `JSON{:sql}`          |
| `bigint{:ts}`    | Large integer (holds `uint256` and `int256`) | `bigint`                 | `NUMERIC(78,0){:sql}` |
| `hex{:ts}`       | UTF‐8 character sequence with `0x` prefix    | `0x${string}`            | `TEXT{:sql}`          |

### Column modifiers

Column modifiers can be chained after column type definitions.

| modifier                      | description                                    |
| :---------------------------- | :--------------------------------------------- |
| `.primaryKey(){:ts}`          | Marks column as the table's primary key        |
| `.notNull(){:ts}`             | Marks column as NOT NULL                       |
| `.array(){:ts}`               | Marks column as an array type                  |
| `.default(value){:ts}`        | Sets a default value for column                |
| `.$default(() => value){:ts}` | Sets a dynamic default via function            |
| `.$type<T>(){:ts}`            | Annotates column with a custom TypeScript type |

### Constraints

#### Primary key

Every table must have exactly one primary key defined using either the `.primaryKey()` column modifier or the `primaryKey()` function in the table constraints argument.

```ts [ponder.schema.ts] {1, 5, 16}
import { onchainTable, primaryKey } from "ponder";

// Single column primary key
export const tokens = onchainTable("tokens", (t) => ({
  id: t.bigint().primaryKey(),
}));

// Composite primary key
export const poolStates = onchainTable(
  "pool_states",
  (t) => ({
    poolId: t.bigint().notNull(),
    address: t.hex().notNull(),
  }),
  (table) => ({
    pk: primaryKey({ columns: [table.poolId, table.address] }),
  })
);
```

### Indexes

Create indexes using the `index()` function in the constraints & indexes argument. Ponder creates database indexes after the backfill completes, just before
the app becomes ready.

```ts [ponder.schema.ts] {1,10}
import { onchainTable, index } from "ponder";

export const persons = onchainTable(
  "persons",
  (t) => ({
    id: t.text().primaryKey(),
    name: t.text(),
  }),
  (table) => ({
    nameIdx: index().on(table.name),
  })
);
```

## `onchainEnum`

The `onchainEnum` function accepts two positional arguments. It returns a function that can be used as a column type.

| field      |    type    | description                                                       |
| :--------- | :--------: | :---------------------------------------------------------------- |
| **name**   |  `string`  | The SQL enum name. Use `snake_case`.                              |
| **values** | `string[]` | An array of strings representing the allowed values for the enum. |

```ts [ponder.schema.ts] {3}
import { onchainEnum, onchainTable } from "ponder";

export const color = onchainEnum("color", ["ORANGE", "BLACK"]);

export const cats = onchainTable("cats", (t) => ({
  name: t.text().primaryKey(),
  color: color().notNull(),
}));
```

Like any other column types, you can use modifiers like `.notNull()`, `.default()`, and `.array()` with enum columns.

```ts [ponder.schema.ts] {5}
// ...

export const dogs = onchainTable("cats", (t) => ({
  name: t.text().primaryKey(),
  color: color().array().default([]),
}));
```

## `onchainView`

The `onchainView` function uses the Drizzle query builder API to define a custom query against other tables and views in `ponder.schema.ts`.

{/_ prettier-ignore _/}

```ts [ponder.schema.ts]
import { onchainView, sql, sum, count } from "ponder";

// ... `transferEvent` and other table definitions

export const hourlyBucket = onchainView("hourly_bucket").as((qb) =>
  qb
    .select({
      hour: sql`FLOOR(${transferEvent.timestamp} / 3600) * 3600`.as("hour"),
      totalVolume: sum(transferEvent.amount).as("total_volume"),
      transferCount: count().as("transfer_count"),
    })
    .from(transferEvent)
    .groupBy(sql`FLOOR(${transferEvent.timestamp} / 3600)`)
);
```

[Read more](https://orm.drizzle.team/docs/select) about the Drizzle query builder API.

## `relations`

Use the `relations` function to define relationships between tables.

```ts [ponder.schema.ts] {1,7}
import { onchainTable, relations } from "ponder";

export const users = onchainTable("users", (t) => ({
  id: t.text().primaryKey(),
}));

export const usersRelations = relations(users, ({ one }) => ({
  profile: one(profiles, {
    fields: [users.id],
    references: [profiles.userId],
  }),
}));
```

### Relationship types

| type             | method      | description                                    |
| :--------------- | :---------- | :--------------------------------------------- |
| **One-to-one**   | `one()`     | References single related record               |
| **One-to-many**  | `many()`    | References array of related records            |
| **Many-to-many** | Combination | Uses join table with two one-to-many relations |

Read more in the [relationships guide](#schema-relations) and the Drizzle [relations documentation](https://orm.drizzle.team/docs/relations).

## Api Reference > Ponder > Indexing Functions

# Indexing functions [API reference]

Note: This is a low-level reference. For an introduction, visit the
[Indexing](#indexing-overview) section.
Indexing functions are user-defined functions that receive blockchain data (a log, block, transaction, trace, or transfer) and insert data into the database. You can register indexing functions within any `.ts` file inside the `src/` directory.

## Registration

To register an indexing function, use the `.on(){:ts}` method of the `ponder` object exported from `"ponder:registry"{:ts}`.

Note: Values returned by indexing functions are ignored.

```ts [src/index.ts]
import { ponder } from "ponder:registry";

ponder.on("ContractName:EventName", async ({ event, context }) => {
  // [!code focus]
  const { db, chain, client, contracts } = context;

  // ...
});
```

### Log event

Log events are specified with `"ContractName:EventName"`.

```ts [src/index.ts]
import { ponder } from "ponder:registry";

ponder.on("ContractName:EventName", async ({ event, context }) => {
  // [!code focus]
  // ...
});
```

The `event` object contains the decoded log arguments and the raw log, block, and transaction.

```ts
type LogEvent = {
  name: string;
  args: Args;
  log: Log;
  block: Block;
  transaction: Transaction;
  // Enabled using `includeTransactionReceipts` in contract config
  transactionReceipt?: TransactionReceipt;
};
```

#### Decoded arguments

The `event.args` object contains log argument data (`log.topics` and `log.data`) decoded using Viem's [decodeEventLog](https://viem.sh/docs/contract/decodeEventLog.html) function.

```ts
/** Sample `args` type for an ERC20 Transfer event. */
type Args = {
  from: `0x${string}`;
  to: `0x${string}`;
  value: bigint;
};
```

### Call trace event

Call trace events are specified using `"ContractName.functionName()"`.

Note: The [includeCallTraces](#guides-call-traces) option must
be enabled to register call trace indexing functions.

```ts [src/index.ts]
import { ponder } from "ponder:registry";

ponder.on("ContractName.functionName()", async ({ event, context }) => {
  // [!code focus]
  // ...
});
```

The `event` object contains the decoded trace arguments and the raw trace, block, and transaction.

```ts
type TraceEvent = {
  name: string;
  args: Args;
  result: Result;
  trace: Trace;
  block: Block;
  transaction: Transaction;
  // Enabled using `includeTransactionReceipts` in contract config
  transactionReceipt?: TransactionReceipt;
};
```

#### Decoded arguments

The `event.args` and `event.result` objects contain `trace.input` and `trace.output` decoded using Viem's [decodeFunctionData](https://viem.sh/docs/contract/decodeFunctionData.html) and [decodeFunctionResult](https://viem.sh/docs/contract/decodeFunctionResult.html) functions, respectively.

### Transaction event

Transaction events are specified using `"AccountName:transaction:from"` or `"AccountName:transaction:to"`.

```ts [src/index.ts]
import { ponder } from "ponder:registry";

ponder.on("AccountName:transaction:from", async ({ event, context }) => {
  // [!code focus]
  // ...
});
```

The `event` object contains the raw transaction, transaction receipt, and block.

```ts
type TransactionEvent = {
  block: Block;
  transaction: Transaction;
  transactionReceipt: TransactionReceipt;
};
```

### Transfer event

Native transfer events are specified using `"AccountName:transfer:from"` or `"AccountName:transfer:to"`.

```ts [src/index.ts]
import { ponder } from "ponder:registry";

ponder.on("AccountName:transfer:from", async ({ event, context }) => {
  // [!code focus]
  // ...
});
```

The `event` object contains the transfer and raw block, transaction, and trace.

```ts
type TransferEvent = {
  transfer: {
    from: `0x${string}`;
    to: `0x${string}`;
    value: bigint;
  };
  block: Block;
  transaction: Transaction;
  trace: Trace;
  // Enabled using `includeTransactionReceipts` in account config
  transactionReceipt?: TransactionReceipt;
};
```

### Block event

Block events are created by [block intervals](#config-block-intervals).

```ts [src/index.ts]
import { ponder } from "ponder:registry";

ponder.on("SourceName:block", async ({ event, context }) => {
  // [!code focus]
  // ...
});
```

The `event` object contains only the block.

```ts
type BlockEvent = {
  block: Block;
};
```

### `"setup"` event

You can also define a setup function for each contract that runs before indexing begins.

- The indexing function does not receive an `event` argument, only `context`.
- If you read from contracts in a `"setup"` indexing function, the `blockNumber` for the request is set to the contract's `startBlock`.

For example, you might have a singleton `World` record that occasionally gets updated in indexing functions.

```ts [src/index.ts]
import { ponder } from "ponder:registry";
import { world } from "ponder:schema";

ponder.on("FunGame:NewPlayer", async ({ context }) => {
  await context.db
    .insert(world)
    .values({ id: 1, playerCount: 0 })
    .onConflictDoUpdate((row) => ({
      playerCount: row.playerCount + 1,
    }));
});
```

Without the `"setup"` event, you need to upsert the record in each indexing function that attempts to use it, which is clunky and bad for performance. Instead, use the `"setup"` event to create the singleton record once at the beginning of indexing.

{/_ prettier-ignore _/}

```ts [src/index.ts]
import { ponder } from "ponder:registry";
import { world } from "ponder:schema";

ponder.on("FunGame:setup", async ({ context }) => {
  await context.db.insert(world).values({
    id: 1,
    playerCount: 0,
  });
});

ponder.on("FunGame:NewPlayer", async ({ context }) => {
  await context.db.update(world, { id: 1 }).set((row) => ({
    playerCount: row.playerCount + 1,
  }));
});
```

## Context

The `context` argument passed to each indexing function contains database model objects and helper objects based on your config.

At runtime, the indexing engine uses a different `context` object depending on the chain the current event was emitted on. The TypeScript types for the `context` object reflect this by creating a union of possible types for `context.chain` and `context.contracts`.

{/_ prettier-ignore _/}

```ts
type Context = {
  db: Database;
  chain: { name: string; id: number };
  client: ReadOnlyClient;
  contracts: Record<
    string,
    {
      abi: Abi;
      address?: `0x${string}`;
      startBlock?: number;
      endBlock?: number;
    }
  >;
};
```

### Database

The `context.db` object is a live database connection. [Read more](#indexing-write) about writing to the database.

```ts [src/index.ts]
import { ponder } from "ponder:registry";
import { persons, dogs } from "ponder:schema";

ponder.on("Neighborhood:NewNeighbor", async ({ event, context }) => {
  await context.db.insert(persons).values({ name: "bob", age: 30 }); // [!code focus]
  await context.db.insert(dogs).values({ name: "jake", ownerName: "bob" }); // [!code focus]
  const jake = await context.db.find(dogs, { name: "jake" }); // [!code focus]
});
```

### Chain

The `context.chain` object includes information about the chain that the current event is from. The object is strictly typed according to the chains defined in `ponder.config.ts`.

```ts [src/index.ts]
ponder.on("UniswapV3Factory:Ownership", async ({ event, context }) => {
  context.chain;
  //      ^? { name: "mainnet", id: 1 } | { name: "base", id: 8453 }

  if (context.chain.name === "mainnet") {
    // Do mainnet-specific stuff!
  }
});
```

### Client

Note: See the [Read contract data](#indexing-read-contracts) guide for more
details.

### Contracts

Note: See the [Read contract data](#indexing-read-contracts) guide for more
details.

## Types

The `"ponder:registry"` module exports utility types that are useful for creating reusable helper functions in your indexing files.

### EventNames

A union of all event names that are available from the contracts defined in `ponder.config.ts`.

```ts [src/helpers.ts]
import { ponder, type EventNames } from "ponder:registry";

function helper(eventName: EventNames) {
  eventName;
  // ^? "Weth:Deposit" | "Weth:Withdraw" | "Weth:Approval | "Weth:Transfer"
}
```

### Event

A generic type that optionally accepts an event name and returns the `event` object type for that event.

```ts [src/helpers.ts]
import { ponder, type Event } from "ponder:registry";

function helper(event: Event<"Weth:Deposit">) {
  event;
  // ^? {
  //      args: { dst: `0x${string}`; wad: bigint };
  //      block: Block;
  //      event: "Deposit";
  //      transaction: Transaction;
  //      log: Log;
  //    }
}
```

If no event name is provided, `Event` is the union of all event types. This can be useful if all you need is the `block`, `transaction`, and `log` types which are the same for all events.

```ts [src/helpers.ts]
import { ponder, type Event } from "ponder:registry";

function helper(event: Event) {
  event;
  // ^? { args: { dst: `0x${string}`; wad: bigint }; block: Block; event: "Deposit"; transaction: Transaction; log: Log; }
  //    | { args: { src: `0x${string}`; wad: bigint }; block: Block; event: "Withdraw"; transaction: Transaction; log: Log; }
  //    ...
}
```

### Context

A generic type that optionally accepts an event name and returns the `context` object type.

```ts [src/helpers.ts]
import { ponder, type Context } from "ponder:registry";

function helper(context: Context<"Weth:Deposit">) {
  event;
  // ^? {
  //      chain: { name: "mainnet"; id: 1; };
  //      client: ReadonlyClient;
  //      db: { Account: DatabaseModel<{ id: `0x${string}`; balance: bigint; }> };
  //      contracts: { weth9: { abi: ...; address: "0xC02aaA39b223FE8D0A0e5C4F27eAD9083C756Cc2" } };
  //    }
}
```

If no event name is provided, `Context` returns the union of all context types. This can be useful if all you need is the `db` or `contracts` types which are the same for all events.

### IndexingFunctionArgs

A generic type that optionally accepts an event name and returns the indexing function argument type.

```ts [src/helpers.ts]
import { ponder, type IndexingFunctionArgs } from "ponder:registry";

function helper(args: IndexingFunctionArgs<"Weth:Deposit">) {
  args;
  // ^? {
  //      event: { ... };
  //      context: { ... };
  //    }
}
```

Like `Event` and `Context`, `IndexingFunctionArgs` returns the union of all indexing function argument types if no event name is provided.

### Schema

Use the [Drizzle type helpers](https://orm.drizzle.team/docs/goodies#type-api) to create custom types for database records.

```ts [src/helpers.ts]
import { accounts } from "ponder:schema";

function helper(account: typeof accounts.$inferSelect) {
  account;
  // ^? {
  //      id: bigint;
  //      balance: bigint;
  //      nickname: string;
  //      createdAt: number;
  //    }
}
```

### EVM objects

```ts
/** The block containing the transaction that emitted the log being processed. */
type Block = {
  /** Base fee per gas */
  baseFeePerGas: bigint | null;
  /** "Extra data" field of this block */
  extraData: `0x${string}`;
  /** Maximum gas allowed in this block */
  gasLimit: bigint;
  /** Total used gas by all transactions in this block */
  gasUsed: bigint;
  /** Block hash */
  hash: `0x${string}`;
  /** Logs bloom filter */
  logsBloom: `0x${string}`;
  /** Address that received this block's mining rewards */
  miner: `0x${string}`;
  /** Block number */
  number: bigint;
  /** Parent block hash */
  parentHash: `0x${string}`;
  /** Root of the this block's receipts trie */
  receiptsRoot: `0x${string}`;
  /** Size of this block in bytes */
  size: bigint;
  /** Root of this block's final state trie */
  stateRoot: `0x${string}`;
  /** Unix timestamp of when this block was collated */
  timestamp: bigint;
  /** Total difficulty of the chain until this block */
  totalDifficulty: bigint | null;
  /** Root of this block's transaction trie */
  transactionsRoot: `0x${string}`;
};

/** The transaction that emitted the log being processed. */
type Transaction = {
  /** Transaction sender */
  from: `0x${string}`;
  /** Gas provided for transaction execution */
  gas: bigint;
  /** Base fee per gas. */
  gasPrice?: bigint | undefined;
  /** Hash of this transaction */
  hash: `0x${string}`;
  /** Contract code or a hashed method call */
  input: `0x${string}`;
  /** Total fee per gas in wei (gasPrice/baseFeePerGas + maxPriorityFeePerGas). */
  maxFeePerGas?: bigint | undefined;
  /** Max priority fee per gas (in wei). */
  maxPriorityFeePerGas?: bigint | undefined;
  /** Unique number identifying this transaction */
  nonce: number;
  /** Transaction recipient or `null` if deploying a contract */
  to: `0x${string}` | null;
  /** Index of this transaction in the block */
  transactionIndex: number;
  /** Value in wei sent with this transaction */
  value: bigint;
};

/** A confirmed Ethereum transaction receipt. */
type TransactionReceipt = {
  /** Address of new contract or `null` if no contract was created */
  contractAddress: Address | null;
  /** Gas used by this and all preceding transactions in this block */
  cumulativeGasUsed: bigint;
  /** Pre-London, it is equal to the transaction's gasPrice. Post-London, it is equal to the actual gas price paid for inclusion. */
  effectiveGasPrice: bigint;
  /** Transaction sender */
  from: Address;
  /** Gas used by this transaction */
  gasUsed: bigint;
  /**
   * NOTE: The `logs` property is NOT included for performance reasons.
   * List of log objects generated by this transaction
   * logs: Log[];
   */
  /** Logs bloom filter */
  logsBloom: Hex;
  /** `success` if this transaction was successful or `reverted` if it failed */
  status: "success" | "reverted";
  /** Transaction recipient or `null` if deploying a contract */
  to: Address | null;
  /** Transaction type */
  type: TransactionType;
};

/** The log being processed. */
type Log = {
  /** Globally unique identifier for this log (`${blockHash}-${logIndex}`). */
  id: string;
  /** The address from which this log originated */
  address: `0x${string}`;
  /** Contains the non-indexed arguments of the log */
  data: `0x${string}`;
  /** Index of this log within its block */
  logIndex: number;
  /**
   * Indicates if this log was removed in a chain reorganization.
   *
   * Ponder automatically handles reorgs, so this will always be `false`.
   */
  removed: boolean;
  /** List of order-dependent topics */
  topics: [`0x${string}`, ...`0x${string}`[]] | [];
};

type Trace = {
  /** Globally unique identifier for this trace (`${transactionHash}-${tracePosition}`) */
  id: string;
  /** The type of the call. */
  type:
    | "CALL"
    | "CALLCODE"
    | "DELEGATECALL"
    | "STATICCALL"
    | "CREATE"
    | "CREATE2"
    | "SELFDESTRUCT";
  /** The address of that initiated the call. */
  from: Address;
  /** The address of the contract that was called. */
  to: Address | null;
  /** How much gas was left before the call. */
  gas: bigint;
  /** How much gas was used by the call. */
  gasUsed: bigint;
  /** Calldata input. */
  input: Hex;
  /** Output of the call, if any. */
  output?: Hex;
  /** Error message, if any. */
  error?: string;
  /** Why this call reverted, if it reverted. */
  revertReason?: string;
  /** Value transferred. */
  value: bigint | null;
  /** Index of this trace in the transaction. */
  traceIndex: number;
  /** Number of subcalls. */
  subcalls: number;
};
```

## Api Reference > Ponder > Api Endpoints

# API endpoints [API reference]

Note: This is a low-level reference. For an overview, visit the
[Query](#query-api-endpoints) section.
Ponder's HTTP server is built with [Hono](https://hono.dev/), a fast and lightweight routing framework.

## Hono

Hono supports all standard HTTP methods and an intuitive middleware API.

| method           | description                          |
| :--------------- | :----------------------------------- |
| `get`            | Register a handler for GET requests  |
| `post`           | Register a handler for POST requests |
| `use`            | Register middleware for a path       |
| ...and many more |                                      |

## File requirements

The `src/api/index.ts` file _must_ **default export** a Hono app instance. You can use other files in `src/api/` to organize your code, just be sure to export the Hono app instance correctly.

```ts [src/api/index.ts]
import { Hono } from "hono";

const app = new Hono();

app.get("/hello", (c) => {
  return c.text("Hello, world!");
});

export default app;
```

## `ponder:schema`

The `ponder:schema` virtual module conveniently re-exports the `ponder.schema.ts` file.

```ts [src/api/index.ts]
import { db } from "ponder:api";
import { accounts } from "ponder:schema"; // [!code focus]
import { Hono } from "hono";

const app = new Hono();

app.get("/account/top-10", async (c) => {
  const account = await db
    .select()
    .from(accounts) // [!code focus]
    .limit(10);

  return c.json(account);
});

export default app;
```

## `ponder:api`

The `ponder:api` virtual module exports a ready-to-use Drizzle database client and Viem clients configured according to `ponder.config.ts`.

### `db`

A read-only Drizzle database client backed by a client-side connection pool.

#### Usage

```ts [src/api/index.ts]
import { db } from "ponder:api"; // [!code focus]
import { accounts } from "ponder:schema";
import { Hono } from "hono";
import { eq } from "ponder";

const app = new Hono();

app.get("/account/:address", async (c) => {
  const address = c.req.param("address");

  const account = await db // [!code focus]
    .select() // [!code focus]
    .from(accounts) // [!code focus]
    .where(eq(accounts.address, address)); // [!code focus]

  return c.json(account);
});

export default app;
```

### `publicClients`

A object containing a Viem [Public Client](https://viem.sh/docs/clients/public) for each chain defined in `ponder.config.ts`.

#### Usage

```ts [src/api/index.ts]
import { publicClients } from "ponder:api"; // [!code focus]
import { Hono } from "hono";

const app = new Hono();

app.get("/balance/:address", async (c) => {
  const address = c.req.param("address");

  const balance = await publicClients["base"].getBalance({ address }); // [!code focus]

  return c.json({ address, balance });
});

export default app;
```

## Middlewares

### `graphql`

The `graphql` function is a Hono middleware that accepts the `ponder.schema.ts` schema object and automatically generates a fast & secure GraphQL API.

| field      |    type    | description                                                              |
| :--------- | :--------: | :----------------------------------------------------------------------- |
| **db**     | `Database` | **Required**. Drizzle database object exported from `"ponder:api"{:ts}`. |
| **schema** |  `Schema`  | **Required**. Drizzle schema exported from `"ponder:schema"{:ts}`.       |

#### Usage

```ts [src/api/index.ts]
import { db } from "ponder:api";
import schema from "ponder:schema";
import { graphql } from "ponder"; // [!code focus]
import { Hono } from "hono";

const app = new Hono();

app.use("/", graphql({ db, schema })); // [!code focus]
app.use("/graphql", graphql({ db, schema })); // [!code focus]

export default app;
```

### `client`

The `client` function is a Hono middleware that serves SQL over HTTP queries submitted by `@ponder/client`.

| field      |    type    | description                                                              |
| :--------- | :--------: | :----------------------------------------------------------------------- |
| **db**     | `Database` | **Required**. Drizzle database object exported from `"ponder:api"{:ts}`. |
| **schema** |  `Schema`  | **Required**. Drizzle schema exported from `"ponder:schema"{:ts}`.       |

#### Usage

```ts [src/api/index.ts]
import { db } from "ponder:api";
import schema from "ponder:schema";
import { Hono } from "hono";
import { client } from "ponder"; // [!code focus]

const app = new Hono();

app.use("/sql/*", client({ db, schema })); // [!code focus]

export default app;
```

## Reserved routes

Ponder reserves a few routes for standard use. If you register custom endpoints that conflict with these routes, the build will fail.

| route      | description                                                                                          |
| :--------- | :--------------------------------------------------------------------------------------------------- |
| `/health`  | Returns status code `200` immediately after the process starts.                                      |
| `/ready`   | Returns status code `503` during the backfill, and status code `200` after the backfill is complete. |
| `/status`  | Returns the current indexing status. [Read more](#advanced-observability#indexing-status).           |
| `/metrics` | Prometheus metrics endpoint. [Read more](#advanced-observability#metrics).                           |

## Api Reference > Ponder > Database

# Database reference [API reference]

Note: This is a low-level reference designed to assist with advanced workflows. Visit the [query the
database](#query-direct-sql) guide for an overview.
This page describes internal details of the Ponder instance lifecycle, which may be useful for advanced workflows and database administration.

## Instance lifecycle

Here's an overview of the instance lifecycle. Here, _instance_ refers to a Node.js process running `ponder dev` or `ponder start`.

1. Start returning `200` from the `/health` endpoint. Return `503` from the `/ready` endpoint.
2. Build all user code (config, schema, indexing functions), then generate a `build_id` by hashing the build artifacts.
3. Follow the database schema flow chart below to validate and prepare the target database schema.
4. Start the backfill, either from scratch or from where the previous instance left off (crash recovery).
5. When the backfill finishes, start returning `200` from the `/ready` endpoint.
6. On shutdown (e.g. due to a process exit signal), release the lock on the target schema. Do not drop any tables.

### Database schema rules

- No two instances can use the same database schema at the same time. This prevents data corruption.
- Once an instance running `ponder start` uses a schema, no other instance can use that schema – even after the instance stops. This is a safety mechanism to prevent data loss in production.
- If the target schema was previously used by `ponder dev`, the new instance will drop the previous tables and start successfully.

Here is the detailed flow chart.

```mermaid
flowchart TD
A[Target schema is currently in use?]

C[Target schema previously used?]
F[Previous instance command?]
E[Previous build ID same as current?]

V(Drop existing tables)
W(Recover from existing tables)
X(Create tables)
Y(Start)
Z1(Error)
Z2(Error)


V --> X
W --> Y
X --> Y

A -- yes --> Z1
A -- no --> C

C -- yes --> F
C -- no --> X

F -- ponder start --> E
F -- ponder dev --> V

E -- no --> Z2
E -- yes --> W

style Y fill:#0a0,color:#fff
style Z1 fill:#f00,color:#fff
style Z2 fill:#f00,color:#fff
```

### Lock / metadata table

The `_ponder_meta` table tracks the state of an instance running in a specific database schema. It stores the `build_id`, indexing checkpoint, and table names of the current instance, and uses a heartbeat locking mechanism to support the lifecycle logic described above.

### Checkpoint Table

The `_ponder_checkpoint` table tracks the indexing progress of each chain.

### Build ID and crash recovery

During the build step, each instance generates a content hash of the entire app (config, schema, and indexing function file contents). This is called the `build_id`.

Note that crash recovery is disabled when running `ponder dev`.

## RPC request cache

Ponder caches RPC request data to improve reindexing performance on hot reloads and redeployments. This includes logs, blocks, transactions, traces, and any RPC requests made with `context.client`.

- The RPC request cache is located in the `ponder_sync` schema.
- The cache is durable and persists across instance restarts.
- The cache query patterns are lock-free. It's safe for multiple instances to run in the same Postgres database at the same time (reading and writing to the same `ponder_sync` schema).
- The cache does not store unfinalized data.

## Api Reference > Ponder Client

# `@ponder/client` [API reference]

Note: This is a low-level reference. For an introduction, visit the
[SQL over HTTP](#query-sql-over-http) page.
The `@ponder/client` package provides a typed SQL over HTTP client for querying your Ponder database from client applications.

## Installation

```bash [pnpm]
pnpm add @ponder/client
```

```bash [yarn]
yarn add @ponder/client
```

```bash [npm]
npm add @ponder/client
```

```bash [bun]
bun add @ponder/client
```

## `createClient`

Create a client object connected to a Ponder server.

#### Usage

```ts [Client project]
import { createClient } from "@ponder/client";
import * as schema from "../../ponder/ponder.schema";

const client = createClient("https://.../sql", { schema });

export { client, schema };
```

#### Parameters

| Parameter        | Type                  | Description                                                |
| ---------------- | --------------------- | ---------------------------------------------------------- |
| `baseUrl`        | `string`              | Ponder server URL where the `client` middleware is running |
| `options.schema` | `Schema \| undefined` | The schema exported by `ponder.schema.ts`                  |

#### Returns

Returns a `Client` object with methods for querying the database.

## `client.db`

Build a SQL query using Drizzle and execute it over HTTP.

#### Usage

```ts [Client project]
import { client, schema } from "../lib/ponder";
import { eq } from "@ponder/client";

const result = await client.db.select().from(schema.account).limit(10);

const filteredResults = await client.db
  .select()
  .from(schema.account)
  .where(eq(schema.account.id, "0x123..."));
```

#### Returns

Returns an array of objects according to the query.

## `client.live`

Subscribe to live updates from the database using server-sent events (SSE).

#### Usage

```ts [Client project]
import { client, schema } from "../lib/ponder";

const { unsubscribe } = client.live(
  (db) => db.select().from(schema.account),
  (result) => {
    console.log("Updated accounts:", result);
  },
  (error) => {
    console.error("Subscription error:", error);
  }
);

// Later, to stop receiving updates:
unsubscribe();
```

#### Parameters

| Parameter | Type                                | Description                                          |
| --------- | ----------------------------------- | ---------------------------------------------------- |
| `queryFn` | `(db: ClientDb) => Promise<Result>` | A query builder callback using the `db` argument     |
| `onData`  | `(result: Result) => void`          | Callback that receives each new query result         |
| `onError` | `(error: Error) => void`            | Optional callback that handles any errors that occur |

#### Returns

Returns an object with an `unsubscribe` method that can be called to stop receiving updates.

#### Implementation notes

- Each `createClient` instance multiplexes all live queries over a single SSE connection.
- The server notifies the client whenever a new block gets indexed. If a query result is no longer valid, the client immediately refetches it to receive the latest result.

## `client.getStatus`

Fetch the indexing progress of each chain.

#### Usage

```ts [Client project]
import { client, schema } from "../lib/ponder";

const status = await client.getStatus();

console.log("Mainnet indexing status:", status.mainnet);
```

#### Returns

Returns a Promise that resolves to an object containing the indexing status of each chain.

```ts
type Status = {
  [chain: string]: {
    id: number;
    block: { number: number; timestamp: number } | null;
  };
};
```

## Drizzle utility functions

The `@ponder/client` package exports all relevant Drizzle utility functions ([full list](https://github.com/ponder-sh/ponder/blob/main/packages/client/src/index.ts#L176)). You shouldn't need to install `drizzle-orm` separately.

#### Usage

```ts [Client project]
import { client, schema } from "../lib/ponder";
import { eq, gte, and, desc } from "@ponder/client"; // [!code focus]

const result = await client.db
  .select()
  .from(schema.transfers)
  .where(
    and(
      gte(schema.transfers.value, 1000000n),
      eq(schema.transfers.from, "0x123...")
    )
  )
  .orderBy(desc(schema.transfers.blockNumber));
```

## Api Reference > Ponder React

# `@ponder/react` [API reference]

Note: This is a low-level reference. For an introduction, visit the
[SQL over HTTP](#query-sql-over-http) page.
The `@ponder/react` package provides React hooks for subscribing to live updates from your database.

This package uses [`@ponder/client`](#api-reference-ponder-client) to execute SQL queries over HTTP, and integrates with [TanStack Query](https://tanstack.com/query) for async state management.

## Installation

`@ponder/react` has peer dependencies on `@ponder/client` and `@tanstack/react-query`.

```bash [pnpm]
pnpm add @ponder/react @ponder/client @tanstack/react-query
```

```bash [yarn]
yarn add @ponder/react @ponder/client @tanstack/react-query
```

```bash [npm]
npm add @ponder/react @ponder/client @tanstack/react-query
```

```bash [bun]
bun add @ponder/react @ponder/client @tanstack/react-query
```

## `PonderProvider`

React Context Provider that makes the SQL over HTTP client instance available to all child components.

#### Usage

```tsx [Client project]
import { QueryClient, QueryClientProvider } from "@tanstack/react-query";
import { PonderProvider } from "@ponder/react";
import { client } from "../lib/ponder"; // Client instance from @ponder/client

const queryClient = new QueryClient();

function App() {
  return (
    <PonderProvider client={client}>
      <QueryClientProvider client={queryClient}>
        {/* Your application components */}
      </QueryClientProvider>
    </PonderProvider>
  );
}
```

#### Parameters

| Parameter | Type     | Description                                                        |
| --------- | -------- | ------------------------------------------------------------------ |
| `client`  | `Client` | A client instance returned by `createClient` from `@ponder/client` |

## `usePonderQuery`

Hook to run a custom SQL query over HTTP with live updates.

#### Usage

```tsx [Client project]
import { usePonderQuery } from "@ponder/react";
import { schema } from "../lib/ponder";

function AccountList() {
  const { data, isLoading, error } = usePonderQuery({
    queryFn: (db) =>
      db
        .select()
        .from(schema.account)
        .orderBy(schema.account.createdAt)
        .limit(10),
  });

  if (isLoading) return <div>Loading...</div>;
  if (error) return <div>Error: {error.message}</div>;

  return (
    <ul>
      {data?.map((account) => (
        <li key={account.id}>{account.address}</li>
      ))}
    </ul>
  );
}
```

#### Parameters

| Parameter        | Type                                                     | Description                                             |
| ---------------- | -------------------------------------------------------- | ------------------------------------------------------- |
| `params.queryFn` | `(db: Client["db"]) => Promise<Result>`                  | Required query builder callback using the `db` argument |
| `params.live`    | `boolean`                                                | Whether to subscribe to live updates (default: `true`)  |
| `...params`      | `Omit<UseQueryOptions<Result>, "queryFn" \| "queryKey">` | All `useQuery` options except `queryFn` and `queryKey`  |

#### Returns

Returns a normal TanStack `useQuery` result object. [Read more](https://tanstack.com/query/latest/docs/framework/react/reference/useQuery) in the TanStack documentation.

#### Implementation notes

- Uses [`client.live`](#api-reference-ponder-client#clientlive) to automatically refetch data when new blocks are indexed
- Subscribes to updates on mount and unsubscribes on unmount
- Requires `PonderProvider` in the component tree

## `usePonderStatus`

Hook to query the indexing status of the Ponder server over HTTP with live updates.

#### Usage

```tsx [Client project]
import { usePonderStatus } from "@ponder/react";

function IndexingStatus() {
  const { data, isLoading } = usePonderStatus();

  if (isLoading) return <div>Loading status...</div>;

  return (
    <div>
      {Object.entries(data).map(([chain, status]) => (
        <div key={chain}>
          <h3>{chain}</h3>
          {status.block && (
            <p>
              Block: {status.block.number} (
              {new Date(status.block.timestamp * 1000).toLocaleString()})
            </p>
          )}
        </div>
      ))}
    </div>
  );
}
```

#### Parameters

| Parameter | Type                                                     | Description                                            |
| --------- | -------------------------------------------------------- | ------------------------------------------------------ |
| `params`  | `Omit<UseQueryOptions<Status>, "queryFn" \| "queryKey">` | All `useQuery` options except `queryFn` and `queryKey` |

#### Returns

Returns a normal TanStack `useQuery` result containing the indexing [status object](#advanced-observability#indexing-status). [Read more](https://tanstack.com/query/latest/docs/framework/react/reference/useQuery) in the TanStack documentation.

## `getPonderQueryOptions`

Helper function to build the TanStack Query `queryFn` and `queryKey` for a SQL over HTTP query.

```tsx [index.ts]
import { getPonderQueryOptions } from "@ponder/react";
import { client, schema } from "../lib/ponder";

const accountsQueryOptions = getPonderQueryOptions(client, (db) =>
  db.select().from(schema.account).limit(10)
);

const query = usePonderQuery(accountsQueryOptions);
```

#### Parameters

| Parameter | Type                                    | Description                                                                         |
| --------- | --------------------------------------- | ----------------------------------------------------------------------------------- |
| `client`  | `Client`                                | A client instance created by `createClient`                                         |
| `queryFn` | `(db: Client["db"]) => Promise<Result>` | Function that receives the Drizzle query builder and returns a query result promise |

#### Returns

| Property   | Type                    | Description                                                                                                                                      |
| ---------- | ----------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------ |
| `queryKey` | `QueryKey`              | A TanStack Query [Key](https://tanstack.com/query/latest/docs/framework/react/guides/query-keys) that encodes the SQL statement                  |
| `queryFn`  | `() => Promise<Result>` | A TanStack Query [Function](https://tanstack.com/query/latest/docs/framework/react/guides/query-functions) that executes the SQL query over HTTP |

## `usePonderQueryOptions`

Same as [`getPonderQueryOptions`](#getponderqueryoptions), but uses the `PonderProvider` context to get the client instance.

```tsx [index.ts]
import { usePonderQueryOptions } from "@ponder/react";
import { schema } from "../lib/ponder";

const accountsQueryOptions = usePonderQueryOptions((db) =>
  db.select().from(schema.account).limit(10)
);

const query = usePonderQuery(accountsQueryOptions);
```

#### Parameters

| Parameter | Type                                    | Description                                                                         |
| --------- | --------------------------------------- | ----------------------------------------------------------------------------------- |
| `queryFn` | `(db: Client["db"]) => Promise<Result>` | Function that receives the Drizzle query builder and returns a query result promise |

#### Returns

| Property   | Type                    | Description                                                                                                                                      |
| ---------- | ----------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------ |
| `queryKey` | `QueryKey`              | A TanStack Query [Key](https://tanstack.com/query/latest/docs/framework/react/guides/query-keys) that encodes the SQL statement                  |
| `queryFn`  | `() => Promise<Result>` | A TanStack Query [Function](https://tanstack.com/query/latest/docs/framework/react/guides/query-functions) that executes the SQL query over HTTP |

## `usePonderClient`

Hook to get the `client` instance from the `PonderProvider` context.

```ts [index.ts]
import { usePonderClient } from "@ponder/react";

const client = usePonderClient();
```

#### Returns

Returns the `client` instance from the `PonderProvider` context.

## Api Reference > Ponder Utils

# `@ponder/utils` [API reference]

The `@ponder/utils` package provides utility functions for common tasks in Ponder apps.

## `mergeAbis`

Combines many ABIs into one. Removes duplicate items if necessary.

#### Usage

```ts [index.ts]
import { mergeAbis } from "@ponder/utils";
import { erc20Abi, erc4626Abi } from "viem";

const tokenAbi = mergeAbis([erc20Abi, erc4626Abi]);
```

#### Parameters

| Parameter | Type    | Description              |
| --------- | ------- | ------------------------ |
| `ABIs`    | `Abi[]` | A list of ABIs to merge. |

#### Returns

A new ABI including all items from the input list, with duplicates removed.

#### Usage in Ponder

Use `mergeAbis` to include multiple ABIs for a single contract. This is especially useful for proxy contracts that have had several different implementation ABIs.

For convenience, `ponder` re-exports `mergeAbis` from `@ponder/utils`.

```ts [ponder.config.ts]
import { createConfig, mergeAbis } from "ponder"; // [!code focus]

import { ERC1967ProxyAbi } from "./abis/ERC1967Proxy"; // [!code focus]
import { NameRegistryAbi } from "./abis/NameRegistry"; // [!code focus]
import { NameRegistry2Abi } from "./abis/NameRegistry2"; // [!code focus]

export default createConfig({
  contracts: {
    FarcasterNameRegistry: {
      abi: mergeAbis([ERC1967ProxyAbi, NameRegistryAbi, NameRegistry2Abi]), // [!code focus]
      // ...
    },
  },
  // ...
});
```

## `replaceBigInts`

Replaces all [`BigInt`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/BigInt) values in an object (deep traversal) with a new value, specified by a replacer function.

#### Usage

This example simply converts `BigInt` values to a string.

```ts [index.ts] {5}
import { replaceBigInts } from "@ponder/utils";

const obj = { a: 100n, b: [-12n, 3_000_000_000n] };

const result = replaceBigInts(obj, (v) => String(v));
//    ?^ { a: '100', b: [ '-12', '3000000000' ] }
```

#### Parameters

| Parameter  | Type                                  | Description                                                             |
| ---------- | ------------------------------------- | ----------------------------------------------------------------------- |
| `value`    | `any`                                 | The scalar, array, or object containing `BigInt` values to be replaced. |
| `replacer` | `(value: bigint) => JSONSerializable` | A custom replacer function that will be called for each `BigInt` value. |

#### Returns

The scalar, array, or object with all `BigInt` values replaced.

#### Replacer functions

Here are three common ways to replace `BigInt` values.

| Encoding            | Replacer type       | Replacer function                                                 |
| :------------------ | :------------------ | :---------------------------------------------------------------- |
| **Hex**             | `0x${string}`       | [`numberToHex`](https://viem.sh/docs/utilities/toHex#numbertohex) |
| **String**          | `string`            | `String`                                                          |
| **Lossless string** | `#bigint.${string}` | `(x) => #bigint.${String(x)}`                                     |

See the [Wagmi FAQ](https://wagmi.sh/react/guides/faq#bigint-serialization) for more information on `BigInt` serialization.

#### Usage in Ponder: `json` columns

The [`json` column type](#schema-tables#column-types) does not support `BigInt` values. Use `replaceBigInts` to prepare objects containing `BigInt` values for insertion.

```ts [src/index.ts] {2,9}
import { ponder } from "ponder:registry";
import { userOperations } from "ponder:schema";
import { replaceBigInts } from "@ponder/utils";
import { toHex } from "viem";

ponder.on("EntryPoint:UserOp", async ({ event, context }) => {
  await context.db.insert(userOperations).values({
    id: event.log.id,
    receipt: replaceBigInts(event.transactionReceipt, toHex),
  });
});
```

To maintain type safety for column values, use the `ReplaceBigInts` helper type in the column `$type` annotation.

```ts [ponder.schema.ts] {1,7}
import { onchainTable } from "ponder";
import type { ReplaceBigInts } from "@ponder/utils";
import type { TransactionReceipt, Hex } from "viem";

export const userOperations = onchainTable("user_operations", (t) => ({
  id: t.text().primaryKey(),
  receipt: t.json<ReplaceBigInts<TransactionReceipt, Hex>>(),
}));
```

#### Usage in Ponder: API endpoints

The GraphQL API automatically serializes `BigInt` values to strings before returning them in HTTP responses. In custom API endpoints, you need to handle this serialization process manually.

```ts [src/api/index.ts]
import { ponder } from "ponder:registry";
import { accounts } from "ponder:schema";
import { replaceBigInts } from "@ponder/utils"; // [!code focus]
import { numberToHex } from "viem";

ponder.get("/whale-balances", async (c) => {
  const rows = await c.db
    .select({
      address: accounts.address,
      ethBalance: accounts.ethBalance,
      dogeBalance: accounts.dogeBalance,
    })
    .from(accounts)
    .where(eq(accounts.address, address));

  const result = replaceBigInts(rows, (v) => numberToHex(v)); // [!code focus]

  return c.json(result);
});
```

## Transports

The `@ponder/utils` package exports two new [Viem transports](https://viem.sh/docs/clients/intro#transports), `loadBalance` and `rateLimit`. These transports are useful for managing the RPC request workloads that Ponder apps commonly encounter.

### `loadBalance`

The `loadBalance` Transport distributes requests across a list of inner Transports in a simple round-robin scheme.

#### Usage

```ts {7-12}
import { loadBalance } from "@ponder/utils"; // [!code focus]
import { createPublicClient, fallback, http, webSocket } from "viem";
import { mainnet } from "viem/chains";

const transport = loadBalance([
  // [!code focus]
  http("https://cloudflare-eth.com"), // [!code focus]
  webSocket("wss://ethereum-rpc.publicnode.com"), // [!code focus]
  rateLimit(http("https://rpc.ankr.com/eth"), { requestsPerSecond: 5 }), // [!code focus]
]); // [!code focus]

const client = createPublicClient({ chain: mainnet, transport });
```

#### Parameters

| Parameter    | Type          | Description                                           |
| ------------ | ------------- | ----------------------------------------------------- |
| `Transports` | `Transport[]` | A list of Transports to load balance requests across. |

#### Usage in Ponder

For convenience, `ponder` re-exports `loadBalance` from `@ponder/utils`.

```ts [ponder.config.ts] {8-13}
import { createConfig, loadBalance } from "ponder";
import { http, webSocket, rateLimit } from "viem";

export default createConfig({
  chains: {
    mainnet: {
      id: 1,
      rpc: loadBalance([
        // [!code focus]
        http("https://cloudflare-eth.com"), // [!code focus]
        http("https://eth-mainnet.public.blastapi.io"), // [!code focus]
        webSocket("wss://ethereum-rpc.publicnode.com"), // [!code focus]
        rateLimit(http("https://rpc.ankr.com/eth"), { requestsPerSecond: 5 }), // [!code focus]
      ]), // [!code focus]
    },
  },
  // ...
});
```

### `rateLimit`

The `rateLimit` Transport limits the number of requests per second submitted to an inner Transport using a first-in-first-out queue.

#### Usage

```ts {7-9}
import { rateLimit } from "@ponder/utils";
import { createPublicClient, fallback, http } from "viem";
import { mainnet } from "viem/chains";

const client = createPublicClient({
  chain: mainnet,
  transport: rateLimit(http("https://eth-mainnet.g.alchemy.com/v2/..."), {
    requestsPerSecond: 25,
  }),
});
```

#### Parameters

| Parameter           | Type                        | Description                                                                                                                                                                                          |
| ------------------- | --------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `Transport`         | `Transport`                 | An inner transport to rate limit.                                                                                                                                                                    |
| `requestsPerSecond` | `number`                    | The maximum number of requests per second to allow.                                                                                                                                                  |
| `browser`           | `boolean` (default: `true`) | If `false`, the internal queue will use the Node.js-specific `process.nextTick()` API to schedule requests. This leads to more predictable behavior in Node.js, but is not available in the browser. |

#### Usage in Ponder

For convenience, `ponder` re-exports `rateLimit` from `@ponder/utils`.

```ts [ponder.config.ts] {8-10}
import { createConfig, rateLimit } from "ponder";
import { http } from "viem";

export default createConfig({
  chains: {
    mainnet: {
      id: 1,
      rpc: rateLimit(http(process.env.PONDER_RPC_URL_1), {
        requestsPerSecond: 25,
      }),
    },
  },
  contracts: {
    // ...
  },
});
```

## Advanced > Observability

# Observability [Logs, metrics, and indexing status]

## Logs

Ponder produces logs to help you understand and debug your application.

![Terminal logs gif](/logs-014.gif)

### Log level

There are two ways to configure the minimum log level. If specified, the environment variable takes precedence over the CLI flag.

- Set the `PONDER_LOG_LEVEL` environment variable
- Use the `--log-level <LEVEL>`, `-v` (debug) or `-vv` (trace) CLI option

```js [.env.local]
PONDER_LOG_LEVEL = trace;
```

```bash [Terminal]
ponder dev --log-level warn
# or, use the shortcut flag for debug
ponder dev -v
```

#### Levels

| Log level        | Example                                                                    |
| :--------------- | :------------------------------------------------------------------------- |
| `silent`         |                                                                            |
| `error`          | Errors thrown in user code and other errors that will likely cause a crash |
| `warn`           | Malformed RPC data, reorgs, and other errors that will be retried          |
| `info` (default) | Indexing progress and key lifecycle events                                 |
| `debug`          | Internal updates                                                           |
| `trace`          | Database query logs, RPC request logs                                      |

#### User logs

Logs produced by your code (e.g. `console.log` statements in `ponder.config.ts` or indexing functions) will always be written to the console. Note that Ponder _does_ catch **errors** thrown by your code and emits an `error` log including the original error message and stack trace.

### Log format

Use the `--log-format <FORMAT>` CLI option to set the log format.

#### Pretty (default)

```bash [Terminal]
ponder start --log-format pretty
```

```bash [Output]
12:12:15.391 INFO  Indexed block chain=mainnet number=23569900 event_count=14 (23ms)
12:12:16.159 INFO  Indexed block chain=polygon number=77633630 event_count=0 (1ms)
12:12:16.174 INFO  Indexed block chain=optimism number=142386579 event_count=1 (4ms)
12:12:16.226 INFO  Indexed block chain=base number=36791294 event_count=9 (14ms)
12:12:18.068 INFO  Indexed block chain=optimism number=142386580 event_count=2 (8ms)
12:12:18.125 INFO  Indexed block chain=polygon number=77633631 event_count=0 (1ms)
12:12:18.188 INFO  Indexed block chain=base number=36791295 event_count=10 (16ms)
12:12:20.021 INFO  Indexed block chain=optimism number=142386581 event_count=0 (4ms)
```

#### JSON

```bash [Terminal]
ponder start --log-format json
```

The JSON log format emits newline-delimited JSON objects with required properties `level`, `time`, and `msg`. Most logs also include a `duration` property and other properties depending on the context.

```json [Output]
{"level":30,"time":1760372079306,"msg":"Indexed block","chain":"mainnet","chain_id":1,"number":23569912,"event_count":17,"duration":27.752416999996058}
{"level":30,"time":1760372080106,"msg":"Indexed block","chain":"polygon","chain_id":137,"number":77633702,"event_count":0,"duration":3.4684160000033444}
{"level":30,"time":1760372080122,"msg":"Indexed block","chain":"optimism","chain_id":10,"number":142386651,"event_count":0,"duration":2.3179999999993015}
{"level":30,"time":1760372080314,"msg":"Indexed block","chain":"base","chain_id":8453,"number":36791366,"event_count":10,"duration":18.320999999996275}
{"level":30,"time":1760372082131,"msg":"Indexed block","chain":"optimism","chain_id":10,"number":142386652,"event_count":0,"duration":3.074124999999185}
{"level":30,"time":1760372082258,"msg":"Indexed block","chain":"polygon","chain_id":137,"number":77633703,"event_count":0,"duration":1.7850829999952111}
{"level":30,"time":1760372082328,"msg":"Indexed block","chain":"base","chain_id":8453,"number":36791367,"event_count":4,"duration":9.394625000000815}
{"level":30,"time":1760372084153,"msg":"Indexed block","chain":"optimism","chain_id":10,"number":142386653,"event_count":0,"duration":2.679999999993015}
```

### Terminal UI

The dynamic terminal UI displays a useful summary of chain connection status, indexing function duration, and backfill progress.

```bash [Output]
Chains

│ Chain    │ Status │ Block     │ RPC (req/s) │
├──────────┼────────┼───────────┼─────────────┤
│ optimism │ live   │ 142388578 │         1.6 │
│ polygon  │ live   │  77635629 │        17.2 │
│ base     │ live   │  36793293 │         4.2 │
│ mainnet  │ live   │  23570232 │         7.5 │

Indexing (live)

│ Event         │ Count │ Duration (ms) │
├───────────────┼───────┼───────────────┤
│ WETH:Deposit  │   107 │         1.554 │

API endpoints
Live at http://localhost:42069
```

The terminal UI is disabled by default for `ponder start`. Use the `--disable-ui` CLI option to disable the UI for `ponder dev`.

```bash [Terminal]
ponder dev --disable-ui
```

## Metrics

Ponder apps publish Prometheus metrics at the `/metrics` path.

Warning: Metrics are not part of the public API, so these are subject to change without notice. Do not rely on these metrics for anything important (yet).
| name | description | type |
| :------------------------------------- | :-------------------------------------------------------------------- | --------- |
| ponder_indexing_total_seconds | Total number of seconds required for indexing | gauge |
| ponder_indexing_completed_seconds | Number of seconds that have been completed | gauge |
| ponder_indexing_completed_events | Number of events that have been processed | gauge |
| ponder_indexing_completed_timestamp | Timestamp through which all events have been completed | gauge |
| ponder_indexing_function_duration | Duration of indexing function execution | histogram |
| ponder_indexing_function_error_total | Total number of errors encountered during indexing function execution | counter |
| ponder_historical_start_timestamp | Unix timestamp (ms) when the historical sync service started | gauge |
| ponder_historical_total_blocks | Number of blocks required for the historical sync | gauge |
| ponder_historical_cached_blocks | Number of blocks that were found in the cache for the historical sync | gauge |
| ponder_historical_completed_blocks | Number of blocks that have been processed for the historical sync | gauge |
| ponder_realtime_is_connected | Boolean (0 or 1) indicating if the realtime sync service is connected | gauge |
| ponder_realtime_latest_block_number | Block number of the latest synced block | gauge |
| ponder_realtime_latest_block_timestamp | Block timestamp of the latest synced block | gauge |
| ponder_realtime_reorg_total | Count of how many re-orgs have occurred | counter |
| ponder_database_method_duration | Duration of database operations | histogram |
| ponder_database_method_error_total | Total number of errors encountered during database operations | counter |
| ponder_http_server_active_requests | Number of active HTTP server requests | gauge |
| ponder_http_server_request_duration_ms | Duration of HTTP responses served by the server | histogram |
| ponder_http_server_request_size_bytes | Size of HTTP requests received by the server | histogram |
| ponder_http_server_response_size_bytes | Size of HTTP responses served by the server | histogram |
| ponder_rpc_request_duration | Duration of RPC requests | histogram |
| ponder_rpc_request_error_total | Total number of failed RPC requests | counter |
| ponder_postgres_pool_connections | Gauge of current connections for PostgreSQL pools | gauge |
| ponder_postgres_query_queue_size | Current size of the query queue for PostgreSQL | gauge |
| ponder_postgres_query_total | Total number of queries processed by PostgreSQL | counter |

## Indexing status

To check the indexing status of your app, use the `/status` endpoint or the `_meta` field in the GraphQL API.

### Usage

Use the indexing status to quickly confirm that Ponder is working as expected. You can also poll the status to confirm that a specific block number has been ingested by Ponder before refetching a query client-side (for example, in a form submit handler).

#### HTTP

```bash [Request]
curl http://localhost:42069/status
```

```json [Response]
{
  "mainnet": {
    "id": 1,
    "block": {
      "number": 20293450,
      "timestamp": 1720823759
    }
  },
  "base": {
    "id": 8453,
    "block": {
      "number": 17017206,
      "timestamp": 1720823759
    }
  }
}
```

#### GraphQL

```graphql [Query]
query {
  _meta {
    status
  }
}
```

```json [Result]
{
  "_meta": {
    "status": {
      "mainnet": {
        "id": 1,
        "block": {
          "number": 20293464,
          "timestamp": 1720823939
        }
      },
      "base": {
        "id": 8453,
        "block": null
      }
    }
  }
}
```

### API

The response object contains a property for each chain in your app with the following fields.

| field     |                       type                       | description                                                                 |
| :-------- | :----------------------------------------------: | :-------------------------------------------------------------------------- |
| **id**    |                     `number`                     | The chain ID.                                                               |
| **block** | `{ number: number; timestamp: number; } \| null` | The most recently indexed block, or `null` if the backfill is not complete. |

## Advanced > Telemetry

# Telemetry [How Ponder collects and uses telemetry]

Ponder collects **completely anonymous** telemetry data about general usage. The developers use this data to prioritize new feature development, identify bugs, and improve performance & stability.

## Opt out

To opt out of telemetry, set the `PONDER_TELEMETRY_DISABLED` environment variable.

{/_ prettier-ignore _/}

```js [.env.local]
PONDER_TELEMETRY_DISABLED = true;
```

## Implementation

Ponder's telemetry implementation is 100% open-source. The [telemetry service](https://github.com/ponder-sh/ponder/blob/main/packages/core/src/common/telemetry.ts#L47) (part of `ponder`) runs on the user's device and submits event data via HTTP POST requests to the [telemetry collection endpoint](https://github.com/ponder-sh/ponder/blob/main/docs/pages/api/telemetry/index.ts) hosted at `https://ponder.sh/api/telemetry`.

The implementation generates a stable anonymous unique identifier for the user's device and stores it at the [system default user config directory](https://github.com/sindresorhus/env-paths#pathsconfig). This config also stores the user's opt-out preference and a stable salt used to hash potentially sensitive data such as file paths and the git remote URL.
